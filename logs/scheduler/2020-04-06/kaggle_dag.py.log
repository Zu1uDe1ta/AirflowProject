[2020-04-05 20:00:30,000] {scheduler_job.py:153} INFO - Started process (PID=16036) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:00:30,006] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:00:30,007] {logging_mixin.py:112} INFO - [2020-04-05 20:00:30,007] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:00:30,196] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:00:30,213] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.212 seconds
[2020-04-05 20:01:22,161] {scheduler_job.py:153} INFO - Started process (PID=16064) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:01:22,168] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:01:22,170] {logging_mixin.py:112} INFO - [2020-04-05 20:01:22,169] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:01:22,391] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:01:22,409] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.249 seconds
[2020-04-05 20:02:14,318] {scheduler_job.py:153} INFO - Started process (PID=16093) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:02:14,325] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:02:14,326] {logging_mixin.py:112} INFO - [2020-04-05 20:02:14,326] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:02:14,498] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:02:14,521] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.203 seconds
[2020-04-05 20:03:06,483] {scheduler_job.py:153} INFO - Started process (PID=16121) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:03:06,489] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:03:06,490] {logging_mixin.py:112} INFO - [2020-04-05 20:03:06,490] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:03:06,662] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:03:06,686] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.203 seconds
[2020-04-05 20:03:58,673] {scheduler_job.py:153} INFO - Started process (PID=16148) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:03:58,679] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:03:58,680] {logging_mixin.py:112} INFO - [2020-04-05 20:03:58,680] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:03:58,858] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:03:58,882] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.209 seconds
[2020-04-05 20:04:50,808] {scheduler_job.py:153} INFO - Started process (PID=16177) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:04:50,815] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:04:50,817] {logging_mixin.py:112} INFO - [2020-04-05 20:04:50,817] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:04:50,994] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:04:51,016] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.208 seconds
[2020-04-05 20:05:42,971] {scheduler_job.py:153} INFO - Started process (PID=16205) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:05:42,978] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:05:42,980] {logging_mixin.py:112} INFO - [2020-04-05 20:05:42,979] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:05:43,210] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:05:43,226] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.256 seconds
[2020-04-05 20:06:35,123] {scheduler_job.py:153} INFO - Started process (PID=16233) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:06:35,129] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:06:35,130] {logging_mixin.py:112} INFO - [2020-04-05 20:06:35,130] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:06:35,308] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:06:35,330] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.207 seconds
[2020-04-05 20:07:27,271] {scheduler_job.py:153} INFO - Started process (PID=16260) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:07:27,276] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:07:27,277] {logging_mixin.py:112} INFO - [2020-04-05 20:07:27,277] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:07:27,450] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:07:27,465] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.194 seconds
[2020-04-05 20:08:19,418] {scheduler_job.py:153} INFO - Started process (PID=16294) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:08:19,426] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:08:19,427] {logging_mixin.py:112} INFO - [2020-04-05 20:08:19,426] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:08:19,643] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:08:19,660] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.242 seconds
[2020-04-05 20:09:11,526] {scheduler_job.py:153} INFO - Started process (PID=16324) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:09:11,532] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:09:11,533] {logging_mixin.py:112} INFO - [2020-04-05 20:09:11,533] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:09:11,706] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:09:11,730] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.203 seconds
[2020-04-05 20:10:03,651] {scheduler_job.py:153} INFO - Started process (PID=16354) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:10:03,658] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:10:03,659] {logging_mixin.py:112} INFO - [2020-04-05 20:10:03,658] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:10:03,833] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:10:03,855] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.204 seconds
[2020-04-05 20:10:55,763] {scheduler_job.py:153} INFO - Started process (PID=16381) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:10:55,769] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:10:55,770] {logging_mixin.py:112} INFO - [2020-04-05 20:10:55,769] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:10:55,940] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:10:55,962] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.199 seconds
[2020-04-05 20:11:47,907] {scheduler_job.py:153} INFO - Started process (PID=16413) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:11:47,915] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:11:47,916] {logging_mixin.py:112} INFO - [2020-04-05 20:11:47,916] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:11:48,242] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:11:48,257] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.350 seconds
[2020-04-05 20:12:40,035] {scheduler_job.py:153} INFO - Started process (PID=16443) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:12:40,048] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:12:40,050] {logging_mixin.py:112} INFO - [2020-04-05 20:12:40,049] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:12:40,228] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:12:40,252] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.217 seconds
[2020-04-05 20:13:32,196] {scheduler_job.py:153} INFO - Started process (PID=16478) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:13:32,206] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:13:32,208] {logging_mixin.py:112} INFO - [2020-04-05 20:13:32,207] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:13:32,456] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:13:32,477] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.282 seconds
[2020-04-05 20:14:24,319] {scheduler_job.py:153} INFO - Started process (PID=16510) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:14:24,326] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:14:24,327] {logging_mixin.py:112} INFO - [2020-04-05 20:14:24,327] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:14:24,542] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:14:24,557] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.238 seconds
[2020-04-05 20:15:16,461] {scheduler_job.py:153} INFO - Started process (PID=16538) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:15:16,467] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:15:16,468] {logging_mixin.py:112} INFO - [2020-04-05 20:15:16,468] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:15:16,706] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:15:16,723] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.262 seconds
[2020-04-05 20:16:08,598] {scheduler_job.py:153} INFO - Started process (PID=16566) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:16:08,607] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:16:08,608] {logging_mixin.py:112} INFO - [2020-04-05 20:16:08,607] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:16:08,779] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:16:08,803] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.205 seconds
[2020-04-05 20:17:00,742] {scheduler_job.py:153} INFO - Started process (PID=16593) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:17:00,749] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:17:00,750] {logging_mixin.py:112} INFO - [2020-04-05 20:17:00,749] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:17:00,922] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:17:00,944] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.202 seconds
[2020-04-05 20:17:52,900] {scheduler_job.py:153} INFO - Started process (PID=16623) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:17:52,905] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:17:52,906] {logging_mixin.py:112} INFO - [2020-04-05 20:17:52,906] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:17:53,099] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:17:53,117] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.217 seconds
[2020-04-05 20:18:45,052] {scheduler_job.py:153} INFO - Started process (PID=16660) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:18:45,066] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:18:45,068] {logging_mixin.py:112} INFO - [2020-04-05 20:18:45,067] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:18:45,262] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:18:45,277] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.225 seconds
[2020-04-05 20:19:37,191] {scheduler_job.py:153} INFO - Started process (PID=16691) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:19:37,197] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:19:37,198] {logging_mixin.py:112} INFO - [2020-04-05 20:19:37,198] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:19:37,553] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:19:37,570] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.379 seconds
[2020-04-05 20:20:29,334] {scheduler_job.py:153} INFO - Started process (PID=16718) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:20:29,343] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:20:29,344] {logging_mixin.py:112} INFO - [2020-04-05 20:20:29,344] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:20:29,720] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:20:29,737] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.403 seconds
[2020-04-05 20:21:21,467] {scheduler_job.py:153} INFO - Started process (PID=16748) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:21:21,479] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:21:21,481] {logging_mixin.py:112} INFO - [2020-04-05 20:21:21,480] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:21:22,188] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:21:22,218] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.751 seconds
[2020-04-05 20:22:13,608] {scheduler_job.py:153} INFO - Started process (PID=16798) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:22:13,614] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:22:13,615] {logging_mixin.py:112} INFO - [2020-04-05 20:22:13,614] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:22:13,837] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:22:13,855] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.247 seconds
[2020-04-05 20:23:05,762] {scheduler_job.py:153} INFO - Started process (PID=16826) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:23:05,768] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:23:05,769] {logging_mixin.py:112} INFO - [2020-04-05 20:23:05,769] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:23:05,957] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:23:05,981] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.220 seconds
[2020-04-05 20:23:57,919] {scheduler_job.py:153} INFO - Started process (PID=16857) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:23:57,925] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:23:57,926] {logging_mixin.py:112} INFO - [2020-04-05 20:23:57,926] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:23:58,178] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:23:58,196] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.277 seconds
[2020-04-05 20:24:50,030] {scheduler_job.py:153} INFO - Started process (PID=16893) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:24:50,037] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:24:50,038] {logging_mixin.py:112} INFO - [2020-04-05 20:24:50,037] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:24:50,323] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:24:50,339] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.309 seconds
[2020-04-05 20:25:42,161] {scheduler_job.py:153} INFO - Started process (PID=16922) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:25:42,168] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:25:42,169] {logging_mixin.py:112} INFO - [2020-04-05 20:25:42,169] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:25:42,366] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:25:42,387] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.226 seconds
[2020-04-05 20:26:34,313] {scheduler_job.py:153} INFO - Started process (PID=16950) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:26:34,327] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:26:34,328] {logging_mixin.py:112} INFO - [2020-04-05 20:26:34,328] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:26:34,523] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:26:34,554] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.241 seconds
[2020-04-05 20:27:26,459] {scheduler_job.py:153} INFO - Started process (PID=16978) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:27:26,467] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:27:26,468] {logging_mixin.py:112} INFO - [2020-04-05 20:27:26,468] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:27:26,661] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:27:26,677] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.218 seconds
[2020-04-05 20:28:18,601] {scheduler_job.py:153} INFO - Started process (PID=17007) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:28:18,650] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:28:18,651] {logging_mixin.py:112} INFO - [2020-04-05 20:28:18,651] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:28:18,902] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:28:18,919] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.318 seconds
[2020-04-05 20:29:10,729] {scheduler_job.py:153} INFO - Started process (PID=17040) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:29:10,736] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:29:10,737] {logging_mixin.py:112} INFO - [2020-04-05 20:29:10,737] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:29:10,914] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:29:10,930] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.201 seconds
[2020-04-05 20:30:02,903] {scheduler_job.py:153} INFO - Started process (PID=17069) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:30:02,910] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:30:02,911] {logging_mixin.py:112} INFO - [2020-04-05 20:30:02,911] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:30:03,103] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:30:03,124] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.221 seconds
[2020-04-05 20:30:55,013] {scheduler_job.py:153} INFO - Started process (PID=17120) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:30:55,024] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:30:55,025] {logging_mixin.py:112} INFO - [2020-04-05 20:30:55,025] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:30:55,223] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:30:55,239] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.226 seconds
[2020-04-05 20:31:47,153] {scheduler_job.py:153} INFO - Started process (PID=17148) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:31:47,159] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:31:47,161] {logging_mixin.py:112} INFO - [2020-04-05 20:31:47,160] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:31:47,347] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:31:47,372] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.219 seconds
[2020-04-05 20:32:39,306] {scheduler_job.py:153} INFO - Started process (PID=17184) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:32:39,312] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:32:39,313] {logging_mixin.py:112} INFO - [2020-04-05 20:32:39,313] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:32:39,489] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:32:39,511] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.205 seconds
[2020-04-05 20:33:31,496] {scheduler_job.py:153} INFO - Started process (PID=17214) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:33:31,502] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:33:31,502] {logging_mixin.py:112} INFO - [2020-04-05 20:33:31,502] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:33:31,679] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:33:31,695] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.200 seconds
[2020-04-05 20:34:23,640] {scheduler_job.py:153} INFO - Started process (PID=17242) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:34:23,646] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:34:23,647] {logging_mixin.py:112} INFO - [2020-04-05 20:34:23,646] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:34:23,818] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:34:23,840] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.200 seconds
[2020-04-05 20:35:15,774] {scheduler_job.py:153} INFO - Started process (PID=17280) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:35:15,781] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:35:15,783] {logging_mixin.py:112} INFO - [2020-04-05 20:35:15,782] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:35:16,012] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:35:16,029] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.255 seconds
[2020-04-05 20:36:07,939] {scheduler_job.py:153} INFO - Started process (PID=17308) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:36:07,945] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:36:07,946] {logging_mixin.py:112} INFO - [2020-04-05 20:36:07,945] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:36:08,119] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:36:08,140] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.201 seconds
[2020-04-05 20:37:00,095] {scheduler_job.py:153} INFO - Started process (PID=17335) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:37:00,101] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:37:00,102] {logging_mixin.py:112} INFO - [2020-04-05 20:37:00,102] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:37:00,277] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:37:00,293] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.198 seconds
[2020-04-05 20:37:52,248] {scheduler_job.py:153} INFO - Started process (PID=17375) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:37:52,257] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:37:52,258] {logging_mixin.py:112} INFO - [2020-04-05 20:37:52,258] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:37:52,468] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:37:52,486] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.239 seconds
[2020-04-05 20:38:44,396] {scheduler_job.py:153} INFO - Started process (PID=17405) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:38:44,402] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:38:44,403] {logging_mixin.py:112} INFO - [2020-04-05 20:38:44,402] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:38:44,813] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:38:44,831] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.435 seconds
[2020-04-05 20:39:36,516] {scheduler_job.py:153} INFO - Started process (PID=17439) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:39:36,523] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:39:36,524] {logging_mixin.py:112} INFO - [2020-04-05 20:39:36,523] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:39:36,778] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:39:36,794] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.278 seconds
[2020-04-05 20:40:28,646] {scheduler_job.py:153} INFO - Started process (PID=17475) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:40:28,654] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:40:28,655] {logging_mixin.py:112} INFO - [2020-04-05 20:40:28,655] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:40:28,863] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:40:28,879] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.233 seconds
[2020-04-05 20:41:20,804] {scheduler_job.py:153} INFO - Started process (PID=17506) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:41:20,810] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:41:20,811] {logging_mixin.py:112} INFO - [2020-04-05 20:41:20,810] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:41:20,984] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:41:21,002] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.198 seconds
[2020-04-05 20:42:12,957] {scheduler_job.py:153} INFO - Started process (PID=17534) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:42:12,963] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:42:12,964] {logging_mixin.py:112} INFO - [2020-04-05 20:42:12,964] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:42:13,159] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:42:13,181] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.224 seconds
[2020-04-05 20:43:05,102] {scheduler_job.py:153} INFO - Started process (PID=17562) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:43:05,109] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:43:05,110] {logging_mixin.py:112} INFO - [2020-04-05 20:43:05,109] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:43:05,322] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:43:05,336] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.234 seconds
[2020-04-05 20:43:57,266] {scheduler_job.py:153} INFO - Started process (PID=17596) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:43:57,271] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:43:57,272] {logging_mixin.py:112} INFO - [2020-04-05 20:43:57,272] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:43:57,445] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:43:57,467] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.202 seconds
[2020-04-05 20:44:49,401] {scheduler_job.py:153} INFO - Started process (PID=17624) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:44:49,415] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:44:49,416] {logging_mixin.py:112} INFO - [2020-04-05 20:44:49,415] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:44:49,595] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:44:49,618] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.217 seconds
[2020-04-05 20:45:41,553] {scheduler_job.py:153} INFO - Started process (PID=17652) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:45:41,561] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:45:41,562] {logging_mixin.py:112} INFO - [2020-04-05 20:45:41,562] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:45:41,742] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:45:41,764] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.211 seconds
[2020-04-05 20:46:33,710] {scheduler_job.py:153} INFO - Started process (PID=17680) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:46:33,716] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:46:33,717] {logging_mixin.py:112} INFO - [2020-04-05 20:46:33,717] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:46:33,891] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:46:33,907] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.197 seconds
[2020-04-05 20:47:25,851] {scheduler_job.py:153} INFO - Started process (PID=17707) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:47:25,858] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:47:25,858] {logging_mixin.py:112} INFO - [2020-04-05 20:47:25,858] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:47:26,034] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:47:26,057] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.206 seconds
[2020-04-05 20:48:18,001] {scheduler_job.py:153} INFO - Started process (PID=17735) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:48:18,007] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:48:18,008] {logging_mixin.py:112} INFO - [2020-04-05 20:48:18,008] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:48:18,187] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:48:18,205] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.204 seconds
[2020-04-05 20:49:10,126] {scheduler_job.py:153} INFO - Started process (PID=17772) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:49:10,133] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:49:10,134] {logging_mixin.py:112} INFO - [2020-04-05 20:49:10,133] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:49:10,319] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:49:10,336] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.210 seconds
[2020-04-05 20:50:02,344] {scheduler_job.py:153} INFO - Started process (PID=17799) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:50:02,350] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:50:02,350] {logging_mixin.py:112} INFO - [2020-04-05 20:50:02,350] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:50:02,523] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:50:02,546] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.202 seconds
[2020-04-05 20:50:54,687] {scheduler_job.py:153} INFO - Started process (PID=17827) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:50:54,693] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:50:54,694] {logging_mixin.py:112} INFO - [2020-04-05 20:50:54,693] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:50:54,867] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:50:54,890] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.203 seconds
[2020-04-05 20:51:47,011] {scheduler_job.py:153} INFO - Started process (PID=17855) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:51:47,018] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:51:47,020] {logging_mixin.py:112} INFO - [2020-04-05 20:51:47,019] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:51:47,200] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:51:47,222] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.211 seconds
[2020-04-05 20:52:39,153] {scheduler_job.py:153} INFO - Started process (PID=17883) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:52:39,168] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:52:39,170] {logging_mixin.py:112} INFO - [2020-04-05 20:52:39,169] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:52:39,398] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:52:39,415] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.262 seconds
[2020-04-05 20:53:31,301] {scheduler_job.py:153} INFO - Started process (PID=17910) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:53:31,310] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:53:31,311] {logging_mixin.py:112} INFO - [2020-04-05 20:53:31,311] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:53:31,538] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:53:31,561] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.260 seconds
[2020-04-05 20:54:23,455] {scheduler_job.py:153} INFO - Started process (PID=17938) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:54:23,461] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:54:23,462] {logging_mixin.py:112} INFO - [2020-04-05 20:54:23,462] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:54:23,637] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:54:23,662] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.207 seconds
[2020-04-05 20:55:15,608] {scheduler_job.py:153} INFO - Started process (PID=17970) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:55:15,615] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:55:15,616] {logging_mixin.py:112} INFO - [2020-04-05 20:55:15,616] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:55:15,834] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:55:15,851] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.242 seconds
[2020-04-05 20:56:07,731] {scheduler_job.py:153} INFO - Started process (PID=18000) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:56:07,738] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:56:07,739] {logging_mixin.py:112} INFO - [2020-04-05 20:56:07,738] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:56:07,933] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:56:07,963] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.232 seconds
[2020-04-05 20:56:59,885] {scheduler_job.py:153} INFO - Started process (PID=18028) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:56:59,897] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:56:59,898] {logging_mixin.py:112} INFO - [2020-04-05 20:56:59,897] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:57:00,088] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:57:00,115] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.230 seconds
[2020-04-05 20:57:52,021] {scheduler_job.py:153} INFO - Started process (PID=18063) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:57:52,027] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-05 20:57:52,028] {logging_mixin.py:112} INFO - [2020-04-05 20:57:52,028] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:57:52,432] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-05 20:57:52,455] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.434 seconds
[2020-04-06 08:16:35,025] {scheduler_job.py:153} INFO - Started process (PID=19058) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:16:35,046] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:16:35,048] {logging_mixin.py:112} INFO - [2020-04-06 08:16:35,047] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:16:35,312] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:16:35,325] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.301 seconds
[2020-04-06 08:17:29,155] {scheduler_job.py:153} INFO - Started process (PID=19087) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:17:29,162] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:17:29,163] {logging_mixin.py:112} INFO - [2020-04-06 08:17:29,163] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:17:29,411] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:17:29,434] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:17:29,452] {scheduler_job.py:1292} INFO - Created <DagRun atp_data01 @ 2020-04-05 00:00:00+00:00: scheduled__2020-04-05T00:00:00+00:00, externally triggered: False>
[2020-04-06 08:17:29,455] {scheduler_job.py:757} INFO - Examining DAG run <DagRun atp_data01 @ 2020-04-05 00:00:00+00:00: scheduled__2020-04-05T00:00:00+00:00, externally triggered: False>
[2020-04-06 08:17:29,462] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:17:29,465] {scheduler_job.py:1634} INFO - Creating / updating <TaskInstance: atp_data01.run_kaggle_api 2020-04-05 00:00:00+00:00 [scheduled]> in ORM
[2020-04-06 08:17:29,471] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.316 seconds
[2020-04-06 08:18:34,642] {scheduler_job.py:153} INFO - Started process (PID=19126) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:18:34,651] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:18:34,652] {logging_mixin.py:112} INFO - [2020-04-06 08:18:34,652] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:18:34,945] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:18:34,962] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:18:34,969] {scheduler_job.py:757} INFO - Examining DAG run <DagRun atp_data01 @ 2020-04-05 00:00:00+00:00: scheduled__2020-04-05T00:00:00+00:00, externally triggered: False>
[2020-04-06 08:18:34,975] {logging_mixin.py:112} INFO - [2020-04-06 08:18:34,975] {dagrun.py:318} INFO - Marking run <DagRun atp_data01 @ 2020-04-05 00:00:00+00:00: scheduled__2020-04-05T00:00:00+00:00, externally triggered: False> successful
[2020-04-06 08:18:34,978] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:18:34,980] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.338 seconds
[2020-04-06 08:19:28,779] {scheduler_job.py:153} INFO - Started process (PID=19156) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:19:28,785] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:19:28,786] {logging_mixin.py:112} INFO - [2020-04-06 08:19:28,785] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:19:29,033] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:19:29,060] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:19:29,068] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:19:29,070] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.292 seconds
[2020-04-06 08:20:22,921] {scheduler_job.py:153} INFO - Started process (PID=19185) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:20:22,927] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:20:22,928] {logging_mixin.py:112} INFO - [2020-04-06 08:20:22,928] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:20:23,192] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:20:23,222] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:20:23,232] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:20:23,234] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.313 seconds
[2020-04-06 08:21:17,064] {scheduler_job.py:153} INFO - Started process (PID=19214) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:21:17,078] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:21:17,079] {logging_mixin.py:112} INFO - [2020-04-06 08:21:17,079] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:21:17,338] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:21:17,366] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:21:17,374] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:21:17,376] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.313 seconds
[2020-04-06 08:22:12,265] {scheduler_job.py:153} INFO - Started process (PID=19243) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:22:12,272] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:22:12,274] {logging_mixin.py:112} INFO - [2020-04-06 08:22:12,273] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:22:12,543] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:22:12,567] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:22:12,575] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:22:12,577] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.312 seconds
[2020-04-06 08:23:05,379] {scheduler_job.py:153} INFO - Started process (PID=19273) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:23:05,385] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:23:05,386] {logging_mixin.py:112} INFO - [2020-04-06 08:23:05,386] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:23:05,635] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:23:05,661] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:23:05,670] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:23:05,672] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.293 seconds
[2020-04-06 08:23:59,508] {scheduler_job.py:153} INFO - Started process (PID=19306) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:23:59,514] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:23:59,515] {logging_mixin.py:112} INFO - [2020-04-06 08:23:59,514] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:23:59,803] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:23:59,830] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:23:59,840] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:23:59,842] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.334 seconds
[2020-04-06 08:24:53,663] {scheduler_job.py:153} INFO - Started process (PID=19337) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:24:53,669] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:24:53,671] {logging_mixin.py:112} INFO - [2020-04-06 08:24:53,670] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:24:53,933] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:24:53,960] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:24:53,968] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:24:53,971] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.307 seconds
[2020-04-06 08:25:47,806] {scheduler_job.py:153} INFO - Started process (PID=19367) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:25:47,817] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:25:47,818] {logging_mixin.py:112} INFO - [2020-04-06 08:25:47,817] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:25:48,061] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:25:48,079] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:25:48,086] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:25:48,088] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.283 seconds
[2020-04-06 08:26:41,957] {scheduler_job.py:153} INFO - Started process (PID=19397) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:26:41,963] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:26:41,964] {logging_mixin.py:112} INFO - [2020-04-06 08:26:41,964] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:26:42,265] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:26:42,282] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:26:42,289] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:26:42,292] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.334 seconds
[2020-04-06 08:27:36,123] {scheduler_job.py:153} INFO - Started process (PID=19426) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:27:36,130] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:27:36,131] {logging_mixin.py:112} INFO - [2020-04-06 08:27:36,130] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:27:36,446] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:27:36,471] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:27:36,478] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:27:36,481] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.358 seconds
[2020-04-06 08:28:30,282] {scheduler_job.py:153} INFO - Started process (PID=19455) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:28:30,288] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:28:30,290] {logging_mixin.py:112} INFO - [2020-04-06 08:28:30,289] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:28:30,583] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:28:30,600] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:28:30,607] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:28:30,609] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.328 seconds
[2020-04-06 08:29:24,437] {scheduler_job.py:153} INFO - Started process (PID=19505) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:29:24,474] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:29:24,477] {logging_mixin.py:112} INFO - [2020-04-06 08:29:24,477] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:29:25,072] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:29:25,116] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:29:25,130] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:29:25,134] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.697 seconds
[2020-04-06 08:30:18,653] {scheduler_job.py:153} INFO - Started process (PID=19544) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:30:18,662] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:30:18,663] {logging_mixin.py:112} INFO - [2020-04-06 08:30:18,663] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:30:18,907] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:30:18,926] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:30:18,937] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:30:18,939] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.286 seconds
[2020-04-06 08:31:12,796] {scheduler_job.py:153} INFO - Started process (PID=19584) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:31:12,802] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:31:12,803] {logging_mixin.py:112} INFO - [2020-04-06 08:31:12,803] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:31:13,034] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:31:13,059] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:31:13,067] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:31:13,069] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.272 seconds
[2020-04-06 08:32:06,985] {scheduler_job.py:153} INFO - Started process (PID=19613) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:32:06,991] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:32:06,992] {logging_mixin.py:112} INFO - [2020-04-06 08:32:06,992] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:32:07,231] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:32:07,253] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:32:07,260] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:32:07,262] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.277 seconds
[2020-04-06 08:33:01,140] {scheduler_job.py:153} INFO - Started process (PID=19643) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:33:01,147] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:33:01,148] {logging_mixin.py:112} INFO - [2020-04-06 08:33:01,147] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:33:01,397] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:33:01,423] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:33:01,431] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:33:01,433] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.293 seconds
[2020-04-06 08:33:55,315] {scheduler_job.py:153} INFO - Started process (PID=19676) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:33:55,321] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:33:55,322] {logging_mixin.py:112} INFO - [2020-04-06 08:33:55,322] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:33:55,572] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:33:55,600] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:33:55,610] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:33:55,612] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.297 seconds
[2020-04-06 08:34:49,474] {scheduler_job.py:153} INFO - Started process (PID=19706) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:34:49,480] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:34:49,481] {logging_mixin.py:112} INFO - [2020-04-06 08:34:49,481] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:34:49,724] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:34:49,751] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:34:49,759] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:34:49,761] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.287 seconds
[2020-04-06 08:35:43,634] {scheduler_job.py:153} INFO - Started process (PID=19737) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:35:43,642] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:35:43,643] {logging_mixin.py:112} INFO - [2020-04-06 08:35:43,643] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:35:43,906] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:35:43,930] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:35:43,939] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:35:43,941] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.307 seconds
[2020-04-06 08:36:37,855] {scheduler_job.py:153} INFO - Started process (PID=19767) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:36:37,862] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:36:37,864] {logging_mixin.py:112} INFO - [2020-04-06 08:36:37,863] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:36:38,168] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:36:38,189] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:36:38,198] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:36:38,200] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.346 seconds
[2020-04-06 08:37:31,933] {scheduler_job.py:153} INFO - Started process (PID=19804) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:37:31,939] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:37:31,940] {logging_mixin.py:112} INFO - [2020-04-06 08:37:31,939] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:37:32,187] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:37:32,210] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:37:32,218] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:37:32,223] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.290 seconds
[2020-04-06 08:38:26,099] {scheduler_job.py:153} INFO - Started process (PID=19834) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:38:26,106] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:38:26,107] {logging_mixin.py:112} INFO - [2020-04-06 08:38:26,107] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:38:26,337] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:38:26,362] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:38:26,371] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:38:26,373] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.274 seconds
[2020-04-06 08:39:20,220] {scheduler_job.py:153} INFO - Started process (PID=19863) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:39:20,226] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:39:20,227] {logging_mixin.py:112} INFO - [2020-04-06 08:39:20,226] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:39:20,458] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:39:20,485] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:39:20,494] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:39:20,496] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.276 seconds
[2020-04-06 08:40:14,375] {scheduler_job.py:153} INFO - Started process (PID=19895) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:40:14,382] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:40:14,383] {logging_mixin.py:112} INFO - [2020-04-06 08:40:14,383] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:40:14,629] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:40:14,658] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:40:14,667] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:40:14,669] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.294 seconds
[2020-04-06 08:41:08,535] {scheduler_job.py:153} INFO - Started process (PID=19934) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:41:08,540] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:41:08,541] {logging_mixin.py:112} INFO - [2020-04-06 08:41:08,541] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:41:08,775] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:41:08,800] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:41:08,808] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:41:08,810] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.275 seconds
[2020-04-06 08:42:02,676] {scheduler_job.py:153} INFO - Started process (PID=19963) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:42:02,682] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:42:02,683] {logging_mixin.py:112} INFO - [2020-04-06 08:42:02,683] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:42:02,928] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:42:02,955] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:42:02,964] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:42:02,966] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.290 seconds
[2020-04-06 08:42:56,800] {scheduler_job.py:153} INFO - Started process (PID=19996) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:42:56,808] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:42:56,809] {logging_mixin.py:112} INFO - [2020-04-06 08:42:56,809] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:42:57,052] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:42:57,079] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:42:57,087] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:42:57,089] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.289 seconds
[2020-04-06 08:43:50,935] {scheduler_job.py:153} INFO - Started process (PID=20029) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:43:50,941] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:43:50,941] {logging_mixin.py:112} INFO - [2020-04-06 08:43:50,941] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:43:51,213] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:43:51,230] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:43:51,237] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:43:51,239] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.305 seconds
[2020-04-06 08:44:45,068] {scheduler_job.py:153} INFO - Started process (PID=20061) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:44:45,074] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:44:45,075] {logging_mixin.py:112} INFO - [2020-04-06 08:44:45,075] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:44:45,314] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:44:45,339] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:44:45,347] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:44:45,349] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.281 seconds
[2020-04-06 08:45:39,236] {scheduler_job.py:153} INFO - Started process (PID=20100) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:45:39,241] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:45:39,242] {logging_mixin.py:112} INFO - [2020-04-06 08:45:39,241] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:45:39,495] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:45:39,512] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:45:39,520] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:45:39,522] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.286 seconds
[2020-04-06 08:46:33,393] {scheduler_job.py:153} INFO - Started process (PID=20133) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:46:33,403] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:46:33,405] {logging_mixin.py:112} INFO - [2020-04-06 08:46:33,404] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:46:33,870] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:46:33,887] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:46:33,896] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:46:33,898] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.505 seconds
[2020-04-06 08:47:27,522] {scheduler_job.py:153} INFO - Started process (PID=20162) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:47:27,535] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:47:27,536] {logging_mixin.py:112} INFO - [2020-04-06 08:47:27,535] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:47:27,778] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:47:27,803] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:47:27,812] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:47:27,814] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.292 seconds
[2020-04-06 08:48:21,690] {scheduler_job.py:153} INFO - Started process (PID=20191) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:48:21,696] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:48:21,697] {logging_mixin.py:112} INFO - [2020-04-06 08:48:21,696] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:48:21,962] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:48:21,988] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:48:21,996] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:48:21,998] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.309 seconds
[2020-04-06 08:49:15,830] {scheduler_job.py:153} INFO - Started process (PID=20219) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:49:15,836] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:49:15,837] {logging_mixin.py:112} INFO - [2020-04-06 08:49:15,837] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:49:16,073] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:49:16,100] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:49:16,107] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:49:16,109] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.280 seconds
[2020-04-06 08:50:09,995] {scheduler_job.py:153} INFO - Started process (PID=20249) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:50:10,001] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:50:10,002] {logging_mixin.py:112} INFO - [2020-04-06 08:50:10,002] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:50:10,239] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:50:10,264] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:50:10,272] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:50:10,274] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.279 seconds
[2020-04-06 08:51:04,171] {scheduler_job.py:153} INFO - Started process (PID=20281) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:51:04,178] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:51:04,179] {logging_mixin.py:112} INFO - [2020-04-06 08:51:04,179] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:51:04,433] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:51:04,459] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:51:04,467] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:51:04,469] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.298 seconds
[2020-04-06 08:51:58,310] {scheduler_job.py:153} INFO - Started process (PID=20310) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:51:58,316] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:51:58,317] {logging_mixin.py:112} INFO - [2020-04-06 08:51:58,317] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:51:58,597] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:51:58,621] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:51:58,631] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:51:58,633] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.323 seconds
[2020-04-06 08:52:52,460] {scheduler_job.py:153} INFO - Started process (PID=20342) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:52:52,473] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:52:52,476] {logging_mixin.py:112} INFO - [2020-04-06 08:52:52,475] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:52:52,767] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:52:52,792] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:52:52,799] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:52:52,801] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.341 seconds
[2020-04-06 08:53:46,594] {scheduler_job.py:153} INFO - Started process (PID=20370) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:53:46,603] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:53:46,605] {logging_mixin.py:112} INFO - [2020-04-06 08:53:46,604] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:53:46,870] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:53:46,897] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:53:46,906] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:53:46,908] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.314 seconds
[2020-04-06 08:54:40,735] {scheduler_job.py:153} INFO - Started process (PID=20402) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:54:40,748] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:54:40,749] {logging_mixin.py:112} INFO - [2020-04-06 08:54:40,749] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:54:40,997] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:54:41,025] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:54:41,034] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:54:41,036] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.301 seconds
[2020-04-06 08:55:34,909] {scheduler_job.py:153} INFO - Started process (PID=20431) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:55:34,915] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:55:34,916] {logging_mixin.py:112} INFO - [2020-04-06 08:55:34,916] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:55:35,199] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:55:35,218] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:55:35,226] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:55:35,228] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.319 seconds
[2020-04-06 08:56:29,060] {scheduler_job.py:153} INFO - Started process (PID=20460) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:56:29,066] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:56:29,068] {logging_mixin.py:112} INFO - [2020-04-06 08:56:29,067] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:56:29,326] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:56:29,352] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:56:29,360] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:56:29,362] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.302 seconds
[2020-04-06 08:57:23,239] {scheduler_job.py:153} INFO - Started process (PID=20492) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:57:23,245] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:57:23,246] {logging_mixin.py:112} INFO - [2020-04-06 08:57:23,246] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:57:23,492] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:57:23,511] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:57:23,519] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:57:23,521] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.282 seconds
[2020-04-06 08:58:17,353] {scheduler_job.py:153} INFO - Started process (PID=20520) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:58:17,366] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:58:17,367] {logging_mixin.py:112} INFO - [2020-04-06 08:58:17,367] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:58:17,608] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:58:17,635] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:58:17,643] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:58:17,646] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.293 seconds
[2020-04-06 08:59:11,493] {scheduler_job.py:153} INFO - Started process (PID=20550) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:59:11,507] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 08:59:11,509] {logging_mixin.py:112} INFO - [2020-04-06 08:59:11,508] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:59:11,757] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 08:59:11,774] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 08:59:11,782] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 08:59:11,784] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.291 seconds
[2020-04-06 09:00:05,634] {scheduler_job.py:153} INFO - Started process (PID=20580) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:00:05,645] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:00:05,647] {logging_mixin.py:112} INFO - [2020-04-06 09:00:05,646] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:00:05,954] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:00:05,973] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:00:05,984] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:00:05,986] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.352 seconds
[2020-04-06 09:00:59,792] {scheduler_job.py:153} INFO - Started process (PID=20609) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:00:59,802] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:00:59,803] {logging_mixin.py:112} INFO - [2020-04-06 09:00:59,802] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:01:00,071] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:01:00,089] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:01:00,100] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:01:00,103] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.311 seconds
[2020-04-06 09:01:53,937] {scheduler_job.py:153} INFO - Started process (PID=20638) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:01:53,944] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:01:53,945] {logging_mixin.py:112} INFO - [2020-04-06 09:01:53,945] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:01:54,191] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:01:54,233] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:01:54,242] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:01:54,244] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.307 seconds
[2020-04-06 09:02:48,090] {scheduler_job.py:153} INFO - Started process (PID=20666) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:02:48,098] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:02:48,099] {logging_mixin.py:112} INFO - [2020-04-06 09:02:48,099] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:02:48,345] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:02:48,366] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:02:48,374] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:02:48,376] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.287 seconds
[2020-04-06 09:03:42,246] {scheduler_job.py:153} INFO - Started process (PID=20707) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:03:42,254] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:03:42,256] {logging_mixin.py:112} INFO - [2020-04-06 09:03:42,255] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:03:42,612] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:03:42,646] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:03:42,656] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:03:42,659] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.414 seconds
[2020-04-06 09:04:36,438] {scheduler_job.py:153} INFO - Started process (PID=20749) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:04:36,444] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:04:36,446] {logging_mixin.py:112} INFO - [2020-04-06 09:04:36,445] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:04:36,749] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:04:36,772] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:04:36,787] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:04:36,789] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.351 seconds
[2020-04-06 09:05:30,608] {scheduler_job.py:153} INFO - Started process (PID=20781) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:05:30,615] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:05:30,618] {logging_mixin.py:112} INFO - [2020-04-06 09:05:30,616] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:05:30,915] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:05:30,939] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:05:30,950] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:05:30,954] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.346 seconds
[2020-04-06 09:06:24,786] {scheduler_job.py:153} INFO - Started process (PID=20811) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:06:24,801] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:06:24,802] {logging_mixin.py:112} INFO - [2020-04-06 09:06:24,802] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:06:25,109] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:06:25,132] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:06:25,142] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:06:25,146] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.361 seconds
[2020-04-06 09:07:18,968] {scheduler_job.py:153} INFO - Started process (PID=20840) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:07:18,978] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:07:18,979] {logging_mixin.py:112} INFO - [2020-04-06 09:07:18,978] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:07:19,279] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:07:19,307] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:07:19,315] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:07:19,317] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.349 seconds
[2020-04-06 09:08:13,129] {scheduler_job.py:153} INFO - Started process (PID=20869) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:08:13,139] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:08:13,140] {logging_mixin.py:112} INFO - [2020-04-06 09:08:13,140] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:08:13,449] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:08:13,479] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:08:13,486] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:08:13,489] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.359 seconds
[2020-04-06 09:09:07,317] {scheduler_job.py:153} INFO - Started process (PID=20899) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:09:07,325] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:09:07,326] {logging_mixin.py:112} INFO - [2020-04-06 09:09:07,326] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:09:07,642] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:09:07,669] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:09:07,683] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:09:07,686] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.368 seconds
[2020-04-06 09:10:01,467] {scheduler_job.py:153} INFO - Started process (PID=20928) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:10:01,473] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:10:01,474] {logging_mixin.py:112} INFO - [2020-04-06 09:10:01,474] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:10:01,769] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:10:01,791] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:10:01,800] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:10:01,802] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.335 seconds
[2020-04-06 09:10:55,690] {scheduler_job.py:153} INFO - Started process (PID=20966) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:10:55,703] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:10:55,704] {logging_mixin.py:112} INFO - [2020-04-06 09:10:55,704] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:10:56,072] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:10:56,120] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:10:56,135] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:10:56,140] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.450 seconds
[2020-04-06 09:11:49,844] {scheduler_job.py:153} INFO - Started process (PID=20997) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:11:49,853] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:11:49,854] {logging_mixin.py:112} INFO - [2020-04-06 09:11:49,854] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:11:50,123] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:11:50,142] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:11:50,150] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:11:50,152] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.308 seconds
[2020-04-06 09:12:44,001] {scheduler_job.py:153} INFO - Started process (PID=21025) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:12:44,009] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:12:44,010] {logging_mixin.py:112} INFO - [2020-04-06 09:12:44,010] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:12:44,315] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:12:44,366] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:12:44,374] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:12:44,377] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.376 seconds
[2020-04-06 09:13:38,183] {scheduler_job.py:153} INFO - Started process (PID=21057) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:13:38,190] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:13:38,192] {logging_mixin.py:112} INFO - [2020-04-06 09:13:38,191] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:13:38,547] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:13:38,586] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:13:38,606] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:13:38,610] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.426 seconds
[2020-04-06 09:14:32,338] {scheduler_job.py:153} INFO - Started process (PID=21094) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:14:32,350] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:14:32,351] {logging_mixin.py:112} INFO - [2020-04-06 09:14:32,350] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:14:32,642] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:14:32,671] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:14:32,681] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:14:32,683] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.345 seconds
[2020-04-06 09:15:26,511] {scheduler_job.py:153} INFO - Started process (PID=21126) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:15:26,517] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:15:26,518] {logging_mixin.py:112} INFO - [2020-04-06 09:15:26,517] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:15:26,840] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:15:26,859] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:15:26,870] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:15:26,872] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.362 seconds
[2020-04-06 09:16:20,690] {scheduler_job.py:153} INFO - Started process (PID=21155) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:16:20,697] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:16:20,698] {logging_mixin.py:112} INFO - [2020-04-06 09:16:20,698] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:16:20,989] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:16:21,006] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:16:21,023] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:16:21,025] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.336 seconds
[2020-04-06 09:17:14,884] {scheduler_job.py:153} INFO - Started process (PID=21183) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:17:14,890] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:17:14,890] {logging_mixin.py:112} INFO - [2020-04-06 09:17:14,890] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:17:15,177] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:17:15,205] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:17:15,214] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:17:15,217] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.333 seconds
[2020-04-06 09:18:09,058] {scheduler_job.py:153} INFO - Started process (PID=21212) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:18:09,065] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:18:09,066] {logging_mixin.py:112} INFO - [2020-04-06 09:18:09,065] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:18:09,352] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:18:09,372] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:18:09,381] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:18:09,386] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.328 seconds
[2020-04-06 09:19:03,208] {scheduler_job.py:153} INFO - Started process (PID=21242) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:19:03,217] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:19:03,218] {logging_mixin.py:112} INFO - [2020-04-06 09:19:03,218] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:19:03,560] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:19:03,600] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:19:03,617] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:19:03,619] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.411 seconds
[2020-04-06 09:19:57,383] {scheduler_job.py:153} INFO - Started process (PID=21271) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:19:57,396] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:19:57,397] {logging_mixin.py:112} INFO - [2020-04-06 09:19:57,397] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:19:57,684] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:19:57,711] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:19:57,722] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:19:57,729] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.346 seconds
[2020-04-06 09:20:51,559] {scheduler_job.py:153} INFO - Started process (PID=21300) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:20:51,572] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:20:51,573] {logging_mixin.py:112} INFO - [2020-04-06 09:20:51,573] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:20:51,890] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:20:51,918] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:20:51,940] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:20:51,944] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.385 seconds
[2020-04-06 09:21:45,716] {scheduler_job.py:153} INFO - Started process (PID=21329) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:21:45,723] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:21:45,724] {logging_mixin.py:112} INFO - [2020-04-06 09:21:45,724] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:21:46,056] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:21:46,083] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:21:46,091] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:21:46,093] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.378 seconds
[2020-04-06 09:22:39,897] {scheduler_job.py:153} INFO - Started process (PID=21358) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:22:39,910] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:22:39,910] {logging_mixin.py:112} INFO - [2020-04-06 09:22:39,910] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:22:40,195] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:22:40,227] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:22:40,235] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:22:40,238] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.341 seconds
[2020-04-06 09:23:34,058] {scheduler_job.py:153} INFO - Started process (PID=21387) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:23:34,065] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:23:34,081] {logging_mixin.py:112} INFO - [2020-04-06 09:23:34,081] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:23:34,390] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:23:34,413] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:23:34,425] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:23:34,427] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.369 seconds
[2020-04-06 09:24:28,236] {scheduler_job.py:153} INFO - Started process (PID=21416) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:24:28,249] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:24:28,252] {logging_mixin.py:112} INFO - [2020-04-06 09:24:28,251] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:24:28,533] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:24:28,561] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:24:28,569] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:24:28,571] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.335 seconds
[2020-04-06 09:25:22,439] {scheduler_job.py:153} INFO - Started process (PID=21446) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:25:22,445] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:25:22,446] {logging_mixin.py:112} INFO - [2020-04-06 09:25:22,446] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:25:22,734] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:25:22,752] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:25:22,761] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:25:22,763] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.325 seconds
[2020-04-06 09:26:16,599] {scheduler_job.py:153} INFO - Started process (PID=21474) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:26:16,605] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:26:16,606] {logging_mixin.py:112} INFO - [2020-04-06 09:26:16,606] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:26:16,913] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:26:16,940] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:26:16,950] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:26:16,952] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.352 seconds
[2020-04-06 09:27:10,783] {scheduler_job.py:153} INFO - Started process (PID=21505) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:27:10,790] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:27:10,791] {logging_mixin.py:112} INFO - [2020-04-06 09:27:10,791] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:27:11,111] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:27:11,144] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:27:11,152] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:27:11,155] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.372 seconds
[2020-04-06 09:28:04,947] {scheduler_job.py:153} INFO - Started process (PID=21534) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:28:04,953] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:28:04,954] {logging_mixin.py:112} INFO - [2020-04-06 09:28:04,954] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:28:05,472] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:28:05,520] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:28:05,538] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:28:05,543] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.597 seconds
[2020-04-06 09:28:59,178] {scheduler_job.py:153} INFO - Started process (PID=21566) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:28:59,191] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:28:59,193] {logging_mixin.py:112} INFO - [2020-04-06 09:28:59,192] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:28:59,577] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:28:59,615] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:28:59,626] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:28:59,631] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.453 seconds
[2020-04-06 09:29:53,358] {scheduler_job.py:153} INFO - Started process (PID=21595) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:29:53,364] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:29:53,365] {logging_mixin.py:112} INFO - [2020-04-06 09:29:53,364] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:29:53,685] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:29:53,705] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:29:53,712] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:29:53,715] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.358 seconds
[2020-04-06 09:30:47,522] {scheduler_job.py:153} INFO - Started process (PID=21625) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:30:47,529] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:30:47,530] {logging_mixin.py:112} INFO - [2020-04-06 09:30:47,529] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:30:47,813] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:30:47,842] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:30:47,855] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:30:47,857] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.335 seconds
[2020-04-06 09:31:41,701] {scheduler_job.py:153} INFO - Started process (PID=21656) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:31:41,709] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:31:41,711] {logging_mixin.py:112} INFO - [2020-04-06 09:31:41,710] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:31:42,031] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:31:42,059] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:31:42,069] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:31:42,071] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.370 seconds
[2020-04-06 09:32:35,879] {scheduler_job.py:153} INFO - Started process (PID=21685) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:32:35,891] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:32:35,892] {logging_mixin.py:112} INFO - [2020-04-06 09:32:35,891] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:32:36,177] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:32:36,206] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:32:36,215] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:32:36,218] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.339 seconds
[2020-04-06 09:33:30,060] {scheduler_job.py:153} INFO - Started process (PID=21714) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:33:30,073] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:33:30,075] {logging_mixin.py:112} INFO - [2020-04-06 09:33:30,074] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:33:30,415] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:33:30,449] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:33:30,458] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:33:30,461] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.401 seconds
[2020-04-06 09:34:24,247] {scheduler_job.py:153} INFO - Started process (PID=21753) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:34:24,255] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:34:24,256] {logging_mixin.py:112} INFO - [2020-04-06 09:34:24,256] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:34:24,631] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:34:24,660] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:34:24,677] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:34:24,679] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.432 seconds
[2020-04-06 09:35:18,415] {scheduler_job.py:153} INFO - Started process (PID=21785) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:35:18,422] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:35:18,423] {logging_mixin.py:112} INFO - [2020-04-06 09:35:18,422] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:35:18,727] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:35:18,750] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:35:18,758] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:35:18,760] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.345 seconds
[2020-04-06 09:36:12,588] {scheduler_job.py:153} INFO - Started process (PID=21816) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:36:12,602] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:36:12,609] {logging_mixin.py:112} INFO - [2020-04-06 09:36:12,608] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:36:12,915] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:36:12,942] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:36:12,951] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:36:12,953] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.365 seconds
[2020-04-06 09:37:06,762] {scheduler_job.py:153} INFO - Started process (PID=21863) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:37:06,768] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:37:06,770] {logging_mixin.py:112} INFO - [2020-04-06 09:37:06,769] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:37:07,067] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:37:07,085] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:37:07,093] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:37:07,096] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.335 seconds
[2020-04-06 09:38:00,929] {scheduler_job.py:153} INFO - Started process (PID=21893) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:38:00,935] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:38:00,937] {logging_mixin.py:112} INFO - [2020-04-06 09:38:00,936] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:38:01,262] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:38:01,286] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:38:01,296] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:38:01,298] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.369 seconds
[2020-04-06 09:38:55,111] {scheduler_job.py:153} INFO - Started process (PID=21922) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:38:55,139] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:38:55,140] {logging_mixin.py:112} INFO - [2020-04-06 09:38:55,139] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:38:55,575] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:38:55,604] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:38:55,612] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:38:55,614] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.503 seconds
[2020-04-06 09:39:49,272] {scheduler_job.py:153} INFO - Started process (PID=21958) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:39:49,278] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:39:49,279] {logging_mixin.py:112} INFO - [2020-04-06 09:39:49,279] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:39:49,580] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:39:49,606] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:39:49,618] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:39:49,623] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.351 seconds
[2020-04-06 09:40:43,454] {scheduler_job.py:153} INFO - Started process (PID=21991) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:40:43,464] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:40:43,470] {logging_mixin.py:112} INFO - [2020-04-06 09:40:43,468] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:40:43,761] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:40:43,781] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:40:43,789] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:40:43,792] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.338 seconds
[2020-04-06 09:41:37,619] {scheduler_job.py:153} INFO - Started process (PID=22022) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:41:37,625] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:41:37,627] {logging_mixin.py:112} INFO - [2020-04-06 09:41:37,626] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:41:37,918] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:41:37,943] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:41:37,953] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:41:37,956] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.337 seconds
[2020-04-06 09:42:31,796] {scheduler_job.py:153} INFO - Started process (PID=22055) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:42:31,804] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:42:31,806] {logging_mixin.py:112} INFO - [2020-04-06 09:42:31,806] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:42:32,110] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:42:32,129] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:42:32,144] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:42:32,148] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.352 seconds
[2020-04-06 09:43:25,979] {scheduler_job.py:153} INFO - Started process (PID=22085) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:43:25,985] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:43:25,989] {logging_mixin.py:112} INFO - [2020-04-06 09:43:25,988] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:43:26,501] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:43:26,523] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:43:26,533] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:43:26,535] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.557 seconds
[2020-04-06 09:44:20,175] {scheduler_job.py:153} INFO - Started process (PID=22114) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:44:20,183] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:44:20,184] {logging_mixin.py:112} INFO - [2020-04-06 09:44:20,183] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:44:20,491] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:44:20,517] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:44:20,526] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:44:20,529] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.354 seconds
[2020-04-06 09:45:14,343] {scheduler_job.py:153} INFO - Started process (PID=22143) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:45:14,349] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:45:14,351] {logging_mixin.py:112} INFO - [2020-04-06 09:45:14,350] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:45:14,784] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:45:14,802] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:45:14,811] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:45:14,813] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.470 seconds
[2020-04-06 09:46:08,547] {scheduler_job.py:153} INFO - Started process (PID=22175) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:46:08,555] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:46:08,556] {logging_mixin.py:112} INFO - [2020-04-06 09:46:08,555] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:46:08,881] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:46:08,910] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:46:08,922] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:46:08,929] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.383 seconds
[2020-04-06 09:47:02,743] {scheduler_job.py:153} INFO - Started process (PID=22204) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:47:02,750] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:47:02,753] {logging_mixin.py:112} INFO - [2020-04-06 09:47:02,752] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:47:03,116] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:47:03,157] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:47:03,169] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:47:03,174] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.431 seconds
[2020-04-06 09:47:56,918] {scheduler_job.py:153} INFO - Started process (PID=22236) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:47:56,937] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:47:56,940] {logging_mixin.py:112} INFO - [2020-04-06 09:47:56,939] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:47:57,291] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:47:57,316] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:47:57,327] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:47:57,339] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.421 seconds
[2020-04-06 09:48:51,146] {scheduler_job.py:153} INFO - Started process (PID=22276) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:48:51,154] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:48:51,157] {logging_mixin.py:112} INFO - [2020-04-06 09:48:51,156] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:48:51,616] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:48:51,640] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:48:51,650] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:48:51,653] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.506 seconds
[2020-04-06 09:49:45,298] {scheduler_job.py:153} INFO - Started process (PID=22304) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:49:45,307] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:49:45,308] {logging_mixin.py:112} INFO - [2020-04-06 09:49:45,308] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:49:45,665] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:49:45,685] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:49:45,699] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:49:45,707] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.409 seconds
[2020-04-06 09:50:39,468] {scheduler_job.py:153} INFO - Started process (PID=22334) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:50:39,477] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:50:39,478] {logging_mixin.py:112} INFO - [2020-04-06 09:50:39,478] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:50:39,823] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:50:39,843] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:50:39,853] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:50:39,855] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.387 seconds
[2020-04-06 09:51:33,646] {scheduler_job.py:153} INFO - Started process (PID=22364) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:51:33,662] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:51:33,664] {logging_mixin.py:112} INFO - [2020-04-06 09:51:33,663] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:51:34,154] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:51:34,199] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:51:34,211] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:51:34,224] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.579 seconds
[2020-04-06 09:52:27,837] {scheduler_job.py:153} INFO - Started process (PID=22393) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:52:27,846] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:52:27,847] {logging_mixin.py:112} INFO - [2020-04-06 09:52:27,847] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:52:28,211] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:52:28,240] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:52:28,255] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:52:28,259] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.422 seconds
[2020-04-06 09:53:22,020] {scheduler_job.py:153} INFO - Started process (PID=22423) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:53:22,036] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:53:22,039] {logging_mixin.py:112} INFO - [2020-04-06 09:53:22,038] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:53:22,370] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:53:22,404] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:53:22,414] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:53:22,418] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.398 seconds
[2020-04-06 09:54:16,159] {scheduler_job.py:153} INFO - Started process (PID=22451) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:54:16,168] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:54:16,169] {logging_mixin.py:112} INFO - [2020-04-06 09:54:16,169] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:54:16,491] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:54:16,517] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:54:16,526] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:54:16,528] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.369 seconds
[2020-04-06 09:55:10,322] {scheduler_job.py:153} INFO - Started process (PID=22480) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:55:10,338] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:55:10,339] {logging_mixin.py:112} INFO - [2020-04-06 09:55:10,339] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:55:10,640] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:55:10,657] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:55:10,667] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:55:10,670] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.349 seconds
[2020-04-06 09:56:04,500] {scheduler_job.py:153} INFO - Started process (PID=22509) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:56:04,515] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:56:04,516] {logging_mixin.py:112} INFO - [2020-04-06 09:56:04,516] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:56:04,845] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:56:04,867] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:56:04,878] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:56:04,881] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.380 seconds
[2020-04-06 09:56:58,668] {scheduler_job.py:153} INFO - Started process (PID=22549) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:56:58,697] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:56:58,699] {logging_mixin.py:112} INFO - [2020-04-06 09:56:58,698] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:56:59,040] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:56:59,077] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:56:59,090] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:56:59,092] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.425 seconds
[2020-04-06 09:57:52,832] {scheduler_job.py:153} INFO - Started process (PID=22578) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:57:52,840] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:57:52,841] {logging_mixin.py:112} INFO - [2020-04-06 09:57:52,841] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:57:53,143] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:57:53,174] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:57:53,190] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:57:53,193] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.361 seconds
[2020-04-06 09:58:47,009] {scheduler_job.py:153} INFO - Started process (PID=22606) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:58:47,015] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:58:47,016] {logging_mixin.py:112} INFO - [2020-04-06 09:58:47,016] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:58:47,326] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:58:47,350] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:58:47,362] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:58:47,365] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.356 seconds
[2020-04-06 09:59:41,193] {scheduler_job.py:153} INFO - Started process (PID=22637) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:59:41,208] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 09:59:41,209] {logging_mixin.py:112} INFO - [2020-04-06 09:59:41,209] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:59:41,506] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 09:59:41,536] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 09:59:41,545] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 09:59:41,549] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.356 seconds
[2020-04-06 10:00:35,363] {scheduler_job.py:153} INFO - Started process (PID=22678) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:00:35,372] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:00:35,375] {logging_mixin.py:112} INFO - [2020-04-06 10:00:35,373] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:00:35,755] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:00:35,786] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:00:35,801] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:00:35,803] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.440 seconds
[2020-04-06 10:01:29,531] {scheduler_job.py:153} INFO - Started process (PID=22707) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:01:29,539] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:01:29,541] {logging_mixin.py:112} INFO - [2020-04-06 10:01:29,541] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:01:29,921] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:01:29,956] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:01:29,969] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:01:29,971] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.441 seconds
[2020-04-06 10:02:23,714] {scheduler_job.py:153} INFO - Started process (PID=22737) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:02:23,727] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:02:23,728] {logging_mixin.py:112} INFO - [2020-04-06 10:02:23,727] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:02:24,007] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:02:24,032] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:02:24,046] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:02:24,048] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.334 seconds
[2020-04-06 10:03:17,896] {scheduler_job.py:153} INFO - Started process (PID=22770) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:03:17,908] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:03:17,909] {logging_mixin.py:112} INFO - [2020-04-06 10:03:17,909] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:03:18,198] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:03:18,220] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:03:18,229] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:03:18,231] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.335 seconds
[2020-04-06 10:04:12,065] {scheduler_job.py:153} INFO - Started process (PID=22800) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:04:12,072] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:04:12,073] {logging_mixin.py:112} INFO - [2020-04-06 10:04:12,072] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:04:12,376] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:04:12,409] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:04:12,419] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:04:12,425] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.360 seconds
[2020-04-06 10:05:06,252] {scheduler_job.py:153} INFO - Started process (PID=22830) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:05:06,262] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:05:06,263] {logging_mixin.py:112} INFO - [2020-04-06 10:05:06,262] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:05:06,577] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:05:06,606] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:05:06,614] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:05:06,616] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.365 seconds
[2020-04-06 10:06:00,430] {scheduler_job.py:153} INFO - Started process (PID=22862) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:06:00,437] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:06:00,439] {logging_mixin.py:112} INFO - [2020-04-06 10:06:00,438] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:06:00,851] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:06:00,880] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:06:00,896] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:06:00,898] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.468 seconds
[2020-04-06 10:06:54,592] {scheduler_job.py:153} INFO - Started process (PID=22891) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:06:54,606] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:06:54,607] {logging_mixin.py:112} INFO - [2020-04-06 10:06:54,607] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:06:54,920] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:06:54,946] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:06:54,954] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:06:54,956] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.365 seconds
[2020-04-06 10:07:48,811] {scheduler_job.py:153} INFO - Started process (PID=22919) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:07:48,825] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:07:48,827] {logging_mixin.py:112} INFO - [2020-04-06 10:07:48,826] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:07:49,197] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:07:49,248] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:07:49,265] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:07:49,276] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.465 seconds
[2020-04-06 10:08:42,978] {scheduler_job.py:153} INFO - Started process (PID=22948) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:08:42,985] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:08:42,986] {logging_mixin.py:112} INFO - [2020-04-06 10:08:42,985] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:08:43,312] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:08:43,341] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:08:43,350] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:08:43,352] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.375 seconds
[2020-04-06 10:09:37,155] {scheduler_job.py:153} INFO - Started process (PID=22981) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:09:37,161] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:09:37,163] {logging_mixin.py:112} INFO - [2020-04-06 10:09:37,162] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:09:37,447] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:09:37,472] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:09:37,483] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:09:37,485] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.330 seconds
[2020-04-06 10:10:31,298] {scheduler_job.py:153} INFO - Started process (PID=23012) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:10:31,309] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:10:31,310] {logging_mixin.py:112} INFO - [2020-04-06 10:10:31,309] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:10:31,607] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:10:31,636] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:10:31,649] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:10:31,651] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.353 seconds
[2020-04-06 10:11:25,480] {scheduler_job.py:153} INFO - Started process (PID=23041) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:11:25,494] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:11:25,495] {logging_mixin.py:112} INFO - [2020-04-06 10:11:25,494] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:11:25,782] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:11:25,801] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:11:25,809] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:11:25,811] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.331 seconds
[2020-04-06 10:12:19,657] {scheduler_job.py:153} INFO - Started process (PID=23071) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:12:19,663] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:12:19,665] {logging_mixin.py:112} INFO - [2020-04-06 10:12:19,664] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:12:19,969] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:12:19,989] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:12:20,000] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:12:20,002] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.345 seconds
[2020-04-06 10:13:13,839] {scheduler_job.py:153} INFO - Started process (PID=23100) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:13:13,845] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:13:13,846] {logging_mixin.py:112} INFO - [2020-04-06 10:13:13,846] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:13:14,128] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:13:14,155] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:13:14,169] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:13:14,171] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.331 seconds
[2020-04-06 10:14:08,008] {scheduler_job.py:153} INFO - Started process (PID=23138) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:14:08,016] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:14:08,017] {logging_mixin.py:112} INFO - [2020-04-06 10:14:08,017] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:14:08,327] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:14:08,355] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:14:08,366] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:14:08,368] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.360 seconds
[2020-04-06 10:15:02,158] {scheduler_job.py:153} INFO - Started process (PID=23172) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:15:02,163] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:15:02,165] {logging_mixin.py:112} INFO - [2020-04-06 10:15:02,164] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:15:02,447] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:15:02,476] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:15:02,487] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:15:02,489] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.332 seconds
[2020-04-06 10:15:56,340] {scheduler_job.py:153} INFO - Started process (PID=23201) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:15:56,349] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:15:56,350] {logging_mixin.py:112} INFO - [2020-04-06 10:15:56,350] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:15:56,639] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:15:56,671] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:15:56,680] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:15:56,682] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.343 seconds
[2020-04-06 10:16:50,533] {scheduler_job.py:153} INFO - Started process (PID=23238) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:16:50,558] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:16:50,560] {logging_mixin.py:112} INFO - [2020-04-06 10:16:50,559] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:16:51,562] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:16:51,594] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:16:51,624] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:16:51,629] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 1.096 seconds
[2020-04-06 10:17:44,696] {scheduler_job.py:153} INFO - Started process (PID=23271) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:17:44,704] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:17:44,705] {logging_mixin.py:112} INFO - [2020-04-06 10:17:44,704] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:17:45,022] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:17:45,040] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:17:45,051] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:17:45,053] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.357 seconds
[2020-04-06 10:18:38,883] {scheduler_job.py:153} INFO - Started process (PID=23301) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:18:38,899] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:18:38,902] {logging_mixin.py:112} INFO - [2020-04-06 10:18:38,901] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:18:39,439] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:18:39,495] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:18:39,512] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:18:39,518] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.636 seconds
[2020-04-06 10:19:33,026] {scheduler_job.py:153} INFO - Started process (PID=23330) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:19:33,036] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:19:33,037] {logging_mixin.py:112} INFO - [2020-04-06 10:19:33,036] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:19:33,407] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:19:33,430] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:19:33,442] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:19:33,444] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.419 seconds
[2020-04-06 10:20:27,222] {scheduler_job.py:153} INFO - Started process (PID=23359) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:20:27,235] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:20:27,235] {logging_mixin.py:112} INFO - [2020-04-06 10:20:27,235] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:20:27,530] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:20:27,559] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:20:27,575] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:20:27,577] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.355 seconds
[2020-04-06 10:21:21,398] {scheduler_job.py:153} INFO - Started process (PID=23391) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:21:21,411] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:21:21,412] {logging_mixin.py:112} INFO - [2020-04-06 10:21:21,411] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:21:21,739] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:21:21,758] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:21:21,770] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:21:21,773] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.375 seconds
[2020-04-06 10:22:15,561] {scheduler_job.py:153} INFO - Started process (PID=23424) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:22:15,568] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:22:15,569] {logging_mixin.py:112} INFO - [2020-04-06 10:22:15,569] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:22:15,856] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:22:15,889] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:22:15,898] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:22:15,900] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.339 seconds
[2020-04-06 10:23:09,750] {scheduler_job.py:153} INFO - Started process (PID=23453) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:23:09,757] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:23:09,758] {logging_mixin.py:112} INFO - [2020-04-06 10:23:09,757] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:23:10,039] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:23:10,066] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:23:10,076] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:23:10,083] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.333 seconds
[2020-04-06 10:24:03,931] {scheduler_job.py:153} INFO - Started process (PID=23483) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:24:03,938] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:24:03,939] {logging_mixin.py:112} INFO - [2020-04-06 10:24:03,939] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:24:04,271] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:24:04,295] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:24:04,303] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:24:04,304] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.374 seconds
[2020-04-06 10:24:58,100] {scheduler_job.py:153} INFO - Started process (PID=23514) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:24:58,106] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:24:58,107] {logging_mixin.py:112} INFO - [2020-04-06 10:24:58,107] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:24:58,468] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:24:58,507] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:24:58,518] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:24:58,524] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.424 seconds
[2020-04-06 10:25:52,277] {scheduler_job.py:153} INFO - Started process (PID=23544) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:25:52,290] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:25:52,291] {logging_mixin.py:112} INFO - [2020-04-06 10:25:52,290] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:25:52,585] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:25:52,606] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:25:52,617] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:25:52,620] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.343 seconds
[2020-04-06 10:26:46,448] {scheduler_job.py:153} INFO - Started process (PID=23572) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:26:46,453] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:26:46,455] {logging_mixin.py:112} INFO - [2020-04-06 10:26:46,454] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:26:46,742] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:26:46,770] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:26:46,778] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:26:46,780] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.333 seconds
[2020-04-06 10:27:40,708] {scheduler_job.py:153} INFO - Started process (PID=23617) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:27:40,719] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:27:40,720] {logging_mixin.py:112} INFO - [2020-04-06 10:27:40,720] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:27:41,032] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:27:41,055] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:27:41,063] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:27:41,065] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.357 seconds
[2020-04-06 10:28:34,788] {scheduler_job.py:153} INFO - Started process (PID=23647) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:28:34,795] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:28:34,797] {logging_mixin.py:112} INFO - [2020-04-06 10:28:34,797] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:28:35,091] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:28:35,117] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:28:35,125] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:28:35,127] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.339 seconds
[2020-04-06 10:29:28,958] {scheduler_job.py:153} INFO - Started process (PID=23676) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:29:28,964] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:29:28,965] {logging_mixin.py:112} INFO - [2020-04-06 10:29:28,965] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:29:29,256] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:29:29,284] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:29:29,293] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:29:29,296] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.338 seconds
[2020-04-06 10:30:23,154] {scheduler_job.py:153} INFO - Started process (PID=23717) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:30:23,173] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:30:23,175] {logging_mixin.py:112} INFO - [2020-04-06 10:30:23,174] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:30:23,509] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:30:23,530] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:30:23,540] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:30:23,542] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.388 seconds
[2020-04-06 10:31:17,293] {scheduler_job.py:153} INFO - Started process (PID=23746) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:31:17,300] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:31:17,301] {logging_mixin.py:112} INFO - [2020-04-06 10:31:17,301] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:31:17,612] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:31:17,643] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:31:17,654] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:31:17,659] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.366 seconds
[2020-04-06 10:32:11,480] {scheduler_job.py:153} INFO - Started process (PID=23779) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:32:11,487] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:32:11,489] {logging_mixin.py:112} INFO - [2020-04-06 10:32:11,488] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:32:11,826] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:32:11,851] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:32:11,864] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:32:11,867] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.387 seconds
[2020-04-06 10:33:05,668] {scheduler_job.py:153} INFO - Started process (PID=23820) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:33:05,684] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:33:05,685] {logging_mixin.py:112} INFO - [2020-04-06 10:33:05,685] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:33:06,028] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:33:06,051] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:33:06,062] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:33:06,067] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.399 seconds
[2020-04-06 10:33:59,858] {scheduler_job.py:153} INFO - Started process (PID=23849) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:33:59,870] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:33:59,871] {logging_mixin.py:112} INFO - [2020-04-06 10:33:59,871] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:34:00,204] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:34:00,231] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:34:00,245] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:34:00,248] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.390 seconds
[2020-04-06 10:34:54,035] {scheduler_job.py:153} INFO - Started process (PID=23878) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:34:54,048] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:34:54,049] {logging_mixin.py:112} INFO - [2020-04-06 10:34:54,048] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:34:54,352] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:34:54,384] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:34:54,395] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:34:54,398] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.363 seconds
[2020-04-06 10:35:48,217] {scheduler_job.py:153} INFO - Started process (PID=23906) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:35:48,223] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:35:48,225] {logging_mixin.py:112} INFO - [2020-04-06 10:35:48,224] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:35:48,512] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:35:48,531] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:35:48,543] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:35:48,547] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.330 seconds
[2020-04-06 10:36:42,377] {scheduler_job.py:153} INFO - Started process (PID=23935) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:36:42,390] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:36:42,392] {logging_mixin.py:112} INFO - [2020-04-06 10:36:42,391] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:36:42,827] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:36:42,860] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:36:42,870] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:36:42,874] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.496 seconds
[2020-04-06 10:37:36,553] {scheduler_job.py:153} INFO - Started process (PID=23965) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:37:36,568] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:37:36,569] {logging_mixin.py:112} INFO - [2020-04-06 10:37:36,568] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:37:36,926] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:37:36,953] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:37:36,964] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:37:36,968] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.415 seconds
[2020-04-06 10:38:30,809] {scheduler_job.py:153} INFO - Started process (PID=23994) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:38:30,831] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:38:30,835] {logging_mixin.py:112} INFO - [2020-04-06 10:38:30,833] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:38:31,363] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:38:31,427] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:38:31,438] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:38:31,442] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.641 seconds
[2020-04-06 10:39:24,945] {scheduler_job.py:153} INFO - Started process (PID=24023) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:39:24,952] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:39:24,953] {logging_mixin.py:112} INFO - [2020-04-06 10:39:24,953] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:39:25,327] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:39:25,347] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:39:25,354] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:39:25,358] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.412 seconds
[2020-04-06 10:40:19,094] {scheduler_job.py:153} INFO - Started process (PID=24052) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:40:19,100] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:40:19,102] {logging_mixin.py:112} INFO - [2020-04-06 10:40:19,101] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:40:19,591] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:40:19,619] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:40:19,643] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:40:19,649] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.555 seconds
[2020-04-06 10:41:13,279] {scheduler_job.py:153} INFO - Started process (PID=24081) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:41:13,287] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:41:13,288] {logging_mixin.py:112} INFO - [2020-04-06 10:41:13,288] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:41:13,558] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:41:13,576] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:41:13,585] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:41:13,587] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.308 seconds
[2020-04-06 10:42:07,425] {scheduler_job.py:153} INFO - Started process (PID=24111) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:42:07,434] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:42:07,435] {logging_mixin.py:112} INFO - [2020-04-06 10:42:07,435] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:42:07,700] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:42:07,726] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:42:07,736] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:42:07,739] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.314 seconds
[2020-04-06 10:43:01,550] {scheduler_job.py:153} INFO - Started process (PID=24145) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:43:01,557] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:43:01,558] {logging_mixin.py:112} INFO - [2020-04-06 10:43:01,557] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:43:01,812] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:43:01,828] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:43:01,838] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:43:01,840] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.290 seconds
[2020-04-06 10:43:55,703] {scheduler_job.py:153} INFO - Started process (PID=24190) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:43:55,709] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:43:55,710] {logging_mixin.py:112} INFO - [2020-04-06 10:43:55,710] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:43:55,969] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:43:55,987] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:43:55,995] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:43:55,998] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.295 seconds
[2020-04-06 10:44:49,832] {scheduler_job.py:153} INFO - Started process (PID=24220) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:44:49,838] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:44:49,839] {logging_mixin.py:112} INFO - [2020-04-06 10:44:49,839] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:44:50,086] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:44:50,103] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:44:50,113] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:44:50,115] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.283 seconds
[2020-04-06 10:45:43,973] {scheduler_job.py:153} INFO - Started process (PID=24251) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:45:43,980] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:45:43,981] {logging_mixin.py:112} INFO - [2020-04-06 10:45:43,981] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:45:44,233] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:45:44,252] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:45:44,259] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:45:44,262] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.289 seconds
[2020-04-06 10:46:38,157] {scheduler_job.py:153} INFO - Started process (PID=24280) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:46:38,164] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:46:38,165] {logging_mixin.py:112} INFO - [2020-04-06 10:46:38,165] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:46:38,442] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:46:38,459] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:46:38,467] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:46:38,469] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.312 seconds
[2020-04-06 10:47:32,295] {scheduler_job.py:153} INFO - Started process (PID=24309) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:47:32,301] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:47:32,302] {logging_mixin.py:112} INFO - [2020-04-06 10:47:32,302] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:47:32,575] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:47:32,595] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:47:32,604] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:47:32,606] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.311 seconds
[2020-04-06 10:48:26,472] {scheduler_job.py:153} INFO - Started process (PID=24338) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:48:26,478] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:48:26,479] {logging_mixin.py:112} INFO - [2020-04-06 10:48:26,479] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:48:26,722] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:48:26,747] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:48:26,755] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:48:26,757] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.285 seconds
[2020-04-06 10:49:20,628] {scheduler_job.py:153} INFO - Started process (PID=24366) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:49:20,642] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:49:20,643] {logging_mixin.py:112} INFO - [2020-04-06 10:49:20,642] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:49:20,885] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:49:20,913] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:49:20,922] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:49:20,924] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.296 seconds
[2020-04-06 10:50:14,781] {scheduler_job.py:153} INFO - Started process (PID=24394) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:50:14,798] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:50:14,799] {logging_mixin.py:112} INFO - [2020-04-06 10:50:14,798] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:50:15,150] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:50:15,176] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:50:15,185] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:50:15,188] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.407 seconds
[2020-04-06 10:51:08,914] {scheduler_job.py:153} INFO - Started process (PID=24424) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:51:08,920] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:51:08,921] {logging_mixin.py:112} INFO - [2020-04-06 10:51:08,920] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:51:09,162] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:51:09,178] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:51:09,186] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:51:09,188] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.274 seconds
[2020-04-06 10:52:03,078] {scheduler_job.py:153} INFO - Started process (PID=24453) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:52:03,084] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:52:03,085] {logging_mixin.py:112} INFO - [2020-04-06 10:52:03,085] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:52:03,326] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:52:03,342] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:52:03,350] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:52:03,352] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.275 seconds
[2020-04-06 10:52:57,218] {scheduler_job.py:153} INFO - Started process (PID=24490) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:52:57,224] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:52:57,225] {logging_mixin.py:112} INFO - [2020-04-06 10:52:57,225] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:52:57,467] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:52:57,493] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:52:57,502] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:52:57,504] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.286 seconds
[2020-04-06 10:53:51,371] {scheduler_job.py:153} INFO - Started process (PID=24518) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:53:51,377] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:53:51,378] {logging_mixin.py:112} INFO - [2020-04-06 10:53:51,377] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:53:51,641] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:53:51,711] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:53:51,721] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:53:51,723] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.352 seconds
[2020-04-06 10:54:45,535] {scheduler_job.py:153} INFO - Started process (PID=24547) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:54:45,547] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:54:45,550] {logging_mixin.py:112} INFO - [2020-04-06 10:54:45,548] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:54:45,813] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:54:45,829] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:54:45,837] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:54:45,839] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.304 seconds
[2020-04-06 10:55:39,703] {scheduler_job.py:153} INFO - Started process (PID=24577) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:55:39,709] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:55:39,710] {logging_mixin.py:112} INFO - [2020-04-06 10:55:39,709] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:55:39,960] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:55:39,976] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:55:39,984] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:55:39,986] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.283 seconds
[2020-04-06 10:56:33,868] {scheduler_job.py:153} INFO - Started process (PID=24606) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:56:33,874] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:56:33,880] {logging_mixin.py:112} INFO - [2020-04-06 10:56:33,880] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:56:34,112] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:56:34,139] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:56:34,149] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:56:34,152] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.284 seconds
[2020-04-06 10:57:28,039] {scheduler_job.py:153} INFO - Started process (PID=24635) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:57:28,048] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:57:28,049] {logging_mixin.py:112} INFO - [2020-04-06 10:57:28,049] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:57:28,292] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:57:28,311] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:57:28,319] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:57:28,321] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.282 seconds
[2020-04-06 10:58:22,178] {scheduler_job.py:153} INFO - Started process (PID=24670) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:58:22,185] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:58:22,186] {logging_mixin.py:112} INFO - [2020-04-06 10:58:22,186] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:58:22,485] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:58:22,510] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:58:22,520] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:58:22,523] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.346 seconds
[2020-04-06 10:59:16,336] {scheduler_job.py:153} INFO - Started process (PID=24702) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:59:16,343] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 10:59:16,344] {logging_mixin.py:112} INFO - [2020-04-06 10:59:16,344] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:59:16,603] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 10:59:16,622] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 10:59:16,629] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 10:59:16,631] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.295 seconds
[2020-04-06 11:00:10,544] {scheduler_job.py:153} INFO - Started process (PID=24736) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:00:10,553] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:00:10,553] {logging_mixin.py:112} INFO - [2020-04-06 11:00:10,553] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:00:10,923] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:00:10,959] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:00:10,979] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:00:10,982] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.438 seconds
[2020-04-06 11:01:04,727] {scheduler_job.py:153} INFO - Started process (PID=24765) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:01:04,736] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:01:04,742] {logging_mixin.py:112} INFO - [2020-04-06 11:01:04,739] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:01:05,096] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:01:05,128] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:01:05,145] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:01:05,149] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.422 seconds
[2020-04-06 11:01:58,891] {scheduler_job.py:153} INFO - Started process (PID=24794) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:01:58,899] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:01:58,901] {logging_mixin.py:112} INFO - [2020-04-06 11:01:58,899] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:01:59,256] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:01:59,289] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:01:59,302] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:01:59,310] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.419 seconds
[2020-04-06 11:02:53,110] {scheduler_job.py:153} INFO - Started process (PID=24825) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:02:53,141] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:02:53,143] {logging_mixin.py:112} INFO - [2020-04-06 11:02:53,143] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:02:53,685] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:02:53,715] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:02:53,726] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:02:53,730] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.620 seconds
[2020-04-06 11:03:47,269] {scheduler_job.py:153} INFO - Started process (PID=24853) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:03:47,276] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:03:47,277] {logging_mixin.py:112} INFO - [2020-04-06 11:03:47,276] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:03:47,642] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:03:47,668] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:03:47,680] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:03:47,684] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.415 seconds
[2020-04-06 11:04:41,652] {scheduler_job.py:153} INFO - Started process (PID=24884) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:04:41,668] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:04:41,670] {logging_mixin.py:112} INFO - [2020-04-06 11:04:41,670] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:04:42,078] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:04:42,106] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:04:42,121] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:04:42,125] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.474 seconds
[2020-04-06 11:05:35,674] {scheduler_job.py:153} INFO - Started process (PID=24914) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:05:35,683] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:05:35,685] {logging_mixin.py:112} INFO - [2020-04-06 11:05:35,684] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:05:36,139] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:05:36,177] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:05:36,188] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:05:36,194] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.521 seconds
[2020-04-06 11:06:29,785] {scheduler_job.py:153} INFO - Started process (PID=24947) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:06:29,794] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:06:29,797] {logging_mixin.py:112} INFO - [2020-04-06 11:06:29,796] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:06:30,101] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:06:30,121] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:06:30,136] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:06:30,138] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.353 seconds
[2020-04-06 11:07:23,951] {scheduler_job.py:153} INFO - Started process (PID=24977) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:07:23,959] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:07:23,961] {logging_mixin.py:112} INFO - [2020-04-06 11:07:23,960] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:07:24,262] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:07:24,282] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:07:24,289] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:07:24,292] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.341 seconds
[2020-04-06 11:08:18,131] {scheduler_job.py:153} INFO - Started process (PID=25005) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:08:18,148] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:08:18,149] {logging_mixin.py:112} INFO - [2020-04-06 11:08:18,149] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:08:18,487] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:08:18,522] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:08:18,532] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:08:18,535] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.404 seconds
[2020-04-06 11:09:12,299] {scheduler_job.py:153} INFO - Started process (PID=25035) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:09:12,308] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:09:12,309] {logging_mixin.py:112} INFO - [2020-04-06 11:09:12,309] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:09:12,640] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:09:12,669] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:09:12,681] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:09:12,683] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.384 seconds
[2020-04-06 11:10:06,467] {scheduler_job.py:153} INFO - Started process (PID=25065) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:10:06,476] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:10:06,478] {logging_mixin.py:112} INFO - [2020-04-06 11:10:06,477] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:10:06,817] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:10:06,837] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:10:06,847] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:10:06,849] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.382 seconds
[2020-04-06 11:11:00,633] {scheduler_job.py:153} INFO - Started process (PID=25094) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:11:00,645] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:11:00,647] {logging_mixin.py:112} INFO - [2020-04-06 11:11:00,646] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:11:00,930] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:11:00,963] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:11:00,971] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:11:00,974] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.341 seconds
[2020-04-06 11:11:54,790] {scheduler_job.py:153} INFO - Started process (PID=25124) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:11:54,798] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:11:54,799] {logging_mixin.py:112} INFO - [2020-04-06 11:11:54,798] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:11:55,092] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:11:55,113] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:11:55,123] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:11:55,127] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.337 seconds
[2020-04-06 11:12:48,943] {scheduler_job.py:153} INFO - Started process (PID=25166) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:12:48,955] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:12:48,957] {logging_mixin.py:112} INFO - [2020-04-06 11:12:48,956] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:12:49,285] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:12:49,313] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:12:49,321] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:12:49,325] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.381 seconds
[2020-04-06 11:13:43,125] {scheduler_job.py:153} INFO - Started process (PID=25195) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:13:43,132] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:13:43,133] {logging_mixin.py:112} INFO - [2020-04-06 11:13:43,132] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:13:43,456] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:13:43,482] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:13:43,490] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:13:43,492] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.367 seconds
[2020-04-06 11:14:37,291] {scheduler_job.py:153} INFO - Started process (PID=25230) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:14:37,299] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:14:37,301] {logging_mixin.py:112} INFO - [2020-04-06 11:14:37,299] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:14:37,630] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:14:37,665] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:14:37,678] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:14:37,680] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.390 seconds
[2020-04-06 11:15:31,455] {scheduler_job.py:153} INFO - Started process (PID=25261) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:15:31,463] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:15:31,465] {logging_mixin.py:112} INFO - [2020-04-06 11:15:31,464] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:15:31,933] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:15:31,967] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:15:31,984] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:15:31,986] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.531 seconds
[2020-04-06 11:16:25,618] {scheduler_job.py:153} INFO - Started process (PID=25299) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:16:25,693] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:16:25,756] {logging_mixin.py:112} INFO - [2020-04-06 11:16:25,753] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:16:26,555] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:16:26,602] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:16:26,617] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:16:26,620] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 1.002 seconds
[2020-04-06 11:17:19,801] {scheduler_job.py:153} INFO - Started process (PID=25330) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:17:19,809] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:17:19,810] {logging_mixin.py:112} INFO - [2020-04-06 11:17:19,809] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:17:20,097] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:17:20,124] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:17:20,131] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:17:20,133] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.332 seconds
[2020-04-06 11:18:13,965] {scheduler_job.py:153} INFO - Started process (PID=25369) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:18:13,975] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:18:13,977] {logging_mixin.py:112} INFO - [2020-04-06 11:18:13,976] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:18:14,364] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:18:14,385] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:18:14,407] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:18:14,409] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.444 seconds
[2020-04-06 11:19:08,167] {scheduler_job.py:153} INFO - Started process (PID=25398) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:19:08,174] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:19:08,175] {logging_mixin.py:112} INFO - [2020-04-06 11:19:08,174] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:19:08,475] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:19:08,502] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:19:08,510] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:19:08,513] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.346 seconds
[2020-04-06 11:20:02,352] {scheduler_job.py:153} INFO - Started process (PID=25439) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:20:02,368] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:20:02,370] {logging_mixin.py:112} INFO - [2020-04-06 11:20:02,369] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:20:02,680] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:20:02,708] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:20:02,718] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:20:02,720] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.368 seconds
[2020-04-06 11:20:56,504] {scheduler_job.py:153} INFO - Started process (PID=25470) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:20:56,516] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:20:56,518] {logging_mixin.py:112} INFO - [2020-04-06 11:20:56,517] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:20:56,871] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:20:56,904] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:20:56,915] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:20:56,919] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.414 seconds
[2020-04-06 11:21:50,665] {scheduler_job.py:153} INFO - Started process (PID=25500) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:21:50,679] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:21:50,682] {logging_mixin.py:112} INFO - [2020-04-06 11:21:50,680] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:21:50,948] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:21:50,973] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:21:50,982] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:21:50,984] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.319 seconds
[2020-04-06 11:22:44,831] {scheduler_job.py:153} INFO - Started process (PID=25541) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:22:44,837] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:22:44,838] {logging_mixin.py:112} INFO - [2020-04-06 11:22:44,837] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:22:45,187] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:22:45,207] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:22:45,218] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:22:45,220] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.389 seconds
[2020-04-06 11:23:39,004] {scheduler_job.py:153} INFO - Started process (PID=25570) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:23:39,011] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:23:39,012] {logging_mixin.py:112} INFO - [2020-04-06 11:23:39,012] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:23:39,282] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:23:39,303] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:23:39,310] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:23:39,312] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.308 seconds
[2020-04-06 11:24:33,180] {scheduler_job.py:153} INFO - Started process (PID=25599) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:24:33,190] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:24:33,191] {logging_mixin.py:112} INFO - [2020-04-06 11:24:33,191] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:24:33,575] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:24:33,600] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:24:33,610] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:24:33,613] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.433 seconds
[2020-04-06 11:25:27,355] {scheduler_job.py:153} INFO - Started process (PID=25630) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:25:27,362] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:25:27,363] {logging_mixin.py:112} INFO - [2020-04-06 11:25:27,362] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:25:27,742] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:25:27,784] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:25:27,796] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:25:27,798] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.444 seconds
[2020-04-06 11:26:21,528] {scheduler_job.py:153} INFO - Started process (PID=25658) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:26:21,541] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:26:21,542] {logging_mixin.py:112} INFO - [2020-04-06 11:26:21,541] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:26:21,809] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:26:21,838] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:26:21,847] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:26:21,849] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.321 seconds
[2020-04-06 11:27:15,679] {scheduler_job.py:153} INFO - Started process (PID=25688) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:27:15,686] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:27:15,687] {logging_mixin.py:112} INFO - [2020-04-06 11:27:15,686] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:27:15,959] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:27:15,983] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:27:15,991] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:27:15,994] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.315 seconds
[2020-04-06 11:28:09,866] {scheduler_job.py:153} INFO - Started process (PID=25721) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:28:09,872] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:28:09,873] {logging_mixin.py:112} INFO - [2020-04-06 11:28:09,873] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:28:10,137] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:28:10,158] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:28:10,167] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:28:10,169] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.303 seconds
[2020-04-06 11:29:04,018] {scheduler_job.py:153} INFO - Started process (PID=25751) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:29:04,027] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:29:04,028] {logging_mixin.py:112} INFO - [2020-04-06 11:29:04,027] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:29:04,322] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:29:04,355] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:29:04,367] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:29:04,369] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.351 seconds
[2020-04-06 11:29:58,179] {scheduler_job.py:153} INFO - Started process (PID=25794) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:29:58,187] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:29:58,189] {logging_mixin.py:112} INFO - [2020-04-06 11:29:58,188] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:29:58,460] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:29:58,487] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:29:58,494] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:29:58,496] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.317 seconds
[2020-04-06 11:30:52,331] {scheduler_job.py:153} INFO - Started process (PID=25823) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:30:52,339] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:30:52,340] {logging_mixin.py:112} INFO - [2020-04-06 11:30:52,339] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:30:52,626] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:30:52,654] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:30:52,663] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:30:52,666] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.335 seconds
[2020-04-06 11:31:46,497] {scheduler_job.py:153} INFO - Started process (PID=25852) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:31:46,505] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:31:46,506] {logging_mixin.py:112} INFO - [2020-04-06 11:31:46,505] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:31:46,907] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:31:46,932] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:31:46,941] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:31:46,943] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.446 seconds
[2020-04-06 11:32:40,671] {scheduler_job.py:153} INFO - Started process (PID=25881) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:32:40,676] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:32:40,677] {logging_mixin.py:112} INFO - [2020-04-06 11:32:40,677] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:32:41,017] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:32:41,047] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:32:41,059] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:32:41,061] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.391 seconds
[2020-04-06 11:33:34,845] {scheduler_job.py:153} INFO - Started process (PID=25910) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:33:34,855] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:33:34,856] {logging_mixin.py:112} INFO - [2020-04-06 11:33:34,856] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:33:35,161] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:33:35,220] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:33:35,234] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:33:35,237] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.392 seconds
[2020-04-06 11:34:29,038] {scheduler_job.py:153} INFO - Started process (PID=25939) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:34:29,044] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:34:29,046] {logging_mixin.py:112} INFO - [2020-04-06 11:34:29,045] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:34:29,341] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:34:29,362] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:34:29,376] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:34:29,378] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.340 seconds
[2020-04-06 11:35:23,221] {scheduler_job.py:153} INFO - Started process (PID=25977) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:35:23,234] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:35:23,235] {logging_mixin.py:112} INFO - [2020-04-06 11:35:23,235] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:35:23,547] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:35:23,591] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:35:23,602] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:35:23,606] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.385 seconds
[2020-04-06 11:36:17,396] {scheduler_job.py:153} INFO - Started process (PID=26007) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:36:17,403] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:36:17,404] {logging_mixin.py:112} INFO - [2020-04-06 11:36:17,403] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:36:17,679] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:36:17,703] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:36:17,716] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:36:17,718] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.322 seconds
[2020-04-06 11:37:11,561] {scheduler_job.py:153} INFO - Started process (PID=26036) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:37:11,567] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:37:11,568] {logging_mixin.py:112} INFO - [2020-04-06 11:37:11,568] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:37:11,918] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:37:11,938] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:37:11,950] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:37:11,952] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.391 seconds
[2020-04-06 11:38:05,757] {scheduler_job.py:153} INFO - Started process (PID=26065) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:38:05,769] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:38:05,771] {logging_mixin.py:112} INFO - [2020-04-06 11:38:05,770] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:38:06,061] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:38:06,095] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:38:06,104] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:38:06,107] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.350 seconds
[2020-04-06 11:38:59,920] {scheduler_job.py:153} INFO - Started process (PID=26094) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:38:59,930] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:38:59,931] {logging_mixin.py:112} INFO - [2020-04-06 11:38:59,931] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:39:00,251] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:39:00,278] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:39:00,294] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:39:00,297] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.377 seconds
[2020-04-06 11:39:54,100] {scheduler_job.py:153} INFO - Started process (PID=26123) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:39:54,107] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:39:54,108] {logging_mixin.py:112} INFO - [2020-04-06 11:39:54,107] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:39:54,463] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:39:54,502] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:39:54,514] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:39:54,517] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.417 seconds
[2020-04-06 11:40:48,287] {scheduler_job.py:153} INFO - Started process (PID=26151) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:40:48,302] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:40:48,304] {logging_mixin.py:112} INFO - [2020-04-06 11:40:48,304] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:40:48,599] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:40:48,622] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:40:48,631] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:40:48,634] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.348 seconds
[2020-04-06 11:41:42,486] {scheduler_job.py:153} INFO - Started process (PID=26181) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:41:42,494] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:41:42,495] {logging_mixin.py:112} INFO - [2020-04-06 11:41:42,495] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:41:42,843] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:41:42,863] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:41:42,875] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:41:42,879] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.393 seconds
[2020-04-06 11:42:36,665] {scheduler_job.py:153} INFO - Started process (PID=26216) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:42:36,670] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:42:36,672] {logging_mixin.py:112} INFO - [2020-04-06 11:42:36,671] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:42:37,006] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:42:37,024] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:42:37,034] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:42:37,036] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.371 seconds
[2020-04-06 11:43:30,856] {scheduler_job.py:153} INFO - Started process (PID=26248) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:43:30,863] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:43:30,864] {logging_mixin.py:112} INFO - [2020-04-06 11:43:30,864] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:43:31,206] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:43:31,225] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:43:31,233] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:43:31,235] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.379 seconds
[2020-04-06 11:44:25,011] {scheduler_job.py:153} INFO - Started process (PID=26283) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:44:25,021] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:44:25,022] {logging_mixin.py:112} INFO - [2020-04-06 11:44:25,021] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:44:25,332] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:44:25,348] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:44:25,361] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:44:25,364] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.353 seconds
[2020-04-06 11:45:19,202] {scheduler_job.py:153} INFO - Started process (PID=26312) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:45:19,210] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:45:19,211] {logging_mixin.py:112} INFO - [2020-04-06 11:45:19,210] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:45:19,517] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:45:19,543] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:45:19,560] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:45:19,563] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.361 seconds
[2020-04-06 11:46:13,370] {scheduler_job.py:153} INFO - Started process (PID=26341) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:46:13,379] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:46:13,380] {logging_mixin.py:112} INFO - [2020-04-06 11:46:13,380] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:46:14,132] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:46:14,164] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:46:14,179] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:46:14,182] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.813 seconds
[2020-04-06 11:47:07,556] {scheduler_job.py:153} INFO - Started process (PID=26371) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:47:07,578] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:47:07,579] {logging_mixin.py:112} INFO - [2020-04-06 11:47:07,579] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:47:07,925] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:47:07,944] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:47:07,956] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:47:07,958] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.403 seconds
[2020-04-06 11:48:01,708] {scheduler_job.py:153} INFO - Started process (PID=26411) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:48:01,716] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:48:01,717] {logging_mixin.py:112} INFO - [2020-04-06 11:48:01,716] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:48:02,113] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:48:02,141] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:48:02,149] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:48:02,153] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.445 seconds
[2020-04-06 11:48:55,880] {scheduler_job.py:153} INFO - Started process (PID=26443) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:48:55,887] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:48:55,891] {logging_mixin.py:112} INFO - [2020-04-06 11:48:55,888] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:48:56,158] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:48:56,189] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:48:56,197] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:48:56,199] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.319 seconds
[2020-04-06 11:49:50,064] {scheduler_job.py:153} INFO - Started process (PID=26471) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:49:50,069] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:49:50,070] {logging_mixin.py:112} INFO - [2020-04-06 11:49:50,070] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:49:50,337] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:49:50,365] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:49:50,372] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:49:50,377] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.313 seconds
[2020-04-06 11:50:44,222] {scheduler_job.py:153} INFO - Started process (PID=26500) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:50:44,228] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:50:44,229] {logging_mixin.py:112} INFO - [2020-04-06 11:50:44,229] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:50:44,521] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:50:44,547] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:50:44,556] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:50:44,558] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.336 seconds
[2020-04-06 11:51:38,370] {scheduler_job.py:153} INFO - Started process (PID=26529) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:51:38,376] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:51:38,377] {logging_mixin.py:112} INFO - [2020-04-06 11:51:38,377] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:51:38,638] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:51:38,666] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:51:38,674] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:51:38,677] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.306 seconds
[2020-04-06 11:52:32,520] {scheduler_job.py:153} INFO - Started process (PID=26559) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:52:32,530] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:52:32,532] {logging_mixin.py:112} INFO - [2020-04-06 11:52:32,531] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:52:32,852] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:52:32,875] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:52:32,882] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:52:32,885] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.365 seconds
[2020-04-06 11:53:26,682] {scheduler_job.py:153} INFO - Started process (PID=26589) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:53:26,689] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:53:26,690] {logging_mixin.py:112} INFO - [2020-04-06 11:53:26,690] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:53:26,958] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:53:26,986] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:53:26,995] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:53:26,998] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.316 seconds
[2020-04-06 11:54:20,864] {scheduler_job.py:153} INFO - Started process (PID=26619) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:54:20,877] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:54:20,878] {logging_mixin.py:112} INFO - [2020-04-06 11:54:20,878] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:54:21,152] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:54:21,180] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:54:21,188] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:54:21,190] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.326 seconds
[2020-04-06 11:55:15,031] {scheduler_job.py:153} INFO - Started process (PID=26650) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:55:15,043] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:55:15,044] {logging_mixin.py:112} INFO - [2020-04-06 11:55:15,044] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:55:15,354] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:55:15,392] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:55:15,404] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:55:15,407] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.376 seconds
[2020-04-06 11:56:09,215] {scheduler_job.py:153} INFO - Started process (PID=26685) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:56:09,223] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:56:09,224] {logging_mixin.py:112} INFO - [2020-04-06 11:56:09,224] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:56:09,512] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:56:09,531] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:56:09,542] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:56:09,544] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.329 seconds
[2020-04-06 11:57:03,410] {scheduler_job.py:153} INFO - Started process (PID=26718) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:57:03,432] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:57:03,434] {logging_mixin.py:112} INFO - [2020-04-06 11:57:03,432] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:57:03,768] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:57:03,800] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:57:03,815] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:57:03,823] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.414 seconds
[2020-04-06 11:57:57,534] {scheduler_job.py:153} INFO - Started process (PID=26747) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:57:57,542] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:57:57,543] {logging_mixin.py:112} INFO - [2020-04-06 11:57:57,542] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:57:57,845] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:57:57,871] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:57:57,880] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:57:57,883] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.349 seconds
[2020-04-06 11:58:51,708] {scheduler_job.py:153} INFO - Started process (PID=26775) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:58:51,714] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:58:51,715] {logging_mixin.py:112} INFO - [2020-04-06 11:58:51,715] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:58:52,002] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:58:52,040] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:58:52,048] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:58:52,050] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.342 seconds
[2020-04-06 11:59:45,884] {scheduler_job.py:153} INFO - Started process (PID=26804) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:59:45,890] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 11:59:45,891] {logging_mixin.py:112} INFO - [2020-04-06 11:59:45,891] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:59:46,161] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 11:59:46,187] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 11:59:46,196] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 11:59:46,198] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.314 seconds
[2020-04-06 12:00:40,026] {scheduler_job.py:153} INFO - Started process (PID=26835) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:00:40,034] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 12:00:40,035] {logging_mixin.py:112} INFO - [2020-04-06 12:00:40,034] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:00:40,351] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:00:40,381] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 12:00:40,390] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 12:00:40,392] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.366 seconds
[2020-04-06 12:01:34,196] {scheduler_job.py:153} INFO - Started process (PID=26865) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:01:34,210] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 12:01:34,212] {logging_mixin.py:112} INFO - [2020-04-06 12:01:34,211] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:01:34,571] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:01:34,598] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 12:01:34,612] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 12:01:34,614] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.418 seconds
[2020-04-06 12:02:28,375] {scheduler_job.py:153} INFO - Started process (PID=26896) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:02:28,391] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 12:02:28,393] {logging_mixin.py:112} INFO - [2020-04-06 12:02:28,392] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:02:28,663] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:02:28,720] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 12:02:28,729] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 12:02:28,731] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.356 seconds
[2020-04-06 12:03:22,534] {scheduler_job.py:153} INFO - Started process (PID=26924) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:03:22,542] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 12:03:22,545] {logging_mixin.py:112} INFO - [2020-04-06 12:03:22,544] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:03:22,817] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:03:22,849] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 12:03:22,861] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 12:03:22,863] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.329 seconds
[2020-04-06 12:04:16,688] {scheduler_job.py:153} INFO - Started process (PID=26953) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:04:16,694] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 12:04:16,694] {logging_mixin.py:112} INFO - [2020-04-06 12:04:16,694] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:04:16,963] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:04:16,992] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 12:04:17,006] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 12:04:17,008] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.320 seconds
[2020-04-06 12:05:10,828] {scheduler_job.py:153} INFO - Started process (PID=26989) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:05:10,834] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 12:05:10,835] {logging_mixin.py:112} INFO - [2020-04-06 12:05:10,835] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:05:11,109] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:05:11,134] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 12:05:11,144] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 12:05:11,146] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.318 seconds
[2020-04-06 12:06:05,009] {scheduler_job.py:153} INFO - Started process (PID=27018) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:06:05,020] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 12:06:05,021] {logging_mixin.py:112} INFO - [2020-04-06 12:06:05,021] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:06:05,329] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:06:05,354] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 12:06:05,372] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 12:06:05,374] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.365 seconds
[2020-04-06 12:06:59,157] {scheduler_job.py:153} INFO - Started process (PID=27050) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:06:59,167] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 12:06:59,168] {logging_mixin.py:112} INFO - [2020-04-06 12:06:59,167] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:06:59,444] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:06:59,478] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 12:06:59,487] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 12:06:59,490] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.333 seconds
[2020-04-06 12:07:53,314] {scheduler_job.py:153} INFO - Started process (PID=27078) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:07:53,328] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 12:07:53,330] {logging_mixin.py:112} INFO - [2020-04-06 12:07:53,329] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:07:53,730] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:07:53,760] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 12:07:53,769] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 12:07:53,773] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.460 seconds
[2020-04-06 12:08:47,486] {scheduler_job.py:153} INFO - Started process (PID=27110) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:08:47,492] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 12:08:47,493] {logging_mixin.py:112} INFO - [2020-04-06 12:08:47,493] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:08:47,800] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:08:47,830] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 12:08:47,839] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 12:08:47,841] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.355 seconds
[2020-04-06 12:09:41,659] {scheduler_job.py:153} INFO - Started process (PID=27140) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:09:41,664] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 12:09:41,666] {logging_mixin.py:112} INFO - [2020-04-06 12:09:41,665] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:09:41,954] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:09:41,979] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 12:09:41,993] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 12:09:41,995] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.337 seconds
[2020-04-06 12:10:35,817] {scheduler_job.py:153} INFO - Started process (PID=27170) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:10:35,822] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 12:10:35,823] {logging_mixin.py:112} INFO - [2020-04-06 12:10:35,823] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:10:36,096] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:10:36,123] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 12:10:36,131] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 12:10:36,136] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.319 seconds
[2020-04-06 12:11:30,002] {scheduler_job.py:153} INFO - Started process (PID=27201) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:11:30,012] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 12:11:30,013] {logging_mixin.py:112} INFO - [2020-04-06 12:11:30,013] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:11:30,347] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:11:30,382] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 12:11:30,399] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 12:11:30,401] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.399 seconds
[2020-04-06 12:12:24,150] {scheduler_job.py:153} INFO - Started process (PID=27230) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:12:24,162] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 12:12:24,166] {logging_mixin.py:112} INFO - [2020-04-06 12:12:24,165] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:12:24,458] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:12:24,482] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 12:12:24,491] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 12:12:24,494] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.344 seconds
[2020-04-06 12:13:18,318] {scheduler_job.py:153} INFO - Started process (PID=27259) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:13:18,324] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 12:13:18,325] {logging_mixin.py:112} INFO - [2020-04-06 12:13:18,325] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:13:18,618] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:13:18,644] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 12:13:18,654] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 12:13:18,656] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.339 seconds
[2020-04-06 12:14:12,497] {scheduler_job.py:153} INFO - Started process (PID=27299) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:14:12,524] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 12:14:12,525] {logging_mixin.py:112} INFO - [2020-04-06 12:14:12,525] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:14:12,944] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:14:12,965] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 12:14:12,980] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 12:14:12,982] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.485 seconds
[2020-04-06 12:15:06,662] {scheduler_job.py:153} INFO - Started process (PID=27339) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:15:06,669] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 12:15:06,670] {logging_mixin.py:112} INFO - [2020-04-06 12:15:06,670] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:15:06,955] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:15:06,983] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 12:15:06,996] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 12:15:06,999] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.337 seconds
[2020-04-06 12:16:00,838] {scheduler_job.py:153} INFO - Started process (PID=27370) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:16:00,844] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 12:16:00,845] {logging_mixin.py:112} INFO - [2020-04-06 12:16:00,845] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:16:01,202] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 12:16:01,225] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 12:16:01,235] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 12:16:01,237] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.399 seconds
[2020-04-06 14:15:13,848] {scheduler_job.py:153} INFO - Started process (PID=27449) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:15:13,860] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:15:13,862] {logging_mixin.py:112} INFO - [2020-04-06 14:15:13,861] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:15:14,331] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:15:14,357] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:15:14,365] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:15:14,367] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.519 seconds
[2020-04-06 14:15:47,951] {scheduler_job.py:153} INFO - Started process (PID=27500) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:15:47,959] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:15:47,960] {logging_mixin.py:112} INFO - [2020-04-06 14:15:47,960] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:15:48,286] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:15:48,309] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:15:48,318] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:15:48,321] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.371 seconds
[2020-04-06 14:16:42,052] {scheduler_job.py:153} INFO - Started process (PID=27532) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:16:42,067] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:16:42,068] {logging_mixin.py:112} INFO - [2020-04-06 14:16:42,068] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:16:42,341] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:16:42,371] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:16:42,380] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:16:42,382] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.331 seconds
[2020-04-06 14:17:36,173] {scheduler_job.py:153} INFO - Started process (PID=27561) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:17:36,183] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:17:36,184] {logging_mixin.py:112} INFO - [2020-04-06 14:17:36,183] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:17:36,442] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:17:36,467] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:17:36,475] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:17:36,477] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.303 seconds
[2020-04-06 14:18:30,285] {scheduler_job.py:153} INFO - Started process (PID=27609) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:18:30,292] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:18:30,293] {logging_mixin.py:112} INFO - [2020-04-06 14:18:30,292] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:18:30,618] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:18:30,642] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:18:30,653] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:18:30,656] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.372 seconds
[2020-04-06 14:19:24,408] {scheduler_job.py:153} INFO - Started process (PID=27639) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:19:24,425] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:19:24,426] {logging_mixin.py:112} INFO - [2020-04-06 14:19:24,426] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:19:24,780] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:19:24,816] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:19:24,827] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:19:24,829] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.421 seconds
[2020-04-06 14:20:18,562] {scheduler_job.py:153} INFO - Started process (PID=27667) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:20:18,570] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:20:18,572] {logging_mixin.py:112} INFO - [2020-04-06 14:20:18,572] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:20:19,087] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:20:19,113] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:20:19,126] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:20:19,129] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.567 seconds
[2020-04-06 14:21:12,725] {scheduler_job.py:153} INFO - Started process (PID=27698) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:21:12,739] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:21:12,740] {logging_mixin.py:112} INFO - [2020-04-06 14:21:12,740] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:21:13,112] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:21:13,160] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:21:13,174] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:21:13,177] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.452 seconds
[2020-04-06 14:22:06,881] {scheduler_job.py:153} INFO - Started process (PID=27727) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:22:06,889] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:22:06,890] {logging_mixin.py:112} INFO - [2020-04-06 14:22:06,890] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:22:07,220] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:22:07,241] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:22:07,248] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:22:07,251] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.370 seconds
[2020-04-06 14:23:01,086] {scheduler_job.py:153} INFO - Started process (PID=27778) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:23:01,096] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:23:01,101] {logging_mixin.py:112} INFO - [2020-04-06 14:23:01,101] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:23:01,608] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:23:01,644] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:23:01,662] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:23:01,666] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.579 seconds
[2020-04-06 14:23:55,262] {scheduler_job.py:153} INFO - Started process (PID=27851) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:23:55,272] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:23:55,273] {logging_mixin.py:112} INFO - [2020-04-06 14:23:55,273] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:23:55,592] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:23:55,619] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:23:55,627] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:23:55,629] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.368 seconds
[2020-04-06 14:24:49,431] {scheduler_job.py:153} INFO - Started process (PID=27899) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:24:49,443] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:24:49,444] {logging_mixin.py:112} INFO - [2020-04-06 14:24:49,443] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:24:49,846] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:24:49,894] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:24:49,909] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:24:49,913] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.482 seconds
[2020-04-06 14:25:43,703] {scheduler_job.py:153} INFO - Started process (PID=28217) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:25:43,712] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:25:43,713] {logging_mixin.py:112} INFO - [2020-04-06 14:25:43,713] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:25:44,506] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:25:44,535] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:25:44,552] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:25:44,554] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.852 seconds
[2020-04-06 14:26:37,800] {scheduler_job.py:153} INFO - Started process (PID=28368) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:26:37,807] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:26:37,808] {logging_mixin.py:112} INFO - [2020-04-06 14:26:37,808] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:26:38,156] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:26:38,177] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:26:38,185] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:26:38,187] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.387 seconds
[2020-04-06 14:27:31,962] {scheduler_job.py:153} INFO - Started process (PID=28401) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:27:31,970] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:27:31,971] {logging_mixin.py:112} INFO - [2020-04-06 14:27:31,970] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:27:32,268] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:27:32,287] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:27:32,298] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:27:32,300] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.338 seconds
[2020-04-06 14:28:26,156] {scheduler_job.py:153} INFO - Started process (PID=28431) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:28:26,163] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:28:26,167] {logging_mixin.py:112} INFO - [2020-04-06 14:28:26,164] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:28:26,501] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:28:26,525] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:28:26,545] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:28:26,547] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.391 seconds
[2020-04-06 14:29:20,316] {scheduler_job.py:153} INFO - Started process (PID=28460) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:29:20,323] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:29:20,324] {logging_mixin.py:112} INFO - [2020-04-06 14:29:20,323] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:29:20,658] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:29:20,680] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:29:20,692] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:29:20,695] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.381 seconds
[2020-04-06 14:30:14,496] {scheduler_job.py:153} INFO - Started process (PID=28491) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:30:14,502] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:30:14,503] {logging_mixin.py:112} INFO - [2020-04-06 14:30:14,502] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:30:14,872] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:30:14,917] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:30:14,929] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:30:14,931] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.435 seconds
[2020-04-06 14:31:08,637] {scheduler_job.py:153} INFO - Started process (PID=28525) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:31:08,643] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:31:08,644] {logging_mixin.py:112} INFO - [2020-04-06 14:31:08,644] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:31:08,909] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:31:08,933] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:31:08,941] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:31:08,943] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.307 seconds
[2020-04-06 14:32:02,816] {scheduler_job.py:153} INFO - Started process (PID=28555) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:32:02,823] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:32:02,824] {logging_mixin.py:112} INFO - [2020-04-06 14:32:02,824] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:32:03,131] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:32:03,159] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:32:03,167] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:32:03,170] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.354 seconds
[2020-04-06 14:32:56,969] {scheduler_job.py:153} INFO - Started process (PID=28588) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:32:56,976] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:32:56,977] {logging_mixin.py:112} INFO - [2020-04-06 14:32:56,976] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:32:57,267] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:32:57,292] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:32:57,307] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:32:57,309] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.340 seconds
[2020-04-06 14:33:51,133] {scheduler_job.py:153} INFO - Started process (PID=28617) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:33:51,144] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:33:51,145] {logging_mixin.py:112} INFO - [2020-04-06 14:33:51,145] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:33:51,451] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:33:51,483] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:33:51,493] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:33:51,502] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.370 seconds
[2020-04-06 14:34:45,306] {scheduler_job.py:153} INFO - Started process (PID=28647) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:34:45,315] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:34:45,316] {logging_mixin.py:112} INFO - [2020-04-06 14:34:45,315] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:34:45,607] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:34:45,632] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:34:45,642] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:34:45,644] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.337 seconds
[2020-04-06 14:35:39,473] {scheduler_job.py:153} INFO - Started process (PID=28679) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:35:39,486] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:35:39,487] {logging_mixin.py:112} INFO - [2020-04-06 14:35:39,487] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:35:39,866] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:35:39,890] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:35:39,899] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:35:39,902] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.429 seconds
[2020-04-06 14:36:33,651] {scheduler_job.py:153} INFO - Started process (PID=28709) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:36:33,656] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:36:33,657] {logging_mixin.py:112} INFO - [2020-04-06 14:36:33,657] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:36:33,950] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:36:33,967] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:36:33,975] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:36:33,977] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.326 seconds
[2020-04-06 14:37:27,811] {scheduler_job.py:153} INFO - Started process (PID=28741) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:37:27,819] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:37:27,822] {logging_mixin.py:112} INFO - [2020-04-06 14:37:27,821] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:37:28,134] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:37:28,156] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:37:28,164] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:37:28,167] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.356 seconds
[2020-04-06 14:38:21,970] {scheduler_job.py:153} INFO - Started process (PID=28774) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:38:21,976] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:38:21,977] {logging_mixin.py:112} INFO - [2020-04-06 14:38:21,977] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:38:22,316] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:38:22,343] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:38:22,351] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:38:22,353] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.384 seconds
[2020-04-06 14:39:16,123] {scheduler_job.py:153} INFO - Started process (PID=28807) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:39:16,134] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:39:16,136] {logging_mixin.py:112} INFO - [2020-04-06 14:39:16,135] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:39:16,451] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:39:16,479] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:39:16,489] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:39:16,493] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.370 seconds
[2020-04-06 14:40:10,320] {scheduler_job.py:153} INFO - Started process (PID=28838) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:40:10,327] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:40:10,328] {logging_mixin.py:112} INFO - [2020-04-06 14:40:10,328] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:40:10,694] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:40:10,716] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:40:10,725] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:40:10,728] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.408 seconds
[2020-04-06 14:41:04,480] {scheduler_job.py:153} INFO - Started process (PID=28874) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:41:04,488] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:41:04,490] {logging_mixin.py:112} INFO - [2020-04-06 14:41:04,489] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:41:04,807] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:41:04,827] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:41:04,845] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:41:04,847] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.367 seconds
[2020-04-06 14:41:58,628] {scheduler_job.py:153} INFO - Started process (PID=28906) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:41:58,638] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:41:58,640] {logging_mixin.py:112} INFO - [2020-04-06 14:41:58,639] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:41:58,938] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:41:58,961] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:41:58,976] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:41:58,979] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.350 seconds
[2020-04-06 14:42:52,788] {scheduler_job.py:153} INFO - Started process (PID=28939) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:42:52,795] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:42:52,797] {logging_mixin.py:112} INFO - [2020-04-06 14:42:52,796] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:42:53,093] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:42:53,119] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:42:53,129] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:42:53,132] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.344 seconds
[2020-04-06 14:43:46,952] {scheduler_job.py:153} INFO - Started process (PID=28972) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:43:46,958] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:43:46,959] {logging_mixin.py:112} INFO - [2020-04-06 14:43:46,959] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:43:47,238] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:43:47,291] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:43:47,300] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:43:47,302] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.350 seconds
[2020-04-06 14:44:41,129] {scheduler_job.py:153} INFO - Started process (PID=29002) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:44:41,137] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:44:41,139] {logging_mixin.py:112} INFO - [2020-04-06 14:44:41,138] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:44:41,455] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:44:41,488] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:44:41,499] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:44:41,502] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.373 seconds
[2020-04-06 14:45:35,310] {scheduler_job.py:153} INFO - Started process (PID=29045) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:45:35,321] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:45:35,322] {logging_mixin.py:112} INFO - [2020-04-06 14:45:35,322] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:45:35,694] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:45:35,728] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:45:35,744] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:45:35,748] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.438 seconds
[2020-04-06 14:46:29,479] {scheduler_job.py:153} INFO - Started process (PID=29075) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:46:29,487] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:46:29,488] {logging_mixin.py:112} INFO - [2020-04-06 14:46:29,488] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:46:29,811] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:46:29,838] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:46:29,847] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:46:29,849] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.370 seconds
[2020-04-06 14:47:23,649] {scheduler_job.py:153} INFO - Started process (PID=29104) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:47:23,657] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:47:23,658] {logging_mixin.py:112} INFO - [2020-04-06 14:47:23,657] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:47:23,994] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:47:24,021] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:47:24,031] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:47:24,033] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.384 seconds
[2020-04-06 14:48:17,818] {scheduler_job.py:153} INFO - Started process (PID=29134) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:48:17,824] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:48:17,825] {logging_mixin.py:112} INFO - [2020-04-06 14:48:17,825] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:48:18,108] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:48:18,129] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:48:18,143] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:48:18,146] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.327 seconds
[2020-04-06 14:49:11,987] {scheduler_job.py:153} INFO - Started process (PID=29167) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:49:11,992] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:49:11,993] {logging_mixin.py:112} INFO - [2020-04-06 14:49:11,993] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:49:12,301] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:49:12,326] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:49:12,334] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:49:12,337] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.350 seconds
[2020-04-06 14:50:06,171] {scheduler_job.py:153} INFO - Started process (PID=29197) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:50:06,182] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:50:06,185] {logging_mixin.py:112} INFO - [2020-04-06 14:50:06,184] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:50:06,518] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:50:06,535] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:50:06,549] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:50:06,552] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.381 seconds
[2020-04-06 14:51:00,326] {scheduler_job.py:153} INFO - Started process (PID=29227) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:51:00,332] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:51:00,333] {logging_mixin.py:112} INFO - [2020-04-06 14:51:00,333] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:51:00,679] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:51:00,710] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:51:00,721] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:51:00,724] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.397 seconds
[2020-04-06 14:51:54,508] {scheduler_job.py:153} INFO - Started process (PID=29261) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:51:54,516] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:51:54,517] {logging_mixin.py:112} INFO - [2020-04-06 14:51:54,517] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:51:54,814] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:51:54,837] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:51:54,846] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:51:54,849] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.341 seconds
[2020-04-06 14:52:48,699] {scheduler_job.py:153} INFO - Started process (PID=29294) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:52:48,709] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:52:48,711] {logging_mixin.py:112} INFO - [2020-04-06 14:52:48,710] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:52:49,072] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:52:49,105] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:52:49,113] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:52:49,116] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.418 seconds
[2020-04-06 14:53:42,836] {scheduler_job.py:153} INFO - Started process (PID=29342) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:53:42,848] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:53:42,849] {logging_mixin.py:112} INFO - [2020-04-06 14:53:42,849] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:53:43,084] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:53:43,107] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:53:43,115] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:53:43,119] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.283 seconds
[2020-04-06 14:54:36,965] {scheduler_job.py:153} INFO - Started process (PID=29372) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:54:36,972] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:54:36,972] {logging_mixin.py:112} INFO - [2020-04-06 14:54:36,972] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:54:37,217] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:54:37,238] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:54:37,245] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:54:37,247] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.282 seconds
[2020-04-06 14:55:31,066] {scheduler_job.py:153} INFO - Started process (PID=29410) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:55:31,075] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:55:31,076] {logging_mixin.py:112} INFO - [2020-04-06 14:55:31,075] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:55:31,388] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:55:31,410] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:55:31,421] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:55:31,424] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.358 seconds
[2020-04-06 14:56:25,194] {scheduler_job.py:153} INFO - Started process (PID=29447) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:56:25,201] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:56:25,202] {logging_mixin.py:112} INFO - [2020-04-06 14:56:25,201] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:56:25,460] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:56:25,478] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:56:25,487] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:56:25,490] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.295 seconds
[2020-04-06 14:57:19,378] {scheduler_job.py:153} INFO - Started process (PID=29478) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:57:19,395] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:57:19,398] {logging_mixin.py:112} INFO - [2020-04-06 14:57:19,397] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:57:19,872] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:57:19,891] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:57:19,908] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:57:19,910] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.533 seconds
[2020-04-06 14:58:13,556] {scheduler_job.py:153} INFO - Started process (PID=29520) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:58:13,568] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:58:13,569] {logging_mixin.py:112} INFO - [2020-04-06 14:58:13,568] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:58:13,879] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:58:13,918] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:58:13,930] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:58:13,932] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.376 seconds
[2020-04-06 14:59:07,739] {scheduler_job.py:153} INFO - Started process (PID=29550) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:59:07,747] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 14:59:07,748] {logging_mixin.py:112} INFO - [2020-04-06 14:59:07,748] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:59:08,043] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 14:59:08,076] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 14:59:08,088] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 14:59:08,090] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.350 seconds
[2020-04-06 15:00:01,914] {scheduler_job.py:153} INFO - Started process (PID=29581) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:00:01,940] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:00:01,942] {logging_mixin.py:112} INFO - [2020-04-06 15:00:01,942] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:00:02,570] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:00:02,593] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:00:02,602] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:00:02,606] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.692 seconds
[2020-04-06 15:00:56,067] {scheduler_job.py:153} INFO - Started process (PID=29624) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:00:56,072] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:00:56,074] {logging_mixin.py:112} INFO - [2020-04-06 15:00:56,073] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:00:56,367] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:00:56,395] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:00:56,403] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:00:56,406] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.340 seconds
[2020-04-06 15:01:50,227] {scheduler_job.py:153} INFO - Started process (PID=29653) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:01:50,233] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:01:50,236] {logging_mixin.py:112} INFO - [2020-04-06 15:01:50,235] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:01:50,522] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:01:50,542] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:01:50,550] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:01:50,552] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.325 seconds
[2020-04-06 15:02:44,400] {scheduler_job.py:153} INFO - Started process (PID=29686) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:02:44,407] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:02:44,408] {logging_mixin.py:112} INFO - [2020-04-06 15:02:44,408] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:02:44,702] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:02:44,727] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:02:44,736] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:02:44,738] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.338 seconds
[2020-04-06 15:03:38,568] {scheduler_job.py:153} INFO - Started process (PID=29717) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:03:38,578] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:03:38,579] {logging_mixin.py:112} INFO - [2020-04-06 15:03:38,578] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:03:38,890] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:03:38,922] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:03:38,930] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:03:38,939] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.371 seconds
[2020-04-06 15:04:32,733] {scheduler_job.py:153} INFO - Started process (PID=29747) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:04:32,742] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:04:32,744] {logging_mixin.py:112} INFO - [2020-04-06 15:04:32,743] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:04:33,050] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:04:33,075] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:04:33,084] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:04:33,086] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.353 seconds
[2020-04-06 15:05:26,924] {scheduler_job.py:153} INFO - Started process (PID=29788) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:05:26,930] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:05:26,931] {logging_mixin.py:112} INFO - [2020-04-06 15:05:26,931] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:05:27,298] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:05:27,319] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:05:27,327] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:05:27,329] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.405 seconds
[2020-04-06 15:06:21,098] {scheduler_job.py:153} INFO - Started process (PID=29821) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:06:21,104] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:06:21,105] {logging_mixin.py:112} INFO - [2020-04-06 15:06:21,104] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:06:21,481] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:06:21,504] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:06:21,515] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:06:21,518] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.420 seconds
[2020-04-06 15:07:15,276] {scheduler_job.py:153} INFO - Started process (PID=29853) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:07:15,282] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:07:15,283] {logging_mixin.py:112} INFO - [2020-04-06 15:07:15,283] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:07:15,544] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:07:15,568] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:07:15,577] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:07:15,580] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.304 seconds
[2020-04-06 15:08:09,442] {scheduler_job.py:153} INFO - Started process (PID=29884) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:08:09,447] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:08:09,448] {logging_mixin.py:112} INFO - [2020-04-06 15:08:09,448] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:08:09,729] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:08:09,752] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:08:09,768] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:08:09,771] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.330 seconds
[2020-04-06 15:09:03,605] {scheduler_job.py:153} INFO - Started process (PID=29938) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:09:03,614] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:09:03,615] {logging_mixin.py:112} INFO - [2020-04-06 15:09:03,615] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:09:03,911] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:09:03,930] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:09:03,940] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:09:03,942] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.337 seconds
[2020-04-06 15:09:57,787] {scheduler_job.py:153} INFO - Started process (PID=29968) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:09:57,793] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:09:57,795] {logging_mixin.py:112} INFO - [2020-04-06 15:09:57,794] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:09:58,073] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:09:58,100] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:09:58,121] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:09:58,123] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.336 seconds
[2020-04-06 15:10:51,956] {scheduler_job.py:153} INFO - Started process (PID=29998) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:10:51,967] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:10:51,968] {logging_mixin.py:112} INFO - [2020-04-06 15:10:51,968] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:10:52,269] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:10:52,288] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:10:52,298] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:10:52,301] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.345 seconds
[2020-04-06 15:11:46,137] {scheduler_job.py:153} INFO - Started process (PID=30031) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:11:46,144] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:11:46,145] {logging_mixin.py:112} INFO - [2020-04-06 15:11:46,145] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:11:46,555] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:11:46,584] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:11:46,593] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:11:46,597] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.461 seconds
[2020-04-06 15:12:40,303] {scheduler_job.py:153} INFO - Started process (PID=30064) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:12:40,312] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:12:40,316] {logging_mixin.py:112} INFO - [2020-04-06 15:12:40,315] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:12:40,596] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:12:40,626] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:12:40,634] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:12:40,637] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.334 seconds
[2020-04-06 15:13:34,463] {scheduler_job.py:153} INFO - Started process (PID=30116) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:13:34,470] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:13:34,471] {logging_mixin.py:112} INFO - [2020-04-06 15:13:34,470] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:13:34,751] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:13:34,772] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:13:34,781] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:13:34,783] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.320 seconds
[2020-04-06 15:14:28,641] {scheduler_job.py:153} INFO - Started process (PID=30145) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:14:28,647] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:14:28,648] {logging_mixin.py:112} INFO - [2020-04-06 15:14:28,648] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:14:29,010] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:14:29,037] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:14:29,050] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:14:29,052] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.411 seconds
[2020-04-06 15:15:22,835] {scheduler_job.py:153} INFO - Started process (PID=30177) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:15:22,841] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:15:22,845] {logging_mixin.py:112} INFO - [2020-04-06 15:15:22,843] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:15:23,241] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:15:23,287] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:15:23,301] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:15:23,304] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.470 seconds
[2020-04-06 15:16:16,975] {scheduler_job.py:153} INFO - Started process (PID=30207) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:16:16,982] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:16:16,983] {logging_mixin.py:112} INFO - [2020-04-06 15:16:16,983] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:16:17,251] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:16:17,276] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:16:17,284] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:16:17,287] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.312 seconds
[2020-04-06 15:17:11,143] {scheduler_job.py:153} INFO - Started process (PID=30238) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:17:11,149] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:17:11,150] {logging_mixin.py:112} INFO - [2020-04-06 15:17:11,150] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:17:11,442] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:17:11,474] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:17:11,485] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:17:11,487] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.344 seconds
[2020-04-06 15:18:05,287] {scheduler_job.py:153} INFO - Started process (PID=30269) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:18:05,293] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:18:05,294] {logging_mixin.py:112} INFO - [2020-04-06 15:18:05,294] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:18:05,644] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:18:05,669] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:18:05,678] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:18:05,681] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.394 seconds
[2020-04-06 15:18:59,460] {scheduler_job.py:153} INFO - Started process (PID=30302) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:18:59,472] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:18:59,473] {logging_mixin.py:112} INFO - [2020-04-06 15:18:59,472] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:18:59,765] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:18:59,797] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:18:59,805] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:18:59,807] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.347 seconds
[2020-04-06 15:19:53,610] {scheduler_job.py:153} INFO - Started process (PID=30332) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:19:53,616] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:19:53,617] {logging_mixin.py:112} INFO - [2020-04-06 15:19:53,616] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:19:53,961] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:19:53,996] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:19:54,009] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:19:54,011] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.401 seconds
[2020-04-06 15:20:47,756] {scheduler_job.py:153} INFO - Started process (PID=30362) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:20:47,766] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:20:47,768] {logging_mixin.py:112} INFO - [2020-04-06 15:20:47,767] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:20:48,094] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:20:48,128] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:20:48,142] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:20:48,144] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.388 seconds
[2020-04-06 15:21:41,930] {scheduler_job.py:153} INFO - Started process (PID=30392) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:21:41,942] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:21:41,943] {logging_mixin.py:112} INFO - [2020-04-06 15:21:41,943] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:21:42,243] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:21:42,262] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:21:42,273] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:21:42,275] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.345 seconds
[2020-04-06 15:22:36,091] {scheduler_job.py:153} INFO - Started process (PID=30423) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:22:36,098] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:22:36,100] {logging_mixin.py:112} INFO - [2020-04-06 15:22:36,099] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:22:36,369] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:22:36,388] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:22:36,395] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:22:36,398] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.307 seconds
[2020-04-06 15:23:30,255] {scheduler_job.py:153} INFO - Started process (PID=30452) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:23:30,261] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:23:30,262] {logging_mixin.py:112} INFO - [2020-04-06 15:23:30,262] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:23:30,554] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:23:30,578] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:23:30,587] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:23:30,589] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.334 seconds
[2020-04-06 15:24:24,427] {scheduler_job.py:153} INFO - Started process (PID=30483) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:24:24,434] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:24:24,435] {logging_mixin.py:112} INFO - [2020-04-06 15:24:24,434] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:24:24,793] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:24:24,815] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:24:24,825] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:24:24,828] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.401 seconds
[2020-04-06 15:25:18,587] {scheduler_job.py:153} INFO - Started process (PID=30512) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:25:18,595] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:25:18,599] {logging_mixin.py:112} INFO - [2020-04-06 15:25:18,596] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:25:18,997] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:25:19,016] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:25:19,032] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:25:19,035] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.448 seconds
[2020-04-06 15:26:12,750] {scheduler_job.py:153} INFO - Started process (PID=30543) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:26:12,762] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:26:12,763] {logging_mixin.py:112} INFO - [2020-04-06 15:26:12,763] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:26:13,245] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:26:13,295] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:26:13,312] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:26:13,320] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.570 seconds
[2020-04-06 15:27:06,879] {scheduler_job.py:153} INFO - Started process (PID=30575) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:27:06,886] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:27:06,887] {logging_mixin.py:112} INFO - [2020-04-06 15:27:06,887] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:27:07,198] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:27:07,218] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:27:07,229] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:27:07,232] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.352 seconds
[2020-04-06 15:28:01,047] {scheduler_job.py:153} INFO - Started process (PID=30606) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:28:01,055] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:28:01,056] {logging_mixin.py:112} INFO - [2020-04-06 15:28:01,055] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:28:01,404] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:28:01,430] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:28:01,440] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:28:01,444] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.398 seconds
[2020-04-06 15:28:55,224] {scheduler_job.py:153} INFO - Started process (PID=30636) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:28:55,234] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:28:55,235] {logging_mixin.py:112} INFO - [2020-04-06 15:28:55,235] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:28:55,535] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:28:55,559] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:28:55,568] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:28:55,570] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.346 seconds
[2020-04-06 15:29:49,386] {scheduler_job.py:153} INFO - Started process (PID=30665) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:29:49,391] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:29:49,392] {logging_mixin.py:112} INFO - [2020-04-06 15:29:49,392] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:29:49,670] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:29:49,696] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:29:49,714] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:29:49,718] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.333 seconds
[2020-04-06 15:30:43,535] {scheduler_job.py:153} INFO - Started process (PID=30698) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:30:43,542] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:30:43,543] {logging_mixin.py:112} INFO - [2020-04-06 15:30:43,543] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:30:43,829] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:30:43,847] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:30:43,855] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:30:43,857] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.321 seconds
[2020-04-06 15:31:37,664] {scheduler_job.py:153} INFO - Started process (PID=30728) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:31:37,670] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:31:37,671] {logging_mixin.py:112} INFO - [2020-04-06 15:31:37,671] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:31:37,938] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:31:37,964] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:31:37,973] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:31:37,975] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.311 seconds
[2020-04-06 15:32:31,823] {scheduler_job.py:153} INFO - Started process (PID=30757) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:32:31,829] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:32:31,830] {logging_mixin.py:112} INFO - [2020-04-06 15:32:31,830] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:32:32,117] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:32:32,145] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:32:32,153] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:32:32,155] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.332 seconds
[2020-04-06 15:33:25,993] {scheduler_job.py:153} INFO - Started process (PID=30787) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:33:25,999] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:33:26,000] {logging_mixin.py:112} INFO - [2020-04-06 15:33:25,999] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:33:26,256] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:33:26,278] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:33:26,288] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:33:26,290] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.297 seconds
[2020-04-06 15:34:20,142] {scheduler_job.py:153} INFO - Started process (PID=30816) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:34:20,148] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:34:20,149] {logging_mixin.py:112} INFO - [2020-04-06 15:34:20,149] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:34:20,455] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:34:20,476] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:34:20,484] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:34:20,487] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.345 seconds
[2020-04-06 15:35:14,309] {scheduler_job.py:153} INFO - Started process (PID=30846) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:35:14,315] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:35:14,316] {logging_mixin.py:112} INFO - [2020-04-06 15:35:14,316] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:35:14,581] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:35:14,604] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:35:14,615] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:35:14,616] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.308 seconds
[2020-04-06 15:36:08,465] {scheduler_job.py:153} INFO - Started process (PID=30876) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:36:08,475] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:36:08,475] {logging_mixin.py:112} INFO - [2020-04-06 15:36:08,475] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:36:08,761] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:36:08,788] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:36:08,798] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:36:08,801] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.336 seconds
[2020-04-06 15:37:02,629] {scheduler_job.py:153} INFO - Started process (PID=30907) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:37:02,635] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:37:02,636] {logging_mixin.py:112} INFO - [2020-04-06 15:37:02,635] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:37:02,900] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:37:02,924] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:37:02,938] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:37:02,940] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.311 seconds
[2020-04-06 15:37:56,762] {scheduler_job.py:153} INFO - Started process (PID=30937) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:37:56,768] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:37:56,769] {logging_mixin.py:112} INFO - [2020-04-06 15:37:56,768] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:37:57,051] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:37:57,073] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:37:57,081] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:37:57,083] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.321 seconds
[2020-04-06 15:38:50,918] {scheduler_job.py:153} INFO - Started process (PID=30968) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:38:50,927] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:38:50,929] {logging_mixin.py:112} INFO - [2020-04-06 15:38:50,928] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:38:51,194] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:38:51,216] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:38:51,224] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:38:51,226] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.308 seconds
[2020-04-06 15:39:45,089] {scheduler_job.py:153} INFO - Started process (PID=31001) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:39:45,095] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:39:45,097] {logging_mixin.py:112} INFO - [2020-04-06 15:39:45,096] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:39:45,403] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:39:45,427] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:39:45,439] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:39:45,441] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.352 seconds
[2020-04-06 15:40:39,251] {scheduler_job.py:153} INFO - Started process (PID=31031) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:40:39,258] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:40:39,258] {logging_mixin.py:112} INFO - [2020-04-06 15:40:39,258] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:40:39,599] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:40:39,628] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:40:39,643] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:40:39,645] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.394 seconds
[2020-04-06 15:41:33,415] {scheduler_job.py:153} INFO - Started process (PID=31062) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:41:33,421] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:41:33,422] {logging_mixin.py:112} INFO - [2020-04-06 15:41:33,422] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:41:33,702] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:41:33,734] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:41:33,747] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:41:33,749] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.334 seconds
[2020-04-06 15:42:27,592] {scheduler_job.py:153} INFO - Started process (PID=31092) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:42:27,598] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:42:27,599] {logging_mixin.py:112} INFO - [2020-04-06 15:42:27,599] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:42:27,902] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:42:27,919] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:42:27,926] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:42:27,929] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.337 seconds
[2020-04-06 15:43:21,736] {scheduler_job.py:153} INFO - Started process (PID=31121) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:43:21,742] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:43:21,742] {logging_mixin.py:112} INFO - [2020-04-06 15:43:21,742] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:43:22,016] {scheduler_job.py:1572} INFO - DAG(s) dict_keys(['atp_data01']) retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:43:22,053] {scheduler_job.py:1282} INFO - Processing atp_data01
[2020-04-06 15:43:22,063] {scheduler_job.py:446} INFO - Skipping SLA check for <DAG: atp_data01> because no tasks in DAG have SLAs
[2020-04-06 15:43:22,064] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.329 seconds
[2020-04-06 15:44:15,887] {scheduler_job.py:153} INFO - Started process (PID=31154) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:44:15,896] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:44:15,898] {logging_mixin.py:112} INFO - [2020-04-06 15:44:15,897] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:44:15,905] {logging_mixin.py:112} INFO - [2020-04-06 15:44:15,902] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 29
    dag = DAG(
      ^
IndentationError: expected an indented block
[2020-04-06 15:44:15,906] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:44:15,926] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.039 seconds
[2020-04-06 15:45:10,060] {scheduler_job.py:153} INFO - Started process (PID=31189) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:45:10,066] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:45:10,068] {logging_mixin.py:112} INFO - [2020-04-06 15:45:10,067] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:45:10,074] {logging_mixin.py:112} INFO - [2020-04-06 15:45:10,071] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 29
    dag = DAG(
      ^
IndentationError: expected an indented block
[2020-04-06 15:45:10,075] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:45:10,086] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.026 seconds
[2020-04-06 15:46:04,223] {scheduler_job.py:153} INFO - Started process (PID=31219) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:46:04,232] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:46:04,233] {logging_mixin.py:112} INFO - [2020-04-06 15:46:04,233] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:46:04,238] {logging_mixin.py:112} INFO - [2020-04-06 15:46:04,237] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 29
    dag = DAG(
      ^
IndentationError: expected an indented block
[2020-04-06 15:46:04,238] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:46:04,248] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.025 seconds
[2020-04-06 15:46:58,396] {scheduler_job.py:153} INFO - Started process (PID=31259) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:46:58,405] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:46:58,406] {logging_mixin.py:112} INFO - [2020-04-06 15:46:58,406] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:46:58,411] {logging_mixin.py:112} INFO - [2020-04-06 15:46:58,409] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 29
    dag = DAG(
      ^
IndentationError: expected an indented block
[2020-04-06 15:46:58,412] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:46:58,425] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.029 seconds
[2020-04-06 15:47:52,554] {scheduler_job.py:153} INFO - Started process (PID=31289) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:47:52,565] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:47:52,566] {logging_mixin.py:112} INFO - [2020-04-06 15:47:52,565] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:47:52,571] {logging_mixin.py:112} INFO - [2020-04-06 15:47:52,568] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 27
    dag = DAG(
      ^
IndentationError: expected an indented block
[2020-04-06 15:47:52,571] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:47:52,581] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.027 seconds
[2020-04-06 15:48:46,703] {scheduler_job.py:153} INFO - Started process (PID=31321) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:48:46,709] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:48:46,711] {logging_mixin.py:112} INFO - [2020-04-06 15:48:46,710] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:48:47,028] {logging_mixin.py:112} INFO - [2020-04-06 15:48:47,027] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 15:48:47,029] {logging_mixin.py:112} INFO - [2020-04-06 15:48:47,028] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 68, in <module>
    task_id="insert_question_to_db", python_callable=insert_question_to_db
NameError: name 'insert_question_to_db' is not defined
[2020-04-06 15:48:47,030] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:48:47,045] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.342 seconds
[2020-04-06 15:49:40,850] {scheduler_job.py:153} INFO - Started process (PID=31355) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:49:40,857] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:49:40,858] {logging_mixin.py:112} INFO - [2020-04-06 15:49:40,858] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:49:41,137] {logging_mixin.py:112} INFO - [2020-04-06 15:49:41,137] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 15:49:41,139] {logging_mixin.py:112} INFO - [2020-04-06 15:49:41,138] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 67, in <module>
    task_id="insert_question_to_db", python_callable=insert_question_to_db
NameError: name 'insert_question_to_db' is not defined
[2020-04-06 15:49:41,139] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:49:41,153] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.303 seconds
[2020-04-06 15:50:35,025] {scheduler_job.py:153} INFO - Started process (PID=31385) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:50:35,034] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:50:35,035] {logging_mixin.py:112} INFO - [2020-04-06 15:50:35,035] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:50:35,345] {logging_mixin.py:112} INFO - [2020-04-06 15:50:35,344] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 15:50:35,350] {logging_mixin.py:112} INFO - [2020-04-06 15:50:35,345] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 67, in <module>
    task_id="insert_question_to_db", python_callable=insert_question_to_db
NameError: name 'insert_question_to_db' is not defined
[2020-04-06 15:50:35,350] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:50:35,357] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.332 seconds
[2020-04-06 15:51:29,218] {scheduler_job.py:153} INFO - Started process (PID=31414) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:51:29,226] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:51:29,227] {logging_mixin.py:112} INFO - [2020-04-06 15:51:29,227] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:51:29,558] {logging_mixin.py:112} INFO - [2020-04-06 15:51:29,558] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 15:51:29,563] {logging_mixin.py:112} INFO - [2020-04-06 15:51:29,559] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 67, in <module>
    task_id="insert_question_to_db", python_callable=insert_question_to_db
NameError: name 'insert_question_to_db' is not defined
[2020-04-06 15:51:29,563] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:51:29,570] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.352 seconds
[2020-04-06 15:52:23,364] {scheduler_job.py:153} INFO - Started process (PID=31445) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:52:23,369] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:52:23,370] {logging_mixin.py:112} INFO - [2020-04-06 15:52:23,370] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:52:23,653] {logging_mixin.py:112} INFO - [2020-04-06 15:52:23,652] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 15:52:23,655] {logging_mixin.py:112} INFO - [2020-04-06 15:52:23,654] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 67, in <module>
    task_id="insert_question_to_db", python_callable=insert_question_to_db
NameError: name 'insert_question_to_db' is not defined
[2020-04-06 15:52:23,656] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:52:23,667] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.303 seconds
[2020-04-06 15:53:17,494] {scheduler_job.py:153} INFO - Started process (PID=31483) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:53:17,505] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:53:17,506] {logging_mixin.py:112} INFO - [2020-04-06 15:53:17,506] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:53:17,822] {logging_mixin.py:112} INFO - [2020-04-06 15:53:17,821] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 15:53:17,826] {logging_mixin.py:112} INFO - [2020-04-06 15:53:17,823] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 67, in <module>
    task_id="insert_question_to_db", python_callable=insert_question_to_db
NameError: name 'insert_question_to_db' is not defined
[2020-04-06 15:53:17,827] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:53:17,832] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.338 seconds
[2020-04-06 15:54:11,640] {scheduler_job.py:153} INFO - Started process (PID=31516) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:54:11,647] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:54:11,648] {logging_mixin.py:112} INFO - [2020-04-06 15:54:11,648] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:54:11,919] {logging_mixin.py:112} INFO - [2020-04-06 15:54:11,919] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 15:54:11,921] {logging_mixin.py:112} INFO - [2020-04-06 15:54:11,920] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 67, in <module>
    task_id="insert test_csv_to_db", python_callable=insert_question_to_db
NameError: name 'insert_question_to_db' is not defined
[2020-04-06 15:54:11,921] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:54:11,927] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.287 seconds
[2020-04-06 15:55:05,789] {scheduler_job.py:153} INFO - Started process (PID=31548) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:55:05,795] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:55:05,797] {logging_mixin.py:112} INFO - [2020-04-06 15:55:05,796] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:55:06,072] {logging_mixin.py:112} INFO - [2020-04-06 15:55:06,071] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 15:55:06,073] {logging_mixin.py:112} INFO - [2020-04-06 15:55:06,072] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 67, in <module>
    task_id="insert test_csv_to_db", python_callable=insert_question_to_db
NameError: name 'insert_question_to_db' is not defined
[2020-04-06 15:55:06,073] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:55:06,081] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.292 seconds
[2020-04-06 15:55:59,931] {scheduler_job.py:153} INFO - Started process (PID=31579) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:55:59,943] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:55:59,946] {logging_mixin.py:112} INFO - [2020-04-06 15:55:59,945] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:56:00,258] {logging_mixin.py:112} INFO - [2020-04-06 15:56:00,257] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 15:56:00,259] {logging_mixin.py:112} INFO - [2020-04-06 15:56:00,258] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 67, in <module>
    task_id="insert test_csv_to_db", python_callable=insert_question_to_db
NameError: name 'insert_question_to_db' is not defined
[2020-04-06 15:56:00,264] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:56:00,271] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.340 seconds
[2020-04-06 15:56:54,084] {scheduler_job.py:153} INFO - Started process (PID=31613) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:56:54,091] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:56:54,092] {logging_mixin.py:112} INFO - [2020-04-06 15:56:54,092] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:56:54,373] {logging_mixin.py:112} INFO - [2020-04-06 15:56:54,373] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 15:56:54,375] {logging_mixin.py:112} INFO - [2020-04-06 15:56:54,374] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 67, in <module>
    task_id="insert test_csv_to_db", python_callable=insert_question_to_db
NameError: name 'insert_question_to_db' is not defined
[2020-04-06 15:56:54,375] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:56:54,386] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.303 seconds
[2020-04-06 15:57:48,230] {scheduler_job.py:153} INFO - Started process (PID=31642) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:57:48,237] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:57:48,238] {logging_mixin.py:112} INFO - [2020-04-06 15:57:48,238] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:57:48,509] {logging_mixin.py:112} INFO - [2020-04-06 15:57:48,509] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 15:57:48,511] {logging_mixin.py:112} INFO - [2020-04-06 15:57:48,510] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 67, in <module>
    task_id="insert test_csv_to_db", python_callable=insert_question_to_db
NameError: name 'insert_question_to_db' is not defined
[2020-04-06 15:57:48,511] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:57:48,519] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.290 seconds
[2020-04-06 15:58:42,402] {scheduler_job.py:153} INFO - Started process (PID=31674) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:58:42,408] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:58:42,410] {logging_mixin.py:112} INFO - [2020-04-06 15:58:42,410] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:58:42,821] {logging_mixin.py:112} INFO - [2020-04-06 15:58:42,820] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 15:58:42,826] {logging_mixin.py:112} INFO - [2020-04-06 15:58:42,821] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 83, in <module>
    task_id="insert test_csv_to_db", python_callable=insert_question_to_db
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/utils/decorators.py", line 98, in wrapper
    result = func(*args, **kwargs)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/operators/python_operator.py", line 89, in __init__
    super(PythonOperator, self).__init__(*args, **kwargs)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/utils/decorators.py", line 98, in wrapper
    result = func(*args, **kwargs)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 339, in __init__
    validate_key(task_id)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/utils/helpers.py", line 65, in validate_key
    "dots and underscores exclusively".format(k=k))
airflow.exceptions.AirflowException: The key (insert test_csv_to_db) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2020-04-06 15:58:42,827] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:58:42,833] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.431 seconds
[2020-04-06 15:59:36,558] {scheduler_job.py:153} INFO - Started process (PID=31704) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:59:36,564] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 15:59:36,566] {logging_mixin.py:112} INFO - [2020-04-06 15:59:36,565] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:59:36,850] {logging_mixin.py:112} INFO - [2020-04-06 15:59:36,849] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 15:59:36,852] {logging_mixin.py:112} INFO - [2020-04-06 15:59:36,850] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 83, in <module>
    task_id="insert test_csv_to_db", python_callable=insert_question_to_db
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/utils/decorators.py", line 98, in wrapper
    result = func(*args, **kwargs)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/operators/python_operator.py", line 89, in __init__
    super(PythonOperator, self).__init__(*args, **kwargs)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/utils/decorators.py", line 98, in wrapper
    result = func(*args, **kwargs)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 339, in __init__
    validate_key(task_id)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/utils/helpers.py", line 65, in validate_key
    "dots and underscores exclusively".format(k=k))
airflow.exceptions.AirflowException: The key (insert test_csv_to_db) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2020-04-06 15:59:36,852] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 15:59:36,858] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.301 seconds
[2020-04-06 16:00:30,730] {scheduler_job.py:153} INFO - Started process (PID=31735) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:00:30,740] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:00:30,741] {logging_mixin.py:112} INFO - [2020-04-06 16:00:30,741] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:00:31,030] {logging_mixin.py:112} INFO - [2020-04-06 16:00:31,030] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:00:31,033] {logging_mixin.py:112} INFO - [2020-04-06 16:00:31,031] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 83, in <module>
    task_id="insert test_csv_to_db", python_callable=insert_question_to_db
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/utils/decorators.py", line 98, in wrapper
    result = func(*args, **kwargs)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/operators/python_operator.py", line 89, in __init__
    super(PythonOperator, self).__init__(*args, **kwargs)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/utils/decorators.py", line 98, in wrapper
    result = func(*args, **kwargs)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 339, in __init__
    validate_key(task_id)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/utils/helpers.py", line 65, in validate_key
    "dots and underscores exclusively".format(k=k))
airflow.exceptions.AirflowException: The key (insert test_csv_to_db) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2020-04-06 16:00:31,033] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:00:31,045] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.315 seconds
[2020-04-06 16:01:24,886] {scheduler_job.py:153} INFO - Started process (PID=31764) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:01:24,892] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:01:24,893] {logging_mixin.py:112} INFO - [2020-04-06 16:01:24,893] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:01:25,157] {logging_mixin.py:112} INFO - [2020-04-06 16:01:25,156] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:01:25,160] {logging_mixin.py:112} INFO - [2020-04-06 16:01:25,158] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 83, in <module>
    task_id="insert test_csv_to_db", python_callable=insert_question_to_db
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/utils/decorators.py", line 98, in wrapper
    result = func(*args, **kwargs)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/operators/python_operator.py", line 89, in __init__
    super(PythonOperator, self).__init__(*args, **kwargs)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/utils/decorators.py", line 98, in wrapper
    result = func(*args, **kwargs)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 339, in __init__
    validate_key(task_id)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/utils/helpers.py", line 65, in validate_key
    "dots and underscores exclusively".format(k=k))
airflow.exceptions.AirflowException: The key (insert test_csv_to_db) has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2020-04-06 16:01:25,160] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:01:25,168] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.282 seconds
[2020-04-06 16:02:19,051] {scheduler_job.py:153} INFO - Started process (PID=31794) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:02:19,058] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:02:19,059] {logging_mixin.py:112} INFO - [2020-04-06 16:02:19,059] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:02:19,063] {logging_mixin.py:112} INFO - [2020-04-06 16:02:19,062] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 59
    rows = call_stack_overflow_api()
    ^
IndentationError: unexpected indent
[2020-04-06 16:02:19,064] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:02:19,079] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.029 seconds
[2020-04-06 16:03:13,221] {scheduler_job.py:153} INFO - Started process (PID=31825) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:03:13,227] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:03:13,227] {logging_mixin.py:112} INFO - [2020-04-06 16:03:13,227] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:03:13,231] {logging_mixin.py:112} INFO - [2020-04-06 16:03:13,230] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 47
    rows = call_stack_overflow_api()
    ^
IndentationError: unexpected indent
[2020-04-06 16:03:13,231] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:03:13,247] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.026 seconds
[2020-04-06 16:04:07,393] {scheduler_job.py:153} INFO - Started process (PID=31862) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:04:07,400] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:04:07,401] {logging_mixin.py:112} INFO - [2020-04-06 16:04:07,400] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:04:07,404] {logging_mixin.py:112} INFO - [2020-04-06 16:04:07,403] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 47
    rows = call_stack_overflow_api()
    ^
IndentationError: unexpected indent
[2020-04-06 16:04:07,405] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:04:07,425] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.032 seconds
[2020-04-06 16:05:01,603] {scheduler_job.py:153} INFO - Started process (PID=31892) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:05:01,621] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:05:01,624] {logging_mixin.py:112} INFO - [2020-04-06 16:05:01,624] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:05:01,631] {logging_mixin.py:112} INFO - [2020-04-06 16:05:01,627] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 47
    rows = call_stack_overflow_api()
    ^
IndentationError: unexpected indent
[2020-04-06 16:05:01,631] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:05:01,646] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.043 seconds
[2020-04-06 16:05:55,749] {scheduler_job.py:153} INFO - Started process (PID=31925) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:05:55,755] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:05:55,756] {logging_mixin.py:112} INFO - [2020-04-06 16:05:55,756] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:05:55,760] {logging_mixin.py:112} INFO - [2020-04-06 16:05:55,758] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 47
    rows = call_stack_overflow_api()
    ^
IndentationError: unexpected indent
[2020-04-06 16:05:55,760] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:05:55,770] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.021 seconds
[2020-04-06 16:06:49,921] {scheduler_job.py:153} INFO - Started process (PID=31959) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:06:49,926] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:06:49,928] {logging_mixin.py:112} INFO - [2020-04-06 16:06:49,927] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:06:49,931] {logging_mixin.py:112} INFO - [2020-04-06 16:06:49,930] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 47
    rows = call_stack_overflow_api()
    ^
IndentationError: unexpected indent
[2020-04-06 16:06:49,931] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:06:49,947] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.026 seconds
[2020-04-06 16:07:44,072] {scheduler_job.py:153} INFO - Started process (PID=31990) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:07:44,084] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:07:44,085] {logging_mixin.py:112} INFO - [2020-04-06 16:07:44,085] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:07:44,089] {logging_mixin.py:112} INFO - [2020-04-06 16:07:44,088] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 66
    for row in rows:
      ^
SyntaxError: invalid syntax
[2020-04-06 16:07:44,089] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:07:44,178] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.105 seconds
[2020-04-06 16:08:38,246] {scheduler_job.py:153} INFO - Started process (PID=32021) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:08:38,252] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:08:38,253] {logging_mixin.py:112} INFO - [2020-04-06 16:08:38,253] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:08:38,257] {logging_mixin.py:112} INFO - [2020-04-06 16:08:38,255] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 66
    for row in rows:
      ^
SyntaxError: invalid syntax
[2020-04-06 16:08:38,257] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:08:38,344] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.098 seconds
[2020-04-06 16:09:32,416] {scheduler_job.py:153} INFO - Started process (PID=32063) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:09:32,422] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:09:32,423] {logging_mixin.py:112} INFO - [2020-04-06 16:09:32,423] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:09:32,543] {logging_mixin.py:112} INFO - [2020-04-06 16:09:32,425] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 66
    for row in rows:
      ^
SyntaxError: invalid syntax
[2020-04-06 16:09:32,543] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:09:32,553] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.138 seconds
[2020-04-06 16:10:26,566] {scheduler_job.py:153} INFO - Started process (PID=32095) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:10:26,579] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:10:26,669] {logging_mixin.py:112} INFO - [2020-04-06 16:10:26,580] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:10:26,672] {logging_mixin.py:112} INFO - [2020-04-06 16:10:26,671] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 66
    for row in rows:
      ^
SyntaxError: invalid syntax
[2020-04-06 16:10:26,672] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:10:26,680] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.115 seconds
[2020-04-06 16:11:20,732] {scheduler_job.py:153} INFO - Started process (PID=32125) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:11:20,741] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:11:20,743] {logging_mixin.py:112} INFO - [2020-04-06 16:11:20,742] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:11:20,755] {logging_mixin.py:112} INFO - [2020-04-06 16:11:20,752] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 75
    for row in rows:
      ^
SyntaxError: invalid syntax
[2020-04-06 16:11:20,755] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:11:20,767] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.035 seconds
[2020-04-06 16:12:14,872] {scheduler_job.py:153} INFO - Started process (PID=32156) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:12:14,878] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:12:14,879] {logging_mixin.py:112} INFO - [2020-04-06 16:12:14,878] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:12:14,883] {logging_mixin.py:112} INFO - [2020-04-06 16:12:14,881] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 67
    pg_hook.run(insert_question_query, parameters=row)
          ^
SyntaxError: invalid syntax
[2020-04-06 16:12:14,884] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:12:14,902] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.031 seconds
[2020-04-06 16:13:09,041] {scheduler_job.py:153} INFO - Started process (PID=32197) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:13:09,047] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:13:09,048] {logging_mixin.py:112} INFO - [2020-04-06 16:13:09,048] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:13:09,051] {logging_mixin.py:112} INFO - [2020-04-06 16:13:09,050] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 67
    pg_hook.run(insert_question_query, parameters=row)
          ^
SyntaxError: invalid syntax
[2020-04-06 16:13:09,052] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:13:09,061] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.021 seconds
[2020-04-06 16:14:03,209] {scheduler_job.py:153} INFO - Started process (PID=32232) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:14:03,216] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:14:03,217] {logging_mixin.py:112} INFO - [2020-04-06 16:14:03,216] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:14:03,220] {logging_mixin.py:112} INFO - [2020-04-06 16:14:03,219] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 67
    pg_hook.run(insert_question_query, parameters=row)
          ^
SyntaxError: invalid syntax
[2020-04-06 16:14:03,221] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:14:03,231] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.023 seconds
[2020-04-06 16:14:57,365] {scheduler_job.py:153} INFO - Started process (PID=32264) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:14:57,372] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:14:57,373] {logging_mixin.py:112} INFO - [2020-04-06 16:14:57,373] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:14:57,378] {logging_mixin.py:112} INFO - [2020-04-06 16:14:57,376] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 67
    pg_hook.run(insert_question_query, parameters=row)
          ^
SyntaxError: invalid syntax
[2020-04-06 16:14:57,378] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:14:57,395] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.030 seconds
[2020-04-06 16:15:51,532] {scheduler_job.py:153} INFO - Started process (PID=32294) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:15:51,539] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:15:51,540] {logging_mixin.py:112} INFO - [2020-04-06 16:15:51,540] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:15:51,547] {logging_mixin.py:112} INFO - [2020-04-06 16:15:51,545] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 67
    pg_hook.run(insert_question_query, parameters=row)
          ^
SyntaxError: invalid syntax
[2020-04-06 16:15:51,548] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:15:51,562] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.030 seconds
[2020-04-06 16:16:45,672] {scheduler_job.py:153} INFO - Started process (PID=32327) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:16:45,681] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:16:45,682] {logging_mixin.py:112} INFO - [2020-04-06 16:16:45,682] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:16:45,686] {logging_mixin.py:112} INFO - [2020-04-06 16:16:45,685] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 67
    pg_hook.run(insert_question_query, parameters=row)
          ^
SyntaxError: invalid syntax
[2020-04-06 16:16:45,687] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:16:45,704] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.032 seconds
[2020-04-06 16:17:39,837] {scheduler_job.py:153} INFO - Started process (PID=32358) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:17:39,854] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:17:39,856] {logging_mixin.py:112} INFO - [2020-04-06 16:17:39,856] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:17:39,864] {logging_mixin.py:112} INFO - [2020-04-06 16:17:39,861] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 67
    pg_hook.run(insert_question_query, parameters=row)
          ^
SyntaxError: invalid syntax
[2020-04-06 16:17:39,866] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:17:39,890] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.053 seconds
[2020-04-06 16:18:33,981] {scheduler_job.py:153} INFO - Started process (PID=32388) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:18:33,989] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:18:33,991] {logging_mixin.py:112} INFO - [2020-04-06 16:18:33,990] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:18:33,995] {logging_mixin.py:112} INFO - [2020-04-06 16:18:33,993] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 67
    pg_hook.run(insert_question_query, parameters=row)
          ^
SyntaxError: invalid syntax
[2020-04-06 16:18:33,995] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:18:34,007] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.027 seconds
[2020-04-06 16:19:28,151] {scheduler_job.py:153} INFO - Started process (PID=32420) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:19:28,166] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:19:28,167] {logging_mixin.py:112} INFO - [2020-04-06 16:19:28,167] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:19:28,414] {logging_mixin.py:112} INFO - [2020-04-06 16:19:28,413] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:19:28,416] {logging_mixin.py:112} INFO - [2020-04-06 16:19:28,415] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 66, in <module>
    sql = f"DELETE FROM test.csv; COPY test.csv FROM '{path}' DELIMITER ',' CSV HEADER;",
NameError: name 'path' is not defined
[2020-04-06 16:19:28,416] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:19:28,425] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.274 seconds
[2020-04-06 16:20:22,315] {scheduler_job.py:153} INFO - Started process (PID=32450) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:20:22,321] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:20:22,322] {logging_mixin.py:112} INFO - [2020-04-06 16:20:22,321] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:20:22,564] {logging_mixin.py:112} INFO - [2020-04-06 16:20:22,563] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:20:22,568] {logging_mixin.py:112} INFO - [2020-04-06 16:20:22,565] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 66, in <module>
    sql = f"DELETE FROM test.csv; COPY test.csv FROM '{path}' DELIMITER ',' CSV HEADER;",
NameError: name 'path' is not defined
[2020-04-06 16:20:22,569] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:20:22,580] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.265 seconds
[2020-04-06 16:21:16,464] {scheduler_job.py:153} INFO - Started process (PID=32481) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:21:16,472] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:21:16,473] {logging_mixin.py:112} INFO - [2020-04-06 16:21:16,472] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:21:16,688] {logging_mixin.py:112} INFO - [2020-04-06 16:21:16,687] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:21:16,690] {logging_mixin.py:112} INFO - [2020-04-06 16:21:16,689] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 66, in <module>
    sql = f"DELETE FROM test.csv; COPY test.csv FROM '{path}' DELIMITER ',' CSV HEADER;",
NameError: name 'path' is not defined
[2020-04-06 16:21:16,690] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:21:16,705] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.241 seconds
[2020-04-06 16:22:10,657] {scheduler_job.py:153} INFO - Started process (PID=32516) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:22:10,664] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:22:10,665] {logging_mixin.py:112} INFO - [2020-04-06 16:22:10,664] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:22:10,899] {logging_mixin.py:112} INFO - [2020-04-06 16:22:10,898] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:22:10,900] {logging_mixin.py:112} INFO - [2020-04-06 16:22:10,899] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 71, in <module>
    Task_I >> Task_II >> Task_III
NameError: name 'Task_I' is not defined
[2020-04-06 16:22:10,900] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:22:10,914] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.258 seconds
[2020-04-06 16:23:04,832] {scheduler_job.py:153} INFO - Started process (PID=32547) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:23:04,838] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:23:04,839] {logging_mixin.py:112} INFO - [2020-04-06 16:23:04,839] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:23:05,161] {logging_mixin.py:112} INFO - [2020-04-06 16:23:05,160] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:23:05,162] {logging_mixin.py:112} INFO - [2020-04-06 16:23:05,161] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 71, in <module>
    Task_I >> Task_II >> Task_III
NameError: name 'Task_I' is not defined
[2020-04-06 16:23:05,163] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:23:05,172] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.339 seconds
[2020-04-06 16:23:59,009] {scheduler_job.py:153} INFO - Started process (PID=32583) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:23:59,016] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:23:59,017] {logging_mixin.py:112} INFO - [2020-04-06 16:23:59,017] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:23:59,250] {logging_mixin.py:112} INFO - [2020-04-06 16:23:59,249] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:23:59,261] {logging_mixin.py:112} INFO - [2020-04-06 16:23:59,251] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 71, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:23:59,261] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:23:59,270] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.261 seconds
[2020-04-06 16:24:53,184] {scheduler_job.py:153} INFO - Started process (PID=32613) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:24:53,195] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:24:53,196] {logging_mixin.py:112} INFO - [2020-04-06 16:24:53,196] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:24:53,410] {logging_mixin.py:112} INFO - [2020-04-06 16:24:53,409] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:24:53,412] {logging_mixin.py:112} INFO - [2020-04-06 16:24:53,410] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 71, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:24:53,412] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:24:53,427] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.243 seconds
[2020-04-06 16:25:47,345] {scheduler_job.py:153} INFO - Started process (PID=32643) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:25:47,357] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:25:47,358] {logging_mixin.py:112} INFO - [2020-04-06 16:25:47,358] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:25:47,609] {logging_mixin.py:112} INFO - [2020-04-06 16:25:47,608] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:25:47,614] {logging_mixin.py:112} INFO - [2020-04-06 16:25:47,610] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 71, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:25:47,615] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:25:47,630] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.285 seconds
[2020-04-06 16:26:41,510] {scheduler_job.py:153} INFO - Started process (PID=32678) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:26:41,516] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:26:41,517] {logging_mixin.py:112} INFO - [2020-04-06 16:26:41,517] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:26:41,776] {logging_mixin.py:112} INFO - [2020-04-06 16:26:41,775] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:26:41,778] {logging_mixin.py:112} INFO - [2020-04-06 16:26:41,776] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 71, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:26:41,778] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:26:41,786] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.276 seconds
[2020-04-06 16:27:35,679] {scheduler_job.py:153} INFO - Started process (PID=32710) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:27:35,686] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:27:35,687] {logging_mixin.py:112} INFO - [2020-04-06 16:27:35,686] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:27:36,044] {logging_mixin.py:112} INFO - [2020-04-06 16:27:36,042] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:27:36,046] {logging_mixin.py:112} INFO - [2020-04-06 16:27:36,044] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:27:36,046] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:27:36,055] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.376 seconds
[2020-04-06 16:28:29,850] {scheduler_job.py:153} INFO - Started process (PID=32741) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:28:29,863] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:28:29,864] {logging_mixin.py:112} INFO - [2020-04-06 16:28:29,864] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:28:30,478] {logging_mixin.py:112} INFO - [2020-04-06 16:28:30,474] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:28:30,485] {logging_mixin.py:112} INFO - [2020-04-06 16:28:30,479] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:28:30,485] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:28:30,513] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.663 seconds
[2020-04-06 16:29:24,030] {scheduler_job.py:153} INFO - Started process (PID=32773) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:29:24,041] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:29:24,042] {logging_mixin.py:112} INFO - [2020-04-06 16:29:24,041] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:29:24,277] {logging_mixin.py:112} INFO - [2020-04-06 16:29:24,276] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:29:24,287] {logging_mixin.py:112} INFO - [2020-04-06 16:29:24,277] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:29:24,287] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:29:24,298] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.268 seconds
[2020-04-06 16:30:18,174] {scheduler_job.py:153} INFO - Started process (PID=32805) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:30:18,181] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:30:18,182] {logging_mixin.py:112} INFO - [2020-04-06 16:30:18,182] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:30:18,439] {logging_mixin.py:112} INFO - [2020-04-06 16:30:18,438] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:30:18,442] {logging_mixin.py:112} INFO - [2020-04-06 16:30:18,440] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:30:18,442] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:30:18,460] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.286 seconds
[2020-04-06 16:31:12,329] {scheduler_job.py:153} INFO - Started process (PID=32836) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:31:12,336] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:31:12,337] {logging_mixin.py:112} INFO - [2020-04-06 16:31:12,336] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:31:12,594] {logging_mixin.py:112} INFO - [2020-04-06 16:31:12,593] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:31:12,597] {logging_mixin.py:112} INFO - [2020-04-06 16:31:12,595] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:31:12,597] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:31:12,613] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.284 seconds
[2020-04-06 16:32:06,496] {scheduler_job.py:153} INFO - Started process (PID=32867) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:32:06,503] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:32:06,505] {logging_mixin.py:112} INFO - [2020-04-06 16:32:06,504] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:32:06,739] {logging_mixin.py:112} INFO - [2020-04-06 16:32:06,739] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:32:06,743] {logging_mixin.py:112} INFO - [2020-04-06 16:32:06,740] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:32:06,743] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:32:06,758] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.262 seconds
[2020-04-06 16:33:00,679] {scheduler_job.py:153} INFO - Started process (PID=32902) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:33:00,684] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:33:00,690] {logging_mixin.py:112} INFO - [2020-04-06 16:33:00,689] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:33:00,918] {logging_mixin.py:112} INFO - [2020-04-06 16:33:00,918] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:33:00,924] {logging_mixin.py:112} INFO - [2020-04-06 16:33:00,919] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:33:00,925] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:33:00,934] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.256 seconds
[2020-04-06 16:33:54,850] {scheduler_job.py:153} INFO - Started process (PID=32933) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:33:54,859] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:33:54,860] {logging_mixin.py:112} INFO - [2020-04-06 16:33:54,860] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:33:55,178] {logging_mixin.py:112} INFO - [2020-04-06 16:33:55,177] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:33:55,181] {logging_mixin.py:112} INFO - [2020-04-06 16:33:55,179] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:33:55,181] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:33:55,194] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.344 seconds
[2020-04-06 16:34:49,024] {scheduler_job.py:153} INFO - Started process (PID=33005) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:34:49,029] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:34:49,030] {logging_mixin.py:112} INFO - [2020-04-06 16:34:49,030] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:34:49,290] {logging_mixin.py:112} INFO - [2020-04-06 16:34:49,289] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:34:49,294] {logging_mixin.py:112} INFO - [2020-04-06 16:34:49,292] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:34:49,295] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:34:49,308] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.284 seconds
[2020-04-06 16:35:43,167] {scheduler_job.py:153} INFO - Started process (PID=33048) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:35:43,179] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:35:43,180] {logging_mixin.py:112} INFO - [2020-04-06 16:35:43,179] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:35:43,466] {logging_mixin.py:112} INFO - [2020-04-06 16:35:43,465] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:35:43,468] {logging_mixin.py:112} INFO - [2020-04-06 16:35:43,466] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:35:43,468] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:35:43,484] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.317 seconds
[2020-04-06 16:36:37,336] {scheduler_job.py:153} INFO - Started process (PID=33330) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:36:37,341] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:36:37,342] {logging_mixin.py:112} INFO - [2020-04-06 16:36:37,342] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:36:37,701] {logging_mixin.py:112} INFO - [2020-04-06 16:36:37,699] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:36:37,736] {logging_mixin.py:112} INFO - [2020-04-06 16:36:37,702] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:36:37,737] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:36:37,758] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.422 seconds
[2020-04-06 16:37:31,539] {scheduler_job.py:153} INFO - Started process (PID=33462) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:37:31,561] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:37:31,563] {logging_mixin.py:112} INFO - [2020-04-06 16:37:31,562] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:37:32,201] {logging_mixin.py:112} INFO - [2020-04-06 16:37:32,200] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:37:32,228] {logging_mixin.py:112} INFO - [2020-04-06 16:37:32,202] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:37:32,230] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:37:32,247] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.709 seconds
[2020-04-06 16:38:25,743] {scheduler_job.py:153} INFO - Started process (PID=33492) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:38:25,751] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:38:25,756] {logging_mixin.py:112} INFO - [2020-04-06 16:38:25,755] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:38:26,061] {logging_mixin.py:112} INFO - [2020-04-06 16:38:26,059] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:38:26,102] {logging_mixin.py:112} INFO - [2020-04-06 16:38:26,061] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:38:26,103] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:38:26,114] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.371 seconds
[2020-04-06 16:39:19,915] {scheduler_job.py:153} INFO - Started process (PID=33525) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:39:19,948] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:39:19,949] {logging_mixin.py:112} INFO - [2020-04-06 16:39:19,949] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:39:20,266] {logging_mixin.py:112} INFO - [2020-04-06 16:39:20,264] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:39:20,275] {logging_mixin.py:112} INFO - [2020-04-06 16:39:20,266] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:39:20,276] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:39:20,285] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.370 seconds
[2020-04-06 16:40:14,103] {scheduler_job.py:153} INFO - Started process (PID=33557) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:40:14,120] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:40:14,123] {logging_mixin.py:112} INFO - [2020-04-06 16:40:14,122] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:40:14,464] {logging_mixin.py:112} INFO - [2020-04-06 16:40:14,463] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:40:14,474] {logging_mixin.py:112} INFO - [2020-04-06 16:40:14,465] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:40:14,475] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:40:14,484] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.381 seconds
[2020-04-06 16:41:08,329] {scheduler_job.py:153} INFO - Started process (PID=33591) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:41:08,345] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:41:08,347] {logging_mixin.py:112} INFO - [2020-04-06 16:41:08,346] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:41:08,667] {logging_mixin.py:112} INFO - [2020-04-06 16:41:08,664] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:41:08,678] {logging_mixin.py:112} INFO - [2020-04-06 16:41:08,672] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:41:08,679] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:41:08,692] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.362 seconds
[2020-04-06 16:42:02,534] {scheduler_job.py:153} INFO - Started process (PID=33622) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:42:02,556] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:42:02,558] {logging_mixin.py:112} INFO - [2020-04-06 16:42:02,557] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:42:02,854] {logging_mixin.py:112} INFO - [2020-04-06 16:42:02,853] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:42:02,859] {logging_mixin.py:112} INFO - [2020-04-06 16:42:02,854] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:42:02,859] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:42:02,869] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.335 seconds
[2020-04-06 16:42:56,760] {scheduler_job.py:153} INFO - Started process (PID=33669) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:42:56,788] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:42:56,792] {logging_mixin.py:112} INFO - [2020-04-06 16:42:56,791] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:42:57,400] {logging_mixin.py:112} INFO - [2020-04-06 16:42:57,399] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:42:57,408] {logging_mixin.py:112} INFO - [2020-04-06 16:42:57,401] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:42:57,408] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:42:57,423] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.664 seconds
[2020-04-06 16:43:50,891] {scheduler_job.py:153} INFO - Started process (PID=33700) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:43:50,899] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:43:50,900] {logging_mixin.py:112} INFO - [2020-04-06 16:43:50,899] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:43:51,207] {logging_mixin.py:112} INFO - [2020-04-06 16:43:51,206] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:43:51,213] {logging_mixin.py:112} INFO - [2020-04-06 16:43:51,208] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:43:51,213] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:43:51,228] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.337 seconds
[2020-04-06 16:44:45,076] {scheduler_job.py:153} INFO - Started process (PID=33739) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:44:45,091] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:44:45,093] {logging_mixin.py:112} INFO - [2020-04-06 16:44:45,092] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:44:45,569] {logging_mixin.py:112} INFO - [2020-04-06 16:44:45,567] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:44:45,576] {logging_mixin.py:112} INFO - [2020-04-06 16:44:45,570] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:44:45,578] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:44:45,588] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.512 seconds
[2020-04-06 16:45:39,268] {scheduler_job.py:153} INFO - Started process (PID=33772) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:45:39,276] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:45:39,277] {logging_mixin.py:112} INFO - [2020-04-06 16:45:39,277] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:45:39,609] {logging_mixin.py:112} INFO - [2020-04-06 16:45:39,597] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:45:39,611] {logging_mixin.py:112} INFO - [2020-04-06 16:45:39,609] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:45:39,612] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:45:39,629] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.360 seconds
[2020-04-06 16:46:33,396] {scheduler_job.py:153} INFO - Started process (PID=33814) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:46:33,405] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:46:33,406] {logging_mixin.py:112} INFO - [2020-04-06 16:46:33,405] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:46:33,773] {logging_mixin.py:112} INFO - [2020-04-06 16:46:33,772] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:46:33,775] {logging_mixin.py:112} INFO - [2020-04-06 16:46:33,774] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:46:33,776] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:46:33,796] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.401 seconds
[2020-04-06 16:47:27,595] {scheduler_job.py:153} INFO - Started process (PID=33847) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:47:27,608] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:47:27,610] {logging_mixin.py:112} INFO - [2020-04-06 16:47:27,609] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:47:28,226] {logging_mixin.py:112} INFO - [2020-04-06 16:47:28,222] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:47:28,229] {logging_mixin.py:112} INFO - [2020-04-06 16:47:28,227] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:47:28,244] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:47:28,258] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.664 seconds
[2020-04-06 16:48:21,743] {scheduler_job.py:153} INFO - Started process (PID=33876) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:48:21,750] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:48:21,752] {logging_mixin.py:112} INFO - [2020-04-06 16:48:21,751] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:48:22,061] {logging_mixin.py:112} INFO - [2020-04-06 16:48:22,060] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:48:22,065] {logging_mixin.py:112} INFO - [2020-04-06 16:48:22,062] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:48:22,066] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:48:22,082] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.339 seconds
[2020-04-06 16:49:15,909] {scheduler_job.py:153} INFO - Started process (PID=33914) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:49:15,923] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:49:15,924] {logging_mixin.py:112} INFO - [2020-04-06 16:49:15,924] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:49:16,205] {logging_mixin.py:112} INFO - [2020-04-06 16:49:16,204] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:49:16,215] {logging_mixin.py:112} INFO - [2020-04-06 16:49:16,206] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:49:16,216] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:49:16,228] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.318 seconds
[2020-04-06 16:50:10,091] {scheduler_job.py:153} INFO - Started process (PID=33944) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:50:10,097] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:50:10,098] {logging_mixin.py:112} INFO - [2020-04-06 16:50:10,098] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:50:10,383] {logging_mixin.py:112} INFO - [2020-04-06 16:50:10,377] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:50:10,387] {logging_mixin.py:112} INFO - [2020-04-06 16:50:10,385] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:50:10,387] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:50:10,402] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.311 seconds
[2020-04-06 16:51:04,244] {scheduler_job.py:153} INFO - Started process (PID=33996) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:51:04,254] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:51:04,259] {logging_mixin.py:112} INFO - [2020-04-06 16:51:04,257] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:51:04,564] {logging_mixin.py:112} INFO - [2020-04-06 16:51:04,562] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:51:04,567] {logging_mixin.py:112} INFO - [2020-04-06 16:51:04,565] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:51:04,567] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:51:04,582] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.338 seconds
[2020-04-06 16:51:58,419] {scheduler_job.py:153} INFO - Started process (PID=34026) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:51:58,431] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:51:58,432] {logging_mixin.py:112} INFO - [2020-04-06 16:51:58,432] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:51:58,752] {logging_mixin.py:112} INFO - [2020-04-06 16:51:58,751] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:51:58,763] {logging_mixin.py:112} INFO - [2020-04-06 16:51:58,752] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:51:58,764] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:51:58,774] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.355 seconds
[2020-04-06 16:52:52,580] {scheduler_job.py:153} INFO - Started process (PID=34055) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:52:52,588] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:52:52,589] {logging_mixin.py:112} INFO - [2020-04-06 16:52:52,589] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:52:52,903] {logging_mixin.py:112} INFO - [2020-04-06 16:52:52,899] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:52:52,905] {logging_mixin.py:112} INFO - [2020-04-06 16:52:52,903] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:52:52,906] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:52:52,922] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.342 seconds
[2020-04-06 16:53:46,746] {scheduler_job.py:153} INFO - Started process (PID=34087) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:53:46,759] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:53:46,760] {logging_mixin.py:112} INFO - [2020-04-06 16:53:46,760] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:53:46,991] {logging_mixin.py:112} INFO - [2020-04-06 16:53:46,990] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:53:46,993] {logging_mixin.py:112} INFO - [2020-04-06 16:53:46,991] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:53:46,993] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:53:47,011] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.264 seconds
[2020-04-06 16:54:40,917] {scheduler_job.py:153} INFO - Started process (PID=34117) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:54:40,924] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:54:40,925] {logging_mixin.py:112} INFO - [2020-04-06 16:54:40,924] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:54:41,199] {logging_mixin.py:112} INFO - [2020-04-06 16:54:41,197] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:54:41,201] {logging_mixin.py:112} INFO - [2020-04-06 16:54:41,199] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:54:41,202] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:54:41,216] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.299 seconds
[2020-04-06 16:55:35,086] {scheduler_job.py:153} INFO - Started process (PID=34148) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:55:35,100] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:55:35,101] {logging_mixin.py:112} INFO - [2020-04-06 16:55:35,100] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:55:35,337] {logging_mixin.py:112} INFO - [2020-04-06 16:55:35,336] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:55:35,344] {logging_mixin.py:112} INFO - [2020-04-06 16:55:35,338] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:55:35,346] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:55:35,356] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.269 seconds
[2020-04-06 16:56:29,320] {scheduler_job.py:153} INFO - Started process (PID=34230) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:56:29,327] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:56:29,330] {logging_mixin.py:112} INFO - [2020-04-06 16:56:29,328] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:56:29,718] {logging_mixin.py:112} INFO - [2020-04-06 16:56:29,717] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:56:29,721] {logging_mixin.py:112} INFO - [2020-04-06 16:56:29,720] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:56:29,722] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:56:29,770] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.450 seconds
[2020-04-06 16:57:23,461] {scheduler_job.py:153} INFO - Started process (PID=34261) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:57:23,469] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:57:23,470] {logging_mixin.py:112} INFO - [2020-04-06 16:57:23,470] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:57:23,704] {logging_mixin.py:112} INFO - [2020-04-06 16:57:23,703] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:57:23,707] {logging_mixin.py:112} INFO - [2020-04-06 16:57:23,705] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:57:23,707] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:57:23,718] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.257 seconds
[2020-04-06 16:58:17,625] {scheduler_job.py:153} INFO - Started process (PID=34291) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:58:17,635] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:58:17,636] {logging_mixin.py:112} INFO - [2020-04-06 16:58:17,636] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:58:17,863] {logging_mixin.py:112} INFO - [2020-04-06 16:58:17,862] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:58:17,866] {logging_mixin.py:112} INFO - [2020-04-06 16:58:17,865] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:58:17,867] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:58:17,882] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.257 seconds
[2020-04-06 16:59:11,793] {scheduler_job.py:153} INFO - Started process (PID=34321) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:59:11,801] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 16:59:11,803] {logging_mixin.py:112} INFO - [2020-04-06 16:59:11,802] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:59:12,025] {logging_mixin.py:112} INFO - [2020-04-06 16:59:12,023] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 16:59:12,029] {logging_mixin.py:112} INFO - [2020-04-06 16:59:12,026] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 16:59:12,030] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 16:59:12,045] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.252 seconds
[2020-04-06 17:00:05,979] {scheduler_job.py:153} INFO - Started process (PID=34352) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:00:05,985] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:00:05,986] {logging_mixin.py:112} INFO - [2020-04-06 17:00:05,986] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:00:06,223] {logging_mixin.py:112} INFO - [2020-04-06 17:00:06,222] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:00:06,226] {logging_mixin.py:112} INFO - [2020-04-06 17:00:06,224] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:00:06,227] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:00:06,236] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.257 seconds
[2020-04-06 17:01:00,137] {scheduler_job.py:153} INFO - Started process (PID=34455) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:01:00,145] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:01:00,153] {logging_mixin.py:112} INFO - [2020-04-06 17:01:00,152] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:01:00,425] {logging_mixin.py:112} INFO - [2020-04-06 17:01:00,424] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:01:00,429] {logging_mixin.py:112} INFO - [2020-04-06 17:01:00,426] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:01:00,429] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:01:00,442] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.305 seconds
[2020-04-06 17:01:54,294] {scheduler_job.py:153} INFO - Started process (PID=34493) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:01:54,305] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:01:54,306] {logging_mixin.py:112} INFO - [2020-04-06 17:01:54,306] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:01:54,571] {logging_mixin.py:112} INFO - [2020-04-06 17:01:54,570] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:01:54,573] {logging_mixin.py:112} INFO - [2020-04-06 17:01:54,571] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:01:54,573] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:01:54,588] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.293 seconds
[2020-04-06 17:02:48,524] {scheduler_job.py:153} INFO - Started process (PID=34522) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:02:48,532] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:02:48,533] {logging_mixin.py:112} INFO - [2020-04-06 17:02:48,533] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:02:48,762] {logging_mixin.py:112} INFO - [2020-04-06 17:02:48,761] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:02:48,764] {logging_mixin.py:112} INFO - [2020-04-06 17:02:48,762] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:02:48,764] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:02:48,774] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.250 seconds
[2020-04-06 17:03:42,840] {scheduler_job.py:153} INFO - Started process (PID=34553) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:03:42,849] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:03:42,850] {logging_mixin.py:112} INFO - [2020-04-06 17:03:42,850] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:03:43,286] {logging_mixin.py:112} INFO - [2020-04-06 17:03:43,285] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:03:43,291] {logging_mixin.py:112} INFO - [2020-04-06 17:03:43,287] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:03:43,292] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:03:43,303] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.463 seconds
[2020-04-06 17:04:37,004] {scheduler_job.py:153} INFO - Started process (PID=34594) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:04:37,016] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:04:37,017] {logging_mixin.py:112} INFO - [2020-04-06 17:04:37,017] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:04:37,429] {logging_mixin.py:112} INFO - [2020-04-06 17:04:37,426] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:04:37,436] {logging_mixin.py:112} INFO - [2020-04-06 17:04:37,431] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:04:37,437] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:04:37,452] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.448 seconds
[2020-04-06 17:05:31,147] {scheduler_job.py:153} INFO - Started process (PID=34633) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:05:31,157] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:05:31,160] {logging_mixin.py:112} INFO - [2020-04-06 17:05:31,158] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:05:32,081] {logging_mixin.py:112} INFO - [2020-04-06 17:05:32,080] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:05:32,086] {logging_mixin.py:112} INFO - [2020-04-06 17:05:32,082] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:05:32,086] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:05:32,106] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.959 seconds
[2020-04-06 17:06:25,318] {scheduler_job.py:153} INFO - Started process (PID=34699) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:06:25,327] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:06:25,330] {logging_mixin.py:112} INFO - [2020-04-06 17:06:25,328] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:06:26,379] {logging_mixin.py:112} INFO - [2020-04-06 17:06:26,378] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:06:26,387] {logging_mixin.py:112} INFO - [2020-04-06 17:06:26,380] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:06:26,388] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:06:26,411] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 1.093 seconds
[2020-04-06 17:07:19,499] {scheduler_job.py:153} INFO - Started process (PID=34734) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:07:19,512] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:07:19,513] {logging_mixin.py:112} INFO - [2020-04-06 17:07:19,513] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:07:19,855] {logging_mixin.py:112} INFO - [2020-04-06 17:07:19,852] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:07:19,864] {logging_mixin.py:112} INFO - [2020-04-06 17:07:19,857] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:07:19,864] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:07:19,883] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.383 seconds
[2020-04-06 17:08:13,645] {scheduler_job.py:153} INFO - Started process (PID=34769) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:08:13,657] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:08:13,658] {logging_mixin.py:112} INFO - [2020-04-06 17:08:13,658] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:08:13,937] {logging_mixin.py:112} INFO - [2020-04-06 17:08:13,935] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:08:13,950] {logging_mixin.py:112} INFO - [2020-04-06 17:08:13,941] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:08:13,952] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:08:13,965] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.321 seconds
[2020-04-06 17:09:07,807] {scheduler_job.py:153} INFO - Started process (PID=34804) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:09:07,821] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:09:07,822] {logging_mixin.py:112} INFO - [2020-04-06 17:09:07,822] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:09:08,087] {logging_mixin.py:112} INFO - [2020-04-06 17:09:08,086] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:09:08,090] {logging_mixin.py:112} INFO - [2020-04-06 17:09:08,088] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:09:08,090] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:09:08,100] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.292 seconds
[2020-04-06 17:10:01,991] {scheduler_job.py:153} INFO - Started process (PID=34834) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:10:01,998] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:10:01,999] {logging_mixin.py:112} INFO - [2020-04-06 17:10:01,999] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:10:02,213] {logging_mixin.py:112} INFO - [2020-04-06 17:10:02,213] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:10:02,216] {logging_mixin.py:112} INFO - [2020-04-06 17:10:02,214] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:10:02,216] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:10:02,228] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.237 seconds
[2020-04-06 17:10:56,166] {scheduler_job.py:153} INFO - Started process (PID=34867) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:10:56,175] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:10:56,176] {logging_mixin.py:112} INFO - [2020-04-06 17:10:56,175] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:10:56,445] {logging_mixin.py:112} INFO - [2020-04-06 17:10:56,445] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:10:56,450] {logging_mixin.py:112} INFO - [2020-04-06 17:10:56,446] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:10:56,451] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:10:56,506] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.339 seconds
[2020-04-06 17:11:50,318] {scheduler_job.py:153} INFO - Started process (PID=34896) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:11:50,324] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:11:50,326] {logging_mixin.py:112} INFO - [2020-04-06 17:11:50,326] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:11:50,567] {logging_mixin.py:112} INFO - [2020-04-06 17:11:50,566] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:11:50,572] {logging_mixin.py:112} INFO - [2020-04-06 17:11:50,570] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:11:50,573] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:11:50,582] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.264 seconds
[2020-04-06 17:12:44,485] {scheduler_job.py:153} INFO - Started process (PID=34929) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:12:44,491] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:12:44,492] {logging_mixin.py:112} INFO - [2020-04-06 17:12:44,492] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:12:44,710] {logging_mixin.py:112} INFO - [2020-04-06 17:12:44,710] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:12:44,713] {logging_mixin.py:112} INFO - [2020-04-06 17:12:44,711] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:12:44,714] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:12:44,722] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.237 seconds
[2020-04-06 17:13:38,653] {scheduler_job.py:153} INFO - Started process (PID=34961) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:13:38,660] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:13:38,661] {logging_mixin.py:112} INFO - [2020-04-06 17:13:38,661] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:13:38,895] {logging_mixin.py:112} INFO - [2020-04-06 17:13:38,894] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:13:38,898] {logging_mixin.py:112} INFO - [2020-04-06 17:13:38,896] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:13:38,899] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:13:38,908] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.255 seconds
[2020-04-06 17:14:32,830] {scheduler_job.py:153} INFO - Started process (PID=34992) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:14:32,841] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:14:32,842] {logging_mixin.py:112} INFO - [2020-04-06 17:14:32,842] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:14:33,036] {logging_mixin.py:112} INFO - [2020-04-06 17:14:33,036] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:14:33,039] {logging_mixin.py:112} INFO - [2020-04-06 17:14:33,037] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:14:33,039] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:14:33,055] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.226 seconds
[2020-04-06 17:15:27,014] {scheduler_job.py:153} INFO - Started process (PID=35024) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:15:27,021] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:15:27,022] {logging_mixin.py:112} INFO - [2020-04-06 17:15:27,022] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:15:27,231] {logging_mixin.py:112} INFO - [2020-04-06 17:15:27,230] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:15:27,233] {logging_mixin.py:112} INFO - [2020-04-06 17:15:27,231] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:15:27,233] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:15:27,242] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.229 seconds
[2020-04-06 17:16:21,174] {scheduler_job.py:153} INFO - Started process (PID=35058) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:16:21,180] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:16:21,181] {logging_mixin.py:112} INFO - [2020-04-06 17:16:21,180] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:16:21,402] {logging_mixin.py:112} INFO - [2020-04-06 17:16:21,401] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:16:21,405] {logging_mixin.py:112} INFO - [2020-04-06 17:16:21,403] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:16:21,405] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:16:21,423] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.249 seconds
[2020-04-06 17:17:15,344] {scheduler_job.py:153} INFO - Started process (PID=35088) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:17:15,350] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:17:15,351] {logging_mixin.py:112} INFO - [2020-04-06 17:17:15,351] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:17:15,842] {logging_mixin.py:112} INFO - [2020-04-06 17:17:15,841] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:17:15,845] {logging_mixin.py:112} INFO - [2020-04-06 17:17:15,843] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:17:15,846] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:17:15,858] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.514 seconds
[2020-04-06 17:18:09,500] {scheduler_job.py:153} INFO - Started process (PID=35124) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:18:09,512] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:18:09,513] {logging_mixin.py:112} INFO - [2020-04-06 17:18:09,513] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:18:09,725] {logging_mixin.py:112} INFO - [2020-04-06 17:18:09,724] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:18:09,737] {logging_mixin.py:112} INFO - [2020-04-06 17:18:09,726] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:18:09,737] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:18:09,747] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.247 seconds
[2020-04-06 17:19:03,651] {scheduler_job.py:153} INFO - Started process (PID=35154) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:19:03,657] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:19:03,658] {logging_mixin.py:112} INFO - [2020-04-06 17:19:03,658] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:19:03,862] {logging_mixin.py:112} INFO - [2020-04-06 17:19:03,860] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:19:03,864] {logging_mixin.py:112} INFO - [2020-04-06 17:19:03,863] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:19:03,865] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:19:03,873] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.222 seconds
[2020-04-06 17:19:57,821] {scheduler_job.py:153} INFO - Started process (PID=35186) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:19:57,829] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:19:57,831] {logging_mixin.py:112} INFO - [2020-04-06 17:19:57,830] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:19:58,072] {logging_mixin.py:112} INFO - [2020-04-06 17:19:58,071] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:19:58,077] {logging_mixin.py:112} INFO - [2020-04-06 17:19:58,073] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:19:58,078] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:19:58,092] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.271 seconds
[2020-04-06 17:20:51,972] {scheduler_job.py:153} INFO - Started process (PID=35215) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:20:51,978] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:20:51,979] {logging_mixin.py:112} INFO - [2020-04-06 17:20:51,979] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:20:52,195] {logging_mixin.py:112} INFO - [2020-04-06 17:20:52,194] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:20:52,197] {logging_mixin.py:112} INFO - [2020-04-06 17:20:52,195] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:20:52,198] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:20:52,206] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.234 seconds
[2020-04-06 17:21:46,146] {scheduler_job.py:153} INFO - Started process (PID=35245) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:21:46,154] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:21:46,155] {logging_mixin.py:112} INFO - [2020-04-06 17:21:46,155] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:21:46,367] {logging_mixin.py:112} INFO - [2020-04-06 17:21:46,366] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:21:46,370] {logging_mixin.py:112} INFO - [2020-04-06 17:21:46,367] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:21:46,370] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:21:46,389] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.243 seconds
[2020-04-06 17:22:40,301] {scheduler_job.py:153} INFO - Started process (PID=35277) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:22:40,307] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:22:40,308] {logging_mixin.py:112} INFO - [2020-04-06 17:22:40,308] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:22:40,480] {logging_mixin.py:112} INFO - [2020-04-06 17:22:40,479] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:22:40,482] {logging_mixin.py:112} INFO - [2020-04-06 17:22:40,481] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:22:40,483] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:22:40,497] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.196 seconds
[2020-04-06 17:23:34,459] {scheduler_job.py:153} INFO - Started process (PID=35308) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:23:34,465] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:23:34,466] {logging_mixin.py:112} INFO - [2020-04-06 17:23:34,465] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:23:34,651] {logging_mixin.py:112} INFO - [2020-04-06 17:23:34,650] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:23:34,653] {logging_mixin.py:112} INFO - [2020-04-06 17:23:34,651] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:23:34,653] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:23:34,664] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.205 seconds
[2020-04-06 17:24:28,630] {scheduler_job.py:153} INFO - Started process (PID=35337) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:24:28,635] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:24:28,636] {logging_mixin.py:112} INFO - [2020-04-06 17:24:28,636] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:24:28,811] {logging_mixin.py:112} INFO - [2020-04-06 17:24:28,810] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:24:28,813] {logging_mixin.py:112} INFO - [2020-04-06 17:24:28,812] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:24:28,814] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:24:28,827] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.197 seconds
[2020-04-06 17:25:22,776] {scheduler_job.py:153} INFO - Started process (PID=35374) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:25:22,782] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:25:22,783] {logging_mixin.py:112} INFO - [2020-04-06 17:25:22,783] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:25:22,960] {logging_mixin.py:112} INFO - [2020-04-06 17:25:22,959] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:25:22,962] {logging_mixin.py:112} INFO - [2020-04-06 17:25:22,961] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:25:22,963] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:25:22,977] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.200 seconds
[2020-04-06 17:26:16,922] {scheduler_job.py:153} INFO - Started process (PID=35404) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:26:16,928] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:26:16,929] {logging_mixin.py:112} INFO - [2020-04-06 17:26:16,928] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:26:17,101] {logging_mixin.py:112} INFO - [2020-04-06 17:26:17,100] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:26:17,103] {logging_mixin.py:112} INFO - [2020-04-06 17:26:17,102] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:26:17,104] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:26:17,118] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.196 seconds
[2020-04-06 17:27:11,059] {scheduler_job.py:153} INFO - Started process (PID=35434) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:27:11,064] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:27:11,065] {logging_mixin.py:112} INFO - [2020-04-06 17:27:11,065] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:27:11,238] {logging_mixin.py:112} INFO - [2020-04-06 17:27:11,238] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:27:11,241] {logging_mixin.py:112} INFO - [2020-04-06 17:27:11,239] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:27:11,241] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:27:11,255] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.196 seconds
[2020-04-06 17:28:05,252] {scheduler_job.py:153} INFO - Started process (PID=35468) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:28:05,259] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:28:05,259] {logging_mixin.py:112} INFO - [2020-04-06 17:28:05,259] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:28:05,470] {logging_mixin.py:112} INFO - [2020-04-06 17:28:05,469] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:28:05,472] {logging_mixin.py:112} INFO - [2020-04-06 17:28:05,471] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:28:05,473] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:28:05,481] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.229 seconds
[2020-04-06 17:28:59,528] {scheduler_job.py:153} INFO - Started process (PID=35498) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:28:59,534] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:28:59,535] {logging_mixin.py:112} INFO - [2020-04-06 17:28:59,535] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:28:59,764] {logging_mixin.py:112} INFO - [2020-04-06 17:28:59,763] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:28:59,767] {logging_mixin.py:112} INFO - [2020-04-06 17:28:59,765] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:28:59,768] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:28:59,777] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.250 seconds
[2020-04-06 17:29:53,743] {scheduler_job.py:153} INFO - Started process (PID=35536) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:29:53,749] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:29:53,751] {logging_mixin.py:112} INFO - [2020-04-06 17:29:53,750] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:29:53,953] {logging_mixin.py:112} INFO - [2020-04-06 17:29:53,952] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:29:53,955] {logging_mixin.py:112} INFO - [2020-04-06 17:29:53,954] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:29:53,956] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:29:53,964] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.221 seconds
[2020-04-06 17:30:48,005] {scheduler_job.py:153} INFO - Started process (PID=35567) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:30:48,013] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:30:48,014] {logging_mixin.py:112} INFO - [2020-04-06 17:30:48,014] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:30:48,235] {logging_mixin.py:112} INFO - [2020-04-06 17:30:48,234] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:30:48,237] {logging_mixin.py:112} INFO - [2020-04-06 17:30:48,236] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:30:48,238] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:30:48,251] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.246 seconds
[2020-04-06 17:31:42,241] {scheduler_job.py:153} INFO - Started process (PID=35598) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:31:42,246] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:31:42,247] {logging_mixin.py:112} INFO - [2020-04-06 17:31:42,247] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:31:42,422] {logging_mixin.py:112} INFO - [2020-04-06 17:31:42,422] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:31:42,425] {logging_mixin.py:112} INFO - [2020-04-06 17:31:42,423] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:31:42,425] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:31:42,440] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.199 seconds
[2020-04-06 17:32:36,554] {scheduler_job.py:153} INFO - Started process (PID=35628) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:32:36,560] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:32:36,561] {logging_mixin.py:112} INFO - [2020-04-06 17:32:36,561] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:32:36,734] {logging_mixin.py:112} INFO - [2020-04-06 17:32:36,733] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:32:36,736] {logging_mixin.py:112} INFO - [2020-04-06 17:32:36,734] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:32:36,736] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:32:36,753] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.199 seconds
[2020-04-06 17:33:30,921] {scheduler_job.py:153} INFO - Started process (PID=35658) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:33:30,927] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:33:30,928] {logging_mixin.py:112} INFO - [2020-04-06 17:33:30,928] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:33:31,106] {logging_mixin.py:112} INFO - [2020-04-06 17:33:31,105] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:33:31,108] {logging_mixin.py:112} INFO - [2020-04-06 17:33:31,106] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:33:31,108] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:33:31,122] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.201 seconds
[2020-04-06 17:52:41,892] {scheduler_job.py:153} INFO - Started process (PID=35716) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:52:41,909] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:52:41,911] {logging_mixin.py:112} INFO - [2020-04-06 17:52:41,910] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:52:42,340] {logging_mixin.py:112} INFO - [2020-04-06 17:52:42,339] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:52:42,343] {logging_mixin.py:112} INFO - [2020-04-06 17:52:42,340] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:52:42,344] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:52:42,354] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.462 seconds
[2020-04-06 17:53:13,757] {scheduler_job.py:153} INFO - Started process (PID=35755) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:53:13,766] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:53:13,767] {logging_mixin.py:112} INFO - [2020-04-06 17:53:13,767] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:53:14,228] {logging_mixin.py:112} INFO - [2020-04-06 17:53:14,227] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:53:14,230] {logging_mixin.py:112} INFO - [2020-04-06 17:53:14,228] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:53:14,231] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:53:14,240] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.483 seconds
[2020-04-06 17:54:07,919] {scheduler_job.py:153} INFO - Started process (PID=35787) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:54:07,925] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:54:07,926] {logging_mixin.py:112} INFO - [2020-04-06 17:54:07,926] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:54:08,138] {logging_mixin.py:112} INFO - [2020-04-06 17:54:08,137] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:54:08,141] {logging_mixin.py:112} INFO - [2020-04-06 17:54:08,139] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:54:08,141] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:54:08,157] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.238 seconds
[2020-04-06 17:55:02,026] {scheduler_job.py:153} INFO - Started process (PID=35821) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:55:02,034] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:55:02,035] {logging_mixin.py:112} INFO - [2020-04-06 17:55:02,035] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:55:02,249] {logging_mixin.py:112} INFO - [2020-04-06 17:55:02,248] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:55:02,255] {logging_mixin.py:112} INFO - [2020-04-06 17:55:02,250] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:55:02,256] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:55:02,268] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.241 seconds
[2020-04-06 17:55:56,163] {scheduler_job.py:153} INFO - Started process (PID=35851) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:55:56,170] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:55:56,171] {logging_mixin.py:112} INFO - [2020-04-06 17:55:56,171] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:55:56,367] {logging_mixin.py:112} INFO - [2020-04-06 17:55:56,366] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:55:56,369] {logging_mixin.py:112} INFO - [2020-04-06 17:55:56,368] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:55:56,370] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:55:56,385] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.223 seconds
[2020-04-06 17:56:50,307] {scheduler_job.py:153} INFO - Started process (PID=35886) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:56:50,322] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:56:50,324] {logging_mixin.py:112} INFO - [2020-04-06 17:56:50,323] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:56:50,523] {logging_mixin.py:112} INFO - [2020-04-06 17:56:50,522] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:56:50,531] {logging_mixin.py:112} INFO - [2020-04-06 17:56:50,524] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:56:50,532] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:56:50,541] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.234 seconds
[2020-04-06 17:57:44,476] {scheduler_job.py:153} INFO - Started process (PID=35918) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:57:44,483] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:57:44,484] {logging_mixin.py:112} INFO - [2020-04-06 17:57:44,484] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:57:44,712] {logging_mixin.py:112} INFO - [2020-04-06 17:57:44,711] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:57:44,716] {logging_mixin.py:112} INFO - [2020-04-06 17:57:44,713] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:57:44,717] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:57:44,726] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.250 seconds
[2020-04-06 17:58:38,633] {scheduler_job.py:153} INFO - Started process (PID=35958) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:58:38,643] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:58:38,644] {logging_mixin.py:112} INFO - [2020-04-06 17:58:38,644] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:58:38,856] {logging_mixin.py:112} INFO - [2020-04-06 17:58:38,855] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:58:38,860] {logging_mixin.py:112} INFO - [2020-04-06 17:58:38,857] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:58:38,860] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:58:38,870] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.237 seconds
[2020-04-06 17:59:32,809] {scheduler_job.py:153} INFO - Started process (PID=35991) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:59:32,817] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 17:59:32,818] {logging_mixin.py:112} INFO - [2020-04-06 17:59:32,818] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:59:33,075] {logging_mixin.py:112} INFO - [2020-04-06 17:59:33,073] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 17:59:33,083] {logging_mixin.py:112} INFO - [2020-04-06 17:59:33,076] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 17:59:33,084] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 17:59:33,094] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.284 seconds
[2020-04-06 18:00:26,952] {scheduler_job.py:153} INFO - Started process (PID=36023) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:00:26,960] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:00:26,961] {logging_mixin.py:112} INFO - [2020-04-06 18:00:26,961] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:00:27,143] {logging_mixin.py:112} INFO - [2020-04-06 18:00:27,142] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 18:00:27,153] {logging_mixin.py:112} INFO - [2020-04-06 18:00:27,143] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 18:00:27,154] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:00:27,162] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.210 seconds
[2020-04-06 18:01:21,135] {scheduler_job.py:153} INFO - Started process (PID=36053) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:01:21,144] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:01:21,145] {logging_mixin.py:112} INFO - [2020-04-06 18:01:21,145] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:01:21,376] {logging_mixin.py:112} INFO - [2020-04-06 18:01:21,374] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 18:01:21,379] {logging_mixin.py:112} INFO - [2020-04-06 18:01:21,377] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 18:01:21,379] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:01:21,394] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.259 seconds
[2020-04-06 18:02:15,253] {scheduler_job.py:153} INFO - Started process (PID=36084) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:02:15,260] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:02:15,261] {logging_mixin.py:112} INFO - [2020-04-06 18:02:15,261] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:02:15,496] {logging_mixin.py:112} INFO - [2020-04-06 18:02:15,495] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 18:02:15,498] {logging_mixin.py:112} INFO - [2020-04-06 18:02:15,496] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 18:02:15,498] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:02:15,506] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.254 seconds
[2020-04-06 18:03:07,378] {scheduler_job.py:153} INFO - Started process (PID=36135) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:03:07,384] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:03:07,385] {logging_mixin.py:112} INFO - [2020-04-06 18:03:07,385] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:03:07,568] {logging_mixin.py:112} INFO - [2020-04-06 18:03:07,567] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 18:03:07,576] {logging_mixin.py:112} INFO - [2020-04-06 18:03:07,568] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 18:03:07,577] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:03:07,588] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.211 seconds
[2020-04-06 18:03:59,522] {scheduler_job.py:153} INFO - Started process (PID=36170) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:03:59,529] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:03:59,530] {logging_mixin.py:112} INFO - [2020-04-06 18:03:59,529] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:03:59,709] {logging_mixin.py:112} INFO - [2020-04-06 18:03:59,708] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 18:03:59,711] {logging_mixin.py:112} INFO - [2020-04-06 18:03:59,709] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 18:03:59,711] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:03:59,727] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.205 seconds
[2020-04-06 18:04:51,675] {scheduler_job.py:153} INFO - Started process (PID=36208) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:04:51,682] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:04:51,683] {logging_mixin.py:112} INFO - [2020-04-06 18:04:51,683] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:04:51,941] {logging_mixin.py:112} INFO - [2020-04-06 18:04:51,940] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 18:04:51,955] {logging_mixin.py:112} INFO - [2020-04-06 18:04:51,942] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 18:04:51,956] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:04:52,005] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.330 seconds
[2020-04-06 18:05:43,855] {scheduler_job.py:153} INFO - Started process (PID=36236) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:05:43,867] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:05:43,869] {logging_mixin.py:112} INFO - [2020-04-06 18:05:43,868] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:05:44,064] {logging_mixin.py:112} INFO - [2020-04-06 18:05:44,063] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 18:05:44,076] {logging_mixin.py:112} INFO - [2020-04-06 18:05:44,064] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 18:05:44,077] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:05:44,088] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.233 seconds
[2020-04-06 18:06:36,005] {scheduler_job.py:153} INFO - Started process (PID=36266) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:06:36,012] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:06:36,013] {logging_mixin.py:112} INFO - [2020-04-06 18:06:36,013] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:06:36,205] {logging_mixin.py:112} INFO - [2020-04-06 18:06:36,204] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 18:06:36,212] {logging_mixin.py:112} INFO - [2020-04-06 18:06:36,205] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 18:06:36,213] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:06:36,223] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.218 seconds
[2020-04-06 18:07:28,147] {scheduler_job.py:153} INFO - Started process (PID=36299) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:07:28,153] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:07:28,154] {logging_mixin.py:112} INFO - [2020-04-06 18:07:28,153] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:07:28,341] {logging_mixin.py:112} INFO - [2020-04-06 18:07:28,340] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 18:07:28,346] {logging_mixin.py:112} INFO - [2020-04-06 18:07:28,341] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 18:07:28,346] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:07:28,356] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.209 seconds
[2020-04-06 18:08:20,292] {scheduler_job.py:153} INFO - Started process (PID=36327) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:08:20,298] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:08:20,299] {logging_mixin.py:112} INFO - [2020-04-06 18:08:20,299] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:08:20,518] {logging_mixin.py:112} INFO - [2020-04-06 18:08:20,516] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 18:08:20,520] {logging_mixin.py:112} INFO - [2020-04-06 18:08:20,518] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 18:08:20,520] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:08:20,530] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.238 seconds
[2020-04-06 18:09:12,452] {scheduler_job.py:153} INFO - Started process (PID=36356) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:09:12,463] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:09:12,465] {logging_mixin.py:112} INFO - [2020-04-06 18:09:12,464] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:09:12,670] {logging_mixin.py:112} INFO - [2020-04-06 18:09:12,668] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 18:09:12,678] {logging_mixin.py:112} INFO - [2020-04-06 18:09:12,671] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 18:09:12,679] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:09:12,691] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.239 seconds
[2020-04-06 18:10:04,597] {scheduler_job.py:153} INFO - Started process (PID=36389) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:10:04,603] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:10:04,604] {logging_mixin.py:112} INFO - [2020-04-06 18:10:04,604] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:10:04,805] {logging_mixin.py:112} INFO - [2020-04-06 18:10:04,804] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 18:10:04,808] {logging_mixin.py:112} INFO - [2020-04-06 18:10:04,806] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 74, in <module>
    Task_I >> Task_II
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 18:10:04,809] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:10:04,818] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.221 seconds
[2020-04-06 18:10:56,750] {scheduler_job.py:153} INFO - Started process (PID=36423) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:10:56,758] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:10:56,760] {logging_mixin.py:112} INFO - [2020-04-06 18:10:56,759] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:10:56,987] {logging_mixin.py:112} INFO - [2020-04-06 18:10:56,986] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 18:10:56,992] {logging_mixin.py:112} INFO - [2020-04-06 18:10:56,988] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 65, in <module>
    path = os.path.join(os.path.dirname(__file__),'../test.csv')
NameError: name 'os' is not defined
[2020-04-06 18:10:57,000] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:10:57,011] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.261 seconds
[2020-04-06 18:11:48,913] {scheduler_job.py:153} INFO - Started process (PID=36453) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:11:48,926] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:11:48,927] {logging_mixin.py:112} INFO - [2020-04-06 18:11:48,927] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:11:49,131] {logging_mixin.py:112} INFO - [2020-04-06 18:11:49,130] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 18:11:49,141] {logging_mixin.py:112} INFO - [2020-04-06 18:11:49,131] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 65, in <module>
    path = os.path.join(os.path.dirname(__file__),'../test.csv')
NameError: name 'os' is not defined
[2020-04-06 18:11:49,142] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:11:49,153] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.241 seconds
[2020-04-06 18:12:41,086] {scheduler_job.py:153} INFO - Started process (PID=36484) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:12:41,093] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:12:41,094] {logging_mixin.py:112} INFO - [2020-04-06 18:12:41,094] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:12:41,294] {logging_mixin.py:112} INFO - [2020-04-06 18:12:41,294] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 18:12:41,295] {logging_mixin.py:112} INFO - [2020-04-06 18:12:41,295] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(PostgresOperator): import_to_postgres>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 18:12:41,305] {logging_mixin.py:112} INFO - [2020-04-06 18:12:41,296] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 76, in <module>
    Task_I >> Task_II >> Task_III
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 18:12:41,305] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:12:41,315] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.228 seconds
[2020-04-06 18:13:33,180] {scheduler_job.py:153} INFO - Started process (PID=36513) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:13:33,186] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:13:33,187] {logging_mixin.py:112} INFO - [2020-04-06 18:13:33,187] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:13:33,364] {logging_mixin.py:112} INFO - [2020-04-06 18:13:33,363] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(BashOperator): run_kaggle_api>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 18:13:33,365] {logging_mixin.py:112} INFO - [2020-04-06 18:13:33,365] {baseoperator.py:374} WARNING - schedule_interval is used for <Task(PostgresOperator): import_to_postgres>, though it has been deprecated as a task parameter, you need to specify it as a DAG parameter instead
[2020-04-06 18:13:33,375] {logging_mixin.py:112} INFO - [2020-04-06 18:13:33,365] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 76, in <module>
    Task_I >> Task_II >> Task_III
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 18:13:33,375] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:13:33,388] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.208 seconds
[2020-04-06 18:14:25,343] {scheduler_job.py:153} INFO - Started process (PID=36543) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:14:25,349] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:14:25,351] {logging_mixin.py:112} INFO - [2020-04-06 18:14:25,350] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:14:25,554] {logging_mixin.py:112} INFO - [2020-04-06 18:14:25,552] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 75, in <module>
    Task_I >> Task_II >> Task_III
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 18:14:25,554] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:14:25,564] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.222 seconds
[2020-04-06 18:15:17,493] {scheduler_job.py:153} INFO - Started process (PID=36579) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:15:17,500] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:15:17,501] {logging_mixin.py:112} INFO - [2020-04-06 18:15:17,500] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:15:17,752] {logging_mixin.py:112} INFO - [2020-04-06 18:15:17,744] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 75, in <module>
    Task_I >> Task_II >> Task_III
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 18:15:17,753] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:15:17,765] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.272 seconds
[2020-04-06 18:16:09,637] {scheduler_job.py:153} INFO - Started process (PID=36611) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:16:09,644] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:16:09,644] {logging_mixin.py:112} INFO - [2020-04-06 18:16:09,644] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:16:09,843] {logging_mixin.py:112} INFO - [2020-04-06 18:16:09,841] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 75, in <module>
    Task_I >> Task_II >> Task_III
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 18:16:09,843] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:16:09,854] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.217 seconds
[2020-04-06 18:17:01,781] {scheduler_job.py:153} INFO - Started process (PID=36640) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:17:01,790] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:17:01,791] {logging_mixin.py:112} INFO - [2020-04-06 18:17:01,790] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:17:01,985] {logging_mixin.py:112} INFO - [2020-04-06 18:17:01,968] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 75, in <module>
    Task_I >> Task_II >> Task_III
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 18:17:01,986] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:17:01,995] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.214 seconds
[2020-04-06 18:17:53,940] {scheduler_job.py:153} INFO - Started process (PID=36671) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:17:53,947] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:17:53,948] {logging_mixin.py:112} INFO - [2020-04-06 18:17:53,948] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:17:54,147] {logging_mixin.py:112} INFO - [2020-04-06 18:17:54,139] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 75, in <module>
    Task_I >> Task_II >> Task_III
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 18:17:54,147] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:17:54,157] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.217 seconds
[2020-04-06 18:18:46,097] {scheduler_job.py:153} INFO - Started process (PID=36699) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:18:46,103] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:18:46,104] {logging_mixin.py:112} INFO - [2020-04-06 18:18:46,104] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:18:46,299] {logging_mixin.py:112} INFO - [2020-04-06 18:18:46,297] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 75, in <module>
    Task_I >> Task_II >> Task_III
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 18:18:46,299] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:18:46,315] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.218 seconds
[2020-04-06 18:19:38,263] {scheduler_job.py:153} INFO - Started process (PID=36728) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:19:38,269] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:19:38,270] {logging_mixin.py:112} INFO - [2020-04-06 18:19:38,269] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:19:38,279] {logging_mixin.py:112} INFO - [2020-04-06 18:19:38,274] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 2, in <module>
    from datetime import dt
ImportError: cannot import name 'dt' from 'datetime' (/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/datetime.py)
[2020-04-06 18:19:38,279] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:19:38,300] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.038 seconds
[2020-04-06 18:20:30,431] {scheduler_job.py:153} INFO - Started process (PID=36757) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:20:30,438] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:20:30,439] {logging_mixin.py:112} INFO - [2020-04-06 18:20:30,439] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:20:30,447] {logging_mixin.py:112} INFO - [2020-04-06 18:20:30,443] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 2, in <module>
    from datetime import dt
ImportError: cannot import name 'dt' from 'datetime' (/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/datetime.py)
[2020-04-06 18:20:30,448] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:20:30,459] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.028 seconds
[2020-04-06 18:21:22,567] {scheduler_job.py:153} INFO - Started process (PID=36795) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:21:22,574] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:21:22,575] {logging_mixin.py:112} INFO - [2020-04-06 18:21:22,575] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:21:22,583] {logging_mixin.py:112} INFO - [2020-04-06 18:21:22,578] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 2, in <module>
    from datetime import dt
ImportError: cannot import name 'dt' from 'datetime' (/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/datetime.py)
[2020-04-06 18:21:22,584] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:21:22,595] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.029 seconds
[2020-04-06 18:22:14,728] {scheduler_job.py:153} INFO - Started process (PID=36823) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:22:14,734] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:22:14,735] {logging_mixin.py:112} INFO - [2020-04-06 18:22:14,734] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:22:14,740] {logging_mixin.py:112} INFO - [2020-04-06 18:22:14,738] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 2, in <module>
    from datetime import dt
ImportError: cannot import name 'dt' from 'datetime' (/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/datetime.py)
[2020-04-06 18:22:14,741] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:22:14,752] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.024 seconds
[2020-04-06 18:23:06,887] {scheduler_job.py:153} INFO - Started process (PID=36862) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:23:06,894] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:23:06,895] {logging_mixin.py:112} INFO - [2020-04-06 18:23:06,895] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:23:06,899] {logging_mixin.py:112} INFO - [2020-04-06 18:23:06,897] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 2, in <module>
    from datetime import dt
ImportError: cannot import name 'dt' from 'datetime' (/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/datetime.py)
[2020-04-06 18:23:06,899] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:23:06,918] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.031 seconds
[2020-04-06 18:23:59,060] {scheduler_job.py:153} INFO - Started process (PID=36894) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:23:59,066] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:23:59,067] {logging_mixin.py:112} INFO - [2020-04-06 18:23:59,066] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:23:59,070] {logging_mixin.py:112} INFO - [2020-04-06 18:23:59,069] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 2, in <module>
    from datetime import dt
ImportError: cannot import name 'dt' from 'datetime' (/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/datetime.py)
[2020-04-06 18:23:59,071] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:23:59,082] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.022 seconds
[2020-04-06 18:24:51,231] {scheduler_job.py:153} INFO - Started process (PID=36923) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:24:51,236] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:24:51,237] {logging_mixin.py:112} INFO - [2020-04-06 18:24:51,237] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:24:51,248] {logging_mixin.py:112} INFO - [2020-04-06 18:24:51,239] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 2, in <module>
    from datetime import dt
ImportError: cannot import name 'dt' from 'datetime' (/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/datetime.py)
[2020-04-06 18:24:51,249] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:24:51,262] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.032 seconds
[2020-04-06 18:25:43,372] {scheduler_job.py:153} INFO - Started process (PID=36951) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:25:43,379] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:25:43,379] {logging_mixin.py:112} INFO - [2020-04-06 18:25:43,379] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:25:43,383] {logging_mixin.py:112} INFO - [2020-04-06 18:25:43,382] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 2, in <module>
    from datetime import dt
ImportError: cannot import name 'dt' from 'datetime' (/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/datetime.py)
[2020-04-06 18:25:43,383] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:25:43,392] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.021 seconds
[2020-04-06 18:26:35,656] {scheduler_job.py:153} INFO - Started process (PID=36980) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:26:35,662] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:26:35,664] {logging_mixin.py:112} INFO - [2020-04-06 18:26:35,663] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:26:35,668] {logging_mixin.py:112} INFO - [2020-04-06 18:26:35,667] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 2, in <module>
    from datetime import dt
ImportError: cannot import name 'dt' from 'datetime' (/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/datetime.py)
[2020-04-06 18:26:35,668] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:26:35,678] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.022 seconds
[2020-04-06 18:27:28,009] {scheduler_job.py:153} INFO - Started process (PID=37010) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:27:28,015] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:27:28,016] {logging_mixin.py:112} INFO - [2020-04-06 18:27:28,016] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:27:28,020] {logging_mixin.py:112} INFO - [2020-04-06 18:27:28,019] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 2, in <module>
    from datetime import dt
ImportError: cannot import name 'dt' from 'datetime' (/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/datetime.py)
[2020-04-06 18:27:28,021] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:27:28,032] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.023 seconds
[2020-04-06 18:28:20,319] {scheduler_job.py:153} INFO - Started process (PID=37048) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:28:20,327] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:28:20,328] {logging_mixin.py:112} INFO - [2020-04-06 18:28:20,327] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:28:20,332] {logging_mixin.py:112} INFO - [2020-04-06 18:28:20,331] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 2, in <module>
    from datetime import dt
ImportError: cannot import name 'dt' from 'datetime' (/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/datetime.py)
[2020-04-06 18:28:20,333] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:28:20,342] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.023 seconds
[2020-04-06 18:29:12,522] {scheduler_job.py:153} INFO - Started process (PID=37077) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:29:12,528] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:29:12,529] {logging_mixin.py:112} INFO - [2020-04-06 18:29:12,529] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:29:12,533] {logging_mixin.py:112} INFO - [2020-04-06 18:29:12,531] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 2, in <module>
    from datetime import dt
ImportError: cannot import name 'dt' from 'datetime' (/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/datetime.py)
[2020-04-06 18:29:12,533] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:29:12,548] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.027 seconds
[2020-04-06 18:30:04,688] {scheduler_job.py:153} INFO - Started process (PID=37107) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:30:04,694] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:30:04,696] {logging_mixin.py:112} INFO - [2020-04-06 18:30:04,695] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:30:04,700] {logging_mixin.py:112} INFO - [2020-04-06 18:30:04,698] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 2, in <module>
    from datetime import dt
ImportError: cannot import name 'dt' from 'datetime' (/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/datetime.py)
[2020-04-06 18:30:04,700] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:30:04,716] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.028 seconds
[2020-04-06 18:30:56,833] {scheduler_job.py:153} INFO - Started process (PID=37138) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:30:56,840] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:30:56,842] {logging_mixin.py:112} INFO - [2020-04-06 18:30:56,841] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:30:57,052] {logging_mixin.py:112} INFO - [2020-04-06 18:30:57,048] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 18, in <module>
    'start_date': datetime.datetime(2017, 6, 1),
AttributeError: type object 'datetime.datetime' has no attribute 'datetime'
[2020-04-06 18:30:57,053] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:30:57,061] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.228 seconds
[2020-04-06 18:31:48,977] {scheduler_job.py:153} INFO - Started process (PID=37168) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:31:48,984] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:31:48,986] {logging_mixin.py:112} INFO - [2020-04-06 18:31:48,985] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:31:49,177] {logging_mixin.py:112} INFO - [2020-04-06 18:31:49,176] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 18, in <module>
    'start_date': datetime.datetime(2017, 6, 1),
AttributeError: type object 'datetime.datetime' has no attribute 'datetime'
[2020-04-06 18:31:49,178] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:31:49,190] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.213 seconds
[2020-04-06 18:32:41,128] {scheduler_job.py:153} INFO - Started process (PID=37197) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:32:41,135] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:32:41,136] {logging_mixin.py:112} INFO - [2020-04-06 18:32:41,136] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:32:41,347] {logging_mixin.py:112} INFO - [2020-04-06 18:32:41,339] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II >> Task_III
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 18:32:41,348] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:32:41,357] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.230 seconds
[2020-04-06 18:33:33,267] {scheduler_job.py:153} INFO - Started process (PID=37227) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:33:33,275] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:33:33,276] {logging_mixin.py:112} INFO - [2020-04-06 18:33:33,275] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:33:33,469] {logging_mixin.py:112} INFO - [2020-04-06 18:33:33,459] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II >> Task_III
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 18:33:33,469] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:33:33,479] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.212 seconds
[2020-04-06 18:34:25,418] {scheduler_job.py:153} INFO - Started process (PID=37255) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:34:25,423] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:34:25,424] {logging_mixin.py:112} INFO - [2020-04-06 18:34:25,424] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:34:25,629] {logging_mixin.py:112} INFO - [2020-04-06 18:34:25,627] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II >> Task_III
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 18:34:25,630] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:34:25,641] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.224 seconds
[2020-04-06 18:35:17,552] {scheduler_job.py:153} INFO - Started process (PID=37284) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:35:17,558] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:35:17,559] {logging_mixin.py:112} INFO - [2020-04-06 18:35:17,558] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:35:17,751] {logging_mixin.py:112} INFO - [2020-04-06 18:35:17,750] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II >> Task_III
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 18:35:17,752] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:35:17,762] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.211 seconds
[2020-04-06 18:36:09,694] {scheduler_job.py:153} INFO - Started process (PID=37314) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:36:09,701] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:36:09,702] {logging_mixin.py:112} INFO - [2020-04-06 18:36:09,702] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:36:09,906] {logging_mixin.py:112} INFO - [2020-04-06 18:36:09,897] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II >> Task_III
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 18:36:09,907] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:36:09,918] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.225 seconds
[2020-04-06 18:37:01,850] {scheduler_job.py:153} INFO - Started process (PID=37344) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:37:01,855] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:37:01,856] {logging_mixin.py:112} INFO - [2020-04-06 18:37:01,856] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:37:02,037] {logging_mixin.py:112} INFO - [2020-04-06 18:37:02,035] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II >> Task_III
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 18:37:02,038] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:37:02,052] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.202 seconds
[2020-04-06 18:37:54,000] {scheduler_job.py:153} INFO - Started process (PID=37373) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:37:54,006] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:37:54,007] {logging_mixin.py:112} INFO - [2020-04-06 18:37:54,007] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:37:54,213] {logging_mixin.py:112} INFO - [2020-04-06 18:37:54,211] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II >> Task_III
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 18:37:54,213] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:37:54,229] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.230 seconds
[2020-04-06 18:38:46,137] {scheduler_job.py:153} INFO - Started process (PID=37402) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:38:46,145] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:38:46,147] {logging_mixin.py:112} INFO - [2020-04-06 18:38:46,146] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:38:46,405] {logging_mixin.py:112} INFO - [2020-04-06 18:38:46,403] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II >> Task_III
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 18:38:46,405] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:38:46,415] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.278 seconds
[2020-04-06 18:39:38,281] {scheduler_job.py:153} INFO - Started process (PID=37441) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:39:38,287] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:39:38,288] {logging_mixin.py:112} INFO - [2020-04-06 18:39:38,287] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:39:38,467] {logging_mixin.py:112} INFO - [2020-04-06 18:39:38,465] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II >> Task_III
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 18:39:38,468] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:39:38,477] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.196 seconds
[2020-04-06 18:40:30,429] {scheduler_job.py:153} INFO - Started process (PID=37471) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:40:30,437] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:40:30,438] {logging_mixin.py:112} INFO - [2020-04-06 18:40:30,438] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:40:30,638] {logging_mixin.py:112} INFO - [2020-04-06 18:40:30,636] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 18, in <module>
    'start_date':  datetime.now(),
NameError: name 'datetime' is not defined
[2020-04-06 18:40:30,638] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:40:30,646] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.218 seconds
[2020-04-06 18:41:22,586] {scheduler_job.py:153} INFO - Started process (PID=37499) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:41:22,592] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:41:22,593] {logging_mixin.py:112} INFO - [2020-04-06 18:41:22,593] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:41:22,772] {logging_mixin.py:112} INFO - [2020-04-06 18:41:22,771] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 18, in <module>
    'start_date':  datetime.now(),
NameError: name 'datetime' is not defined
[2020-04-06 18:41:22,772] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:41:22,786] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.200 seconds
[2020-04-06 18:42:14,734] {scheduler_job.py:153} INFO - Started process (PID=37527) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:42:14,739] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:42:14,740] {logging_mixin.py:112} INFO - [2020-04-06 18:42:14,740] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:42:14,927] {logging_mixin.py:112} INFO - [2020-04-06 18:42:14,926] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 18, in <module>
    'start_date':  datetime.now(),
NameError: name 'datetime' is not defined
[2020-04-06 18:42:14,927] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:42:14,936] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.202 seconds
[2020-04-06 18:43:06,896] {scheduler_job.py:153} INFO - Started process (PID=37557) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:43:06,909] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:43:06,910] {logging_mixin.py:112} INFO - [2020-04-06 18:43:06,909] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:43:07,089] {logging_mixin.py:112} INFO - [2020-04-06 18:43:07,082] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 18, in <module>
    'start_date':  datetime.now(),
NameError: name 'datetime' is not defined
[2020-04-06 18:43:07,090] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:43:07,101] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.205 seconds
[2020-04-06 18:43:59,054] {scheduler_job.py:153} INFO - Started process (PID=37587) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:43:59,061] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:43:59,061] {logging_mixin.py:112} INFO - [2020-04-06 18:43:59,061] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:43:59,242] {logging_mixin.py:112} INFO - [2020-04-06 18:43:59,241] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 18, in <module>
    'start_date':  datetime.now(),
NameError: name 'datetime' is not defined
[2020-04-06 18:43:59,243] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:43:59,256] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.202 seconds
[2020-04-06 18:44:51,194] {scheduler_job.py:153} INFO - Started process (PID=37616) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:44:51,200] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:44:51,201] {logging_mixin.py:112} INFO - [2020-04-06 18:44:51,200] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:44:51,396] {logging_mixin.py:112} INFO - [2020-04-06 18:44:51,394] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 18, in <module>
    'start_date':  datetime.now(),
NameError: name 'datetime' is not defined
[2020-04-06 18:44:51,396] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:44:51,405] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.212 seconds
[2020-04-06 18:45:43,337] {scheduler_job.py:153} INFO - Started process (PID=37644) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:45:43,343] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:45:43,344] {logging_mixin.py:112} INFO - [2020-04-06 18:45:43,344] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:45:43,534] {logging_mixin.py:112} INFO - [2020-04-06 18:45:43,533] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 18, in <module>
    'start_date':  datetime.now(),
NameError: name 'datetime' is not defined
[2020-04-06 18:45:43,535] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:45:43,549] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.212 seconds
[2020-04-06 18:46:35,473] {scheduler_job.py:153} INFO - Started process (PID=37673) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:46:35,479] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:46:35,480] {logging_mixin.py:112} INFO - [2020-04-06 18:46:35,480] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:46:35,656] {logging_mixin.py:112} INFO - [2020-04-06 18:46:35,655] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 18, in <module>
    'start_date':  datetime.now(),
NameError: name 'datetime' is not defined
[2020-04-06 18:46:35,656] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:46:35,670] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.198 seconds
[2020-04-06 18:47:27,684] {scheduler_job.py:153} INFO - Started process (PID=37711) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:47:27,689] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:47:27,690] {logging_mixin.py:112} INFO - [2020-04-06 18:47:27,690] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:47:27,887] {logging_mixin.py:112} INFO - [2020-04-06 18:47:27,885] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 18, in <module>
    'start_date':  datetime.now(),
NameError: name 'datetime' is not defined
[2020-04-06 18:47:27,887] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:47:27,897] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.213 seconds
[2020-04-06 18:48:19,924] {scheduler_job.py:153} INFO - Started process (PID=37740) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:48:19,931] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:48:19,932] {logging_mixin.py:112} INFO - [2020-04-06 18:48:19,931] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:48:20,120] {logging_mixin.py:112} INFO - [2020-04-06 18:48:20,119] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 18, in <module>
    'start_date':  datetime.now(),
NameError: name 'datetime' is not defined
[2020-04-06 18:48:20,120] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:48:20,132] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.208 seconds
[2020-04-06 18:49:12,175] {scheduler_job.py:153} INFO - Started process (PID=37768) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:49:12,181] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:49:12,182] {logging_mixin.py:112} INFO - [2020-04-06 18:49:12,182] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:49:12,384] {logging_mixin.py:112} INFO - [2020-04-06 18:49:12,382] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 18, in <module>
    'start_date':  datetime.now(),
NameError: name 'datetime' is not defined
[2020-04-06 18:49:12,384] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:49:12,399] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.224 seconds
[2020-04-06 18:50:04,453] {scheduler_job.py:153} INFO - Started process (PID=37797) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:50:04,459] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:50:04,460] {logging_mixin.py:112} INFO - [2020-04-06 18:50:04,459] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:50:04,647] {logging_mixin.py:112} INFO - [2020-04-06 18:50:04,646] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 18, in <module>
    'start_date':  datetime.now(),
NameError: name 'datetime' is not defined
[2020-04-06 18:50:04,647] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:50:04,657] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.204 seconds
[2020-04-06 18:50:56,798] {scheduler_job.py:153} INFO - Started process (PID=37827) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:50:56,803] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:50:56,805] {logging_mixin.py:112} INFO - [2020-04-06 18:50:56,804] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:50:56,989] {logging_mixin.py:112} INFO - [2020-04-06 18:50:56,982] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 18, in <module>
    'start_date':  datetime.now(),
NameError: name 'datetime' is not defined
[2020-04-06 18:50:56,990] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:50:57,001] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.203 seconds
[2020-04-06 18:51:49,153] {scheduler_job.py:153} INFO - Started process (PID=37855) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:51:49,158] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:51:49,159] {logging_mixin.py:112} INFO - [2020-04-06 18:51:49,159] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:51:49,333] {logging_mixin.py:112} INFO - [2020-04-06 18:51:49,332] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 18, in <module>
    'start_date':  datetime.now(),
NameError: name 'datetime' is not defined
[2020-04-06 18:51:49,333] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:51:49,347] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.194 seconds
[2020-04-06 18:52:41,442] {scheduler_job.py:153} INFO - Started process (PID=37885) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:52:41,449] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 18:52:41,450] {logging_mixin.py:112} INFO - [2020-04-06 18:52:41,449] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:52:41,623] {logging_mixin.py:112} INFO - [2020-04-06 18:52:41,619] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 18, in <module>
    'start_date':  datetime.now(),
NameError: name 'datetime' is not defined
[2020-04-06 18:52:41,623] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 18:52:41,633] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.190 seconds
[2020-04-06 19:20:55,159] {scheduler_job.py:153} INFO - Started process (PID=37937) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:20:55,172] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 19:20:55,173] {logging_mixin.py:112} INFO - [2020-04-06 19:20:55,173] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:20:55,405] {logging_mixin.py:112} INFO - [2020-04-06 19:20:55,404] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 18, in <module>
    'start_date':  datetime.now(),
NameError: name 'datetime' is not defined
[2020-04-06 19:20:55,406] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:20:55,416] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.257 seconds
[2020-04-06 19:21:47,312] {scheduler_job.py:153} INFO - Started process (PID=37965) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:21:47,325] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 19:21:47,326] {logging_mixin.py:112} INFO - [2020-04-06 19:21:47,326] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:21:47,513] {logging_mixin.py:112} INFO - [2020-04-06 19:21:47,509] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 18, in <module>
    'start_date':  dt.now(),
AttributeError: module 'datetime' has no attribute 'now'
[2020-04-06 19:21:47,514] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:21:47,524] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.212 seconds
[2020-04-06 19:22:39,455] {scheduler_job.py:153} INFO - Started process (PID=37993) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:22:39,461] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 19:22:39,462] {logging_mixin.py:112} INFO - [2020-04-06 19:22:39,462] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:22:39,659] {logging_mixin.py:112} INFO - [2020-04-06 19:22:39,651] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 18, in <module>
    'start_date':  dt.now(),
AttributeError: module 'datetime' has no attribute 'now'
[2020-04-06 19:22:39,660] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:22:39,670] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.214 seconds
[2020-04-06 19:23:31,613] {scheduler_job.py:153} INFO - Started process (PID=38023) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:23:31,618] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 19:23:31,619] {logging_mixin.py:112} INFO - [2020-04-06 19:23:31,618] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:23:31,822] {logging_mixin.py:112} INFO - [2020-04-06 19:23:31,815] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 18, in <module>
    'start_date':  dt.now(),
AttributeError: module 'datetime' has no attribute 'now'
[2020-04-06 19:23:31,823] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:23:31,837] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.224 seconds
[2020-04-06 19:24:23,748] {scheduler_job.py:153} INFO - Started process (PID=38053) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:24:23,754] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 19:24:23,755] {logging_mixin.py:112} INFO - [2020-04-06 19:24:23,755] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:24:23,960] {logging_mixin.py:112} INFO - [2020-04-06 19:24:23,959] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 18, in <module>
    'start_date':  dt.now(),
AttributeError: module 'datetime' has no attribute 'now'
[2020-04-06 19:24:23,961] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:24:23,970] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.222 seconds
[2020-04-06 19:25:15,871] {scheduler_job.py:153} INFO - Started process (PID=38082) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:25:15,878] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 19:25:15,879] {logging_mixin.py:112} INFO - [2020-04-06 19:25:15,879] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:25:15,885] {logging_mixin.py:112} INFO - [2020-04-06 19:25:15,881] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 19
    'retries': 1,
            ^
SyntaxError: invalid syntax
[2020-04-06 19:25:15,886] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:25:15,896] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.025 seconds
[2020-04-06 19:26:08,021] {scheduler_job.py:153} INFO - Started process (PID=38112) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:26:08,031] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 19:26:08,032] {logging_mixin.py:112} INFO - [2020-04-06 19:26:08,031] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:26:08,037] {logging_mixin.py:112} INFO - [2020-04-06 19:26:08,034] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 19
    'retries': 1,
            ^
SyntaxError: invalid syntax
[2020-04-06 19:26:08,038] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:26:08,053] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.032 seconds
[2020-04-06 19:27:00,180] {scheduler_job.py:153} INFO - Started process (PID=38141) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:27:00,187] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 19:27:00,188] {logging_mixin.py:112} INFO - [2020-04-06 19:27:00,188] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:27:00,194] {logging_mixin.py:112} INFO - [2020-04-06 19:27:00,191] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 19
    'retries': 1,
            ^
SyntaxError: invalid syntax
[2020-04-06 19:27:00,195] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:27:00,206] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.026 seconds
[2020-04-06 19:27:52,338] {scheduler_job.py:153} INFO - Started process (PID=38181) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:27:52,344] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 19:27:52,345] {logging_mixin.py:112} INFO - [2020-04-06 19:27:52,345] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:27:52,351] {logging_mixin.py:112} INFO - [2020-04-06 19:27:52,348] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 19
    'retries': 1,
            ^
SyntaxError: invalid syntax
[2020-04-06 19:27:52,351] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:27:52,361] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.023 seconds
[2020-04-06 19:28:44,469] {scheduler_job.py:153} INFO - Started process (PID=38209) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:28:44,474] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 19:28:44,476] {logging_mixin.py:112} INFO - [2020-04-06 19:28:44,475] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:28:44,479] {logging_mixin.py:112} INFO - [2020-04-06 19:28:44,478] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 19
    'retries': 1,
            ^
SyntaxError: invalid syntax
[2020-04-06 19:28:44,480] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:28:44,492] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.023 seconds
[2020-04-06 19:29:36,603] {scheduler_job.py:153} INFO - Started process (PID=38238) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:29:36,610] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 19:29:36,611] {logging_mixin.py:112} INFO - [2020-04-06 19:29:36,611] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:29:36,616] {logging_mixin.py:112} INFO - [2020-04-06 19:29:36,614] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 19
    'retries': 0,
            ^
SyntaxError: invalid syntax
[2020-04-06 19:29:36,616] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:29:36,634] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.031 seconds
[2020-04-06 19:30:28,739] {scheduler_job.py:153} INFO - Started process (PID=38269) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:30:28,746] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 19:30:28,747] {logging_mixin.py:112} INFO - [2020-04-06 19:30:28,747] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:30:28,751] {logging_mixin.py:112} INFO - [2020-04-06 19:30:28,750] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 19
    'retries': 1,
            ^
SyntaxError: invalid syntax
[2020-04-06 19:30:28,752] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:30:28,762] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.023 seconds
[2020-04-06 19:31:20,862] {scheduler_job.py:153} INFO - Started process (PID=38304) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:31:20,869] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 19:31:20,870] {logging_mixin.py:112} INFO - [2020-04-06 19:31:20,869] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:31:21,064] {logging_mixin.py:112} INFO - [2020-04-06 19:31:21,051] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II >> Task_III
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 19:31:21,065] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:31:21,076] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.214 seconds
[2020-04-06 19:32:13,011] {scheduler_job.py:153} INFO - Started process (PID=38337) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:32:13,018] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 19:32:13,019] {logging_mixin.py:112} INFO - [2020-04-06 19:32:13,018] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:32:13,221] {logging_mixin.py:112} INFO - [2020-04-06 19:32:13,219] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II >> Task_III
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 19:32:13,221] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:32:13,233] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.222 seconds
[2020-04-06 19:33:05,153] {scheduler_job.py:153} INFO - Started process (PID=38367) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:33:05,158] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 19:33:05,159] {logging_mixin.py:112} INFO - [2020-04-06 19:33:05,159] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:33:05,378] {logging_mixin.py:112} INFO - [2020-04-06 19:33:05,376] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II >> Task_III
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 19:33:05,379] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:33:05,390] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.238 seconds
[2020-04-06 19:33:57,283] {scheduler_job.py:153} INFO - Started process (PID=38396) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:33:57,289] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 19:33:57,290] {logging_mixin.py:112} INFO - [2020-04-06 19:33:57,290] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:33:57,485] {logging_mixin.py:112} INFO - [2020-04-06 19:33:57,482] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II >> Task_III
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 19:33:57,486] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:33:57,501] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.218 seconds
[2020-04-06 19:34:49,432] {scheduler_job.py:153} INFO - Started process (PID=38424) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:34:49,438] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 19:34:49,439] {logging_mixin.py:112} INFO - [2020-04-06 19:34:49,439] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:34:49,628] {logging_mixin.py:112} INFO - [2020-04-06 19:34:49,627] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II >> Task_III
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 19:34:49,629] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:34:49,645] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.213 seconds
[2020-04-06 19:35:42,537] {scheduler_job.py:153} INFO - Started process (PID=38462) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:35:42,543] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 19:35:42,544] {logging_mixin.py:112} INFO - [2020-04-06 19:35:42,544] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:35:42,768] {logging_mixin.py:112} INFO - [2020-04-06 19:35:42,762] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II >> Task_III
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 19:35:42,769] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:35:42,785] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.247 seconds
[2020-04-06 19:36:34,676] {scheduler_job.py:153} INFO - Started process (PID=38490) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:36:34,682] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 19:36:34,683] {logging_mixin.py:112} INFO - [2020-04-06 19:36:34,682] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:36:34,867] {logging_mixin.py:112} INFO - [2020-04-06 19:36:34,866] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 72, in <module>
    Task_I >> Task_II >> Task_III
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 19:36:34,868] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:36:34,882] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.206 seconds
[2020-04-06 19:37:26,852] {scheduler_job.py:153} INFO - Started process (PID=38520) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:37:26,857] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 19:37:26,858] {logging_mixin.py:112} INFO - [2020-04-06 19:37:26,858] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:37:27,038] {logging_mixin.py:112} INFO - [2020-04-06 19:37:27,036] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 71, in <module>
    Task_I >> Task_II >> Task_III
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 19:37:27,038] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:37:27,052] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.201 seconds
[2020-04-06 19:38:18,976] {scheduler_job.py:153} INFO - Started process (PID=38550) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:38:18,982] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 19:38:18,983] {logging_mixin.py:112} INFO - [2020-04-06 19:38:18,983] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:38:19,194] {logging_mixin.py:112} INFO - [2020-04-06 19:38:19,188] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 71, in <module>
    Task_I >> Task_II >> Task_III
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 19:38:19,195] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:38:19,204] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.229 seconds
[2020-04-06 19:39:11,111] {scheduler_job.py:153} INFO - Started process (PID=38580) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:39:11,122] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 19:39:11,123] {logging_mixin.py:112} INFO - [2020-04-06 19:39:11,123] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:39:11,452] {logging_mixin.py:112} INFO - [2020-04-06 19:39:11,439] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 73, in <module>
    Task_I >> Task_II >> Task_III
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 19:39:11,453] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:39:11,468] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.357 seconds
[2020-04-06 19:40:03,240] {scheduler_job.py:153} INFO - Started process (PID=38611) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:40:03,248] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 19:40:03,249] {logging_mixin.py:112} INFO - [2020-04-06 19:40:03,249] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:40:03,446] {logging_mixin.py:112} INFO - [2020-04-06 19:40:03,438] {dagbag.py:246} ERROR - Failed to import: /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
Traceback (most recent call last):
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dagbag.py", line 243, in process_file
    m = imp.load_source(mod_name, filepath)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/imp.py", line 171, in load_source
    module = _load(spec)
  File "<frozen importlib._bootstrap>", line 696, in _load
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/Users/cchavez/dev/airflow_home/dags/kaggle_dag.py", line 73, in <module>
    Task_I >> Task_II >> Task_III
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 482, in __rshift__
    self.set_downstream(other)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1035, in set_downstream
    self._set_relatives(task_or_task_list, upstream=False)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 1022, in _set_relatives
    task.dag = dag
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 542, in dag
    dag.add_task(self)
  File "/Users/cchavez/opt/anaconda3/envs/airflow/lib/python3.7/site-packages/airflow/models/dag.py", line 1285, in add_task
    raise AirflowException("Task is missing the start_date parameter")
airflow.exceptions.AirflowException: Task is missing the start_date parameter
[2020-04-06 19:40:03,447] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:40:03,458] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.218 seconds
[2020-04-06 19:40:55,370] {scheduler_job.py:153} INFO - Started process (PID=38640) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:40:55,377] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 19:40:55,378] {logging_mixin.py:112} INFO - [2020-04-06 19:40:55,378] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:40:55,379] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:40:55,380] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.009 seconds
[2020-04-06 19:41:47,549] {scheduler_job.py:153} INFO - Started process (PID=38681) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:41:47,561] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 19:41:47,563] {logging_mixin.py:112} INFO - [2020-04-06 19:41:47,563] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:41:47,565] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:41:47,567] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.018 seconds
[2020-04-06 19:42:39,665] {scheduler_job.py:153} INFO - Started process (PID=38709) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:42:39,672] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 19:42:39,673] {logging_mixin.py:112} INFO - [2020-04-06 19:42:39,673] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:42:39,674] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:42:39,675] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.010 seconds
[2020-04-06 19:43:31,810] {scheduler_job.py:153} INFO - Started process (PID=38739) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:43:31,817] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 19:43:31,817] {logging_mixin.py:112} INFO - [2020-04-06 19:43:31,817] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:43:31,818] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:43:31,819] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.009 seconds
[2020-04-06 19:44:23,949] {scheduler_job.py:153} INFO - Started process (PID=38769) to work on /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:44:23,957] {scheduler_job.py:1560} INFO - Processing file /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py for tasks to queue
[2020-04-06 19:44:23,958] {logging_mixin.py:112} INFO - [2020-04-06 19:44:23,958] {dagbag.py:403} INFO - Filling up the DagBag from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:44:23,960] {scheduler_job.py:1574} WARNING - No viable dags retrieved from /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py
[2020-04-06 19:44:23,960] {scheduler_job.py:161} INFO - Processing /Users/cchavez/dev/airflow_home/dags/kaggle_dag.py took 0.012 seconds
